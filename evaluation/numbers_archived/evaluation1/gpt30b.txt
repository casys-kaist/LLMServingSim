model: gpt3-30b, num requests: 1, total length: 10, prompt/kv_cache length: ['10']
model: gpt3-30b, num requests: 1, total length: 1, prompt/kv_cache length: ['11']
model: gpt3-30b, num requests: 1, total length: 1, prompt/kv_cache length: ['12']
model: gpt3-30b, num requests: 1, total length: 1, prompt/kv_cache length: ['13']
model: gpt3-30b, num requests: 1, total length: 1, prompt/kv_cache length: ['14']
model: gpt3-30b, num requests: 1, total length: 1, prompt/kv_cache length: ['15']
model: gpt3-30b, num requests: 2, total length: 23, prompt/kv_cache length: ['16', '22']
model: gpt3-30b, num requests: 2, total length: 2, prompt/kv_cache length: ['17', '23']
[0.5s] Avg Throughput: propmt: 64, generation: 12
model: gpt3-30b, num requests: 3, total length: 18, prompt/kv_cache length: ['18', '24', '16']
model: gpt3-30b, num requests: 5, total length: 20, prompt/kv_cache length: ['19', '25', '17', '4', '13']
model: gpt3-30b, num requests: 7, total length: 35, prompt/kv_cache length: ['20', '26', '18', '5', '14', '15', '15']
model: gpt3-30b, num requests: 7, total length: 7, prompt/kv_cache length: ['21', '27', '19', '6', '15', '16', '16']
model: gpt3-30b, num requests: 8, total length: 9, prompt/kv_cache length: ['22', '28', '20', '7', '16', '17', '17', '2']
model: gpt3-30b, num requests: 8, total length: 8, prompt/kv_cache length: ['23', '29', '21', '8', '17', '18', '18', '3']
model: gpt3-30b, num requests: 9, total length: 26, prompt/kv_cache length: ['24', '30', '22', '9', '18', '19', '19', '4', '18']
[1.0s] Avg Throughput: propmt: 130, generation: 68
model: gpt3-30b, num requests: 11, total length: 97, prompt/kv_cache length: ['25', '31', '23', '10', '19', '20', '20', '5', '19', '5', '83']
model: gpt3-30b, num requests: 11, total length: 11, prompt/kv_cache length: ['26', '32', '24', '11', '20', '21', '21', '6', '20', '6', '84']
model: gpt3-30b, num requests: 11, total length: 11, prompt/kv_cache length: ['27', '33', '25', '12', '21', '22', '22', '7', '21', '7', '85']
model: gpt3-30b, num requests: 12, total length: 19, prompt/kv_cache length: ['28', '34', '26', '13', '22', '23', '23', '8', '22', '8', '86', '8']
model: gpt3-30b, num requests: 12, total length: 12, prompt/kv_cache length: ['29', '35', '27', '14', '23', '24', '24', '9', '23', '9', '87', '9']
[1.5s] Avg Throughput: propmt: 228, generation: 100
model: gpt3-30b, num requests: 12, total length: 12, prompt/kv_cache length: ['30', '36', '28', '15', '24', '25', '25', '10', '24', '10', '88', '10']
model: gpt3-30b, num requests: 12, total length: 38, prompt/kv_cache length: ['31', '37', '29', '25', '26', '26', '25', '11', '89', '11', '14', '14']
model: gpt3-30b, num requests: 15, total length: 46, prompt/kv_cache length: ['32', '38', '30', '26', '27', '27', '26', '12', '90', '12', '15', '15', '3', '8', '23']
model: gpt3-30b, num requests: 16, total length: 33, prompt/kv_cache length: ['33', '39', '31', '27', '28', '28', '27', '13', '91', '13', '16', '16', '4', '9', '24', '18']
model: gpt3-30b, num requests: 18, total length: 71, prompt/kv_cache length: ['34', '40', '32', '28', '29', '29', '28', '14', '92', '14', '17', '17', '5', '10', '25', '19', '30', '25']
model: gpt3-30b, num requests: 21, total length: 40, prompt/kv_cache length: ['35', '41', '33', '29', '30', '30', '29', '15', '93', '15', '18', '18', '6', '11', '26', '20', '31', '26', '8', '10', '4']
[2.0s] Avg Throughput: propmt: 270, generation: 154
model: gpt3-30b, num requests: 22, total length: 89, prompt/kv_cache length: ['36', '42', '34', '30', '31', '31', '30', '16', '94', '16', '19', '19', '7', '12', '27', '21', '32', '27', '9', '11', '5', '68']
model: gpt3-30b, num requests: 23, total length: 29, prompt/kv_cache length: ['37', '43', '35', '31', '32', '32', '31', '17', '95', '17', '20', '20', '8', '13', '28', '22', '33', '28', '10', '12', '6', '69', '7']
model: gpt3-30b, num requests: 25, total length: 49, prompt/kv_cache length: ['38', '44', '36', '32', '33', '33', '32', '18', '96', '18', '21', '21', '9', '14', '29', '23', '34', '29', '11', '13', '7', '70', '8', '10', '16']
model: gpt3-30b, num requests: 26, total length: 33, prompt/kv_cache length: ['39', '45', '37', '33', '34', '34', '33', '19', '97', '19', '22', '22', '10', '15', '30', '24', '35', '30', '12', '14', '8', '71', '9', '11', '17', '8']
model: gpt3-30b, num requests: 28, total length: 86, prompt/kv_cache length: ['40', '46', '38', '34', '35', '35', '34', '20', '98', '20', '23', '23', '11', '16', '31', '25', '36', '31', '13', '15', '9', '72', '10', '12', '18', '9', '47', '13']
[2.5s] Avg Throughput: propmt: 262, generation: 218
model: gpt3-30b, num requests: 31, total length: 105, prompt/kv_cache length: ['41', '47', '39', '35', '36', '36', '35', '21', '99', '21', '24', '24', '12', '17', '32', '26', '37', '32', '14', '16', '10', '73', '11', '13', '19', '10', '48', '14', '26', '8', '43']
model: gpt3-30b, num requests: 31, total length: 31, prompt/kv_cache length: ['42', '48', '40', '36', '37', '37', '36', '22', '100', '22', '25', '25', '13', '18', '33', '27', '38', '33', '15', '17', '11', '74', '12', '14', '20', '11', '49', '15', '27', '9', '44']
model: gpt3-30b, num requests: 31, total length: 31, prompt/kv_cache length: ['43', '49', '41', '37', '38', '38', '37', '23', '101', '23', '26', '26', '14', '19', '34', '28', '39', '34', '16', '18', '12', '75', '13', '15', '21', '12', '50', '16', '28', '10', '45']
model: gpt3-30b, num requests: 32, total length: 74, prompt/kv_cache length: ['44', '50', '42', '38', '39', '39', '38', '24', '102', '24', '27', '27', '15', '20', '35', '29', '40', '35', '17', '19', '13', '76', '14', '16', '22', '13', '51', '17', '29', '11', '46', '43']
[3.0s] Avg Throughput: propmt: 274, generation: 232
model: gpt3-30b, num requests: 31, total length: 31, prompt/kv_cache length: ['45', '51', '43', '39', '40', '40', '39', '25', '103', '25', '28', '28', '16', '21', '36', '30', '41', '36', '18', '14', '77', '15', '17', '23', '14', '52', '18', '30', '12', '47', '44']
model: gpt3-30b, num requests: 31, total length: 31, prompt/kv_cache length: ['46', '52', '44', '40', '41', '41', '40', '26', '104', '26', '29', '29', '17', '22', '37', '31', '42', '37', '19', '15', '78', '16', '18', '24', '15', '53', '19', '31', '13', '48', '45']
model: gpt3-30b, num requests: 32, total length: 48, prompt/kv_cache length: ['47', '53', '45', '41', '42', '42', '41', '27', '105', '27', '30', '30', '18', '23', '38', '32', '43', '38', '20', '16', '79', '17', '19', '25', '16', '54', '20', '32', '14', '49', '46', '17']
model: gpt3-30b, num requests: 31, total length: 31, prompt/kv_cache length: ['48', '54', '46', '42', '43', '43', '42', '28', '106', '28', '31', '31', '19', '24', '39', '33', '44', '39', '21', '17', '80', '18', '26', '17', '55', '21', '33', '15', '50', '47', '18']
model: gpt3-30b, num requests: 32, total length: 39, prompt/kv_cache length: ['49', '55', '47', '43', '44', '44', '43', '29', '107', '29', '32', '32', '20', '25', '40', '34', '45', '40', '22', '18', '81', '19', '27', '18', '56', '22', '34', '16', '51', '48', '19', '8']
model: gpt3-30b, num requests: 34, total length: 42, prompt/kv_cache length: ['50', '56', '48', '44', '45', '45', '44', '30', '108', '30', '33', '33', '21', '26', '41', '35', '46', '41', '23', '19', '82', '20', '28', '19', '57', '23', '35', '17', '52', '49', '20', '9', '1', '9']
[3.5s] Avg Throughput: propmt: 136, generation: 372
model: gpt3-30b, num requests: 34, total length: 35, prompt/kv_cache length: ['51', '57', '49', '45', '46', '46', '45', '109', '31', '34', '34', '22', '27', '42', '36', '47', '42', '24', '20', '83', '21', '29', '20', '58', '24', '36', '18', '53', '50', '21', '10', '2', '10', '2']
model: gpt3-30b, num requests: 36, total length: 138, prompt/kv_cache length: ['52', '58', '50', '46', '47', '47', '46', '110', '32', '35', '35', '23', '28', '43', '37', '48', '43', '25', '21', '84', '22', '30', '21', '59', '25', '37', '19', '54', '51', '22', '11', '3', '11', '3', '1', '103']
model: gpt3-30b, num requests: 39, total length: 121, prompt/kv_cache length: ['53', '59', '51', '47', '48', '48', '47', '111', '33', '36', '36', '24', '29', '44', '38', '49', '44', '26', '22', '85', '23', '31', '22', '60', '26', '38', '20', '55', '52', '23', '12', '4', '12', '4', '2', '104', '63', '5', '17']
[4.0s] Avg Throughput: propmt: 232, generation: 198
model: gpt3-30b, num requests: 40, total length: 64, prompt/kv_cache length: ['54', '60', '52', '48', '49', '49', '48', '112', '34', '37', '37', '25', '30', '45', '39', '50', '45', '27', '23', '86', '24', '32', '23', '61', '27', '39', '21', '56', '53', '24', '13', '5', '13', '5', '3', '64', '6', '18', '6', '20']
model: gpt3-30b, num requests: 41, total length: 184, prompt/kv_cache length: ['55', '61', '53', '49', '50', '50', '49', '113', '35', '38', '38', '26', '31', '46', '40', '46', '28', '24', '87', '25', '33', '24', '62', '28', '40', '22', '57', '54', '25', '14', '6', '14', '6', '4', '65', '7', '19', '7', '21', '36', '109']
model: gpt3-30b, num requests: 43, total length: 123, prompt/kv_cache length: ['56', '62', '54', '50', '51', '51', '50', '114', '36', '39', '39', '27', '32', '47', '41', '47', '29', '25', '88', '26', '34', '25', '63', '29', '41', '23', '58', '55', '26', '15', '7', '15', '7', '5', '66', '8', '20', '8', '22', '37', '110', '9', '73']
[4.5s] Avg Throughput: propmt: 512, generation: 226
model: gpt3-30b, num requests: 43, total length: 54, prompt/kv_cache length: ['57', '63', '55', '51', '52', '52', '51', '115', '37', '40', '40', '28', '33', '48', '42', '48', '30', '26', '89', '27', '35', '26', '64', '30', '42', '24', '59', '27', '16', '8', '16', '8', '6', '67', '9', '21', '9', '23', '38', '111', '10', '74', '12']
model: gpt3-30b, num requests: 44, total length: 47, prompt/kv_cache length: ['58', '64', '56', '52', '53', '53', '52', '116', '38', '41', '41', '29', '34', '49', '43', '49', '31', '27', '90', '28', '36', '27', '65', '31', '43', '25', '60', '28', '17', '9', '17', '9', '7', '68', '10', '22', '10', '24', '39', '112', '11', '75', '13', '4']
model: gpt3-30b, num requests: 44, total length: 44, prompt/kv_cache length: ['59', '65', '57', '53', '54', '54', '53', '117', '39', '42', '42', '30', '35', '50', '44', '50', '32', '28', '91', '29', '37', '28', '66', '32', '44', '26', '61', '29', '18', '10', '18', '10', '8', '69', '11', '23', '11', '25', '40', '113', '12', '76', '14', '5']
model: gpt3-30b, num requests: 44, total length: 44, prompt/kv_cache length: ['60', '66', '58', '54', '55', '55', '54', '118', '40', '43', '43', '31', '36', '51', '45', '51', '33', '29', '92', '30', '38', '29', '67', '33', '45', '27', '62', '30', '19', '11', '19', '11', '9', '70', '12', '24', '12', '26', '41', '114', '13', '77', '15', '6']
[5.0s] Avg Throughput: propmt: 196, generation: 340
model: gpt3-30b, num requests: 44, total length: 44, prompt/kv_cache length: ['61', '67', '59', '55', '56', '56', '55', '119', '41', '44', '44', '32', '37', '52', '46', '52', '34', '30', '93', '31', '39', '30', '68', '34', '46', '28', '63', '31', '20', '12', '20', '12', '10', '71', '13', '25', '13', '27', '42', '115', '14', '78', '16', '7']
model: gpt3-30b, num requests: 45, total length: 60, prompt/kv_cache length: ['62', '68', '60', '56', '57', '57', '56', '120', '42', '45', '45', '33', '38', '53', '47', '53', '35', '31', '94', '32', '40', '31', '69', '35', '47', '29', '64', '32', '21', '13', '21', '13', '11', '72', '14', '26', '14', '28', '43', '116', '15', '79', '17', '8', '16']
model: gpt3-30b, num requests: 45, total length: 45, prompt/kv_cache length: ['63', '69', '61', '57', '58', '58', '57', '121', '43', '46', '46', '34', '39', '54', '48', '54', '36', '32', '95', '33', '41', '32', '70', '36', '48', '30', '65', '33', '22', '14', '22', '14', '12', '73', '15', '27', '15', '29', '44', '117', '16', '80', '18', '9', '17']
model: gpt3-30b, num requests: 45, total length: 93, prompt/kv_cache length: ['64', '70', '62', '58', '59', '59', '58', '122', '44', '47', '47', '35', '40', '55', '49', '55', '33', '96', '34', '42', '33', '71', '37', '49', '31', '66', '34', '23', '15', '23', '15', '13', '74', '16', '28', '16', '30', '45', '118', '17', '81', '19', '10', '18', '49']
model: gpt3-30b, num requests: 46, total length: 54, prompt/kv_cache length: ['65', '71', '63', '59', '60', '60', '59', '123', '45', '48', '48', '36', '41', '56', '50', '56', '34', '97', '35', '43', '34', '72', '38', '50', '32', '67', '35', '24', '16', '24', '16', '14', '75', '17', '29', '17', '31', '46', '119', '18', '82', '20', '11', '19', '50', '9']
[5.5s] Avg Throughput: propmt: 130, generation: 442
model: gpt3-30b, num requests: 46, total length: 46, prompt/kv_cache length: ['66', '72', '64', '60', '61', '61', '60', '124', '46', '49', '49', '37', '42', '57', '51', '57', '35', '98', '36', '44', '35', '73', '39', '51', '33', '68', '36', '25', '17', '25', '17', '15', '76', '18', '30', '18', '32', '47', '120', '19', '83', '21', '12', '20', '51', '10']
model: gpt3-30b, num requests: 47, total length: 175, prompt/kv_cache length: ['67', '73', '65', '61', '62', '62', '61', '125', '47', '50', '50', '38', '43', '58', '52', '58', '36', '99', '37', '45', '36', '74', '40', '52', '34', '69', '37', '26', '18', '26', '18', '16', '77', '19', '31', '19', '33', '48', '121', '20', '84', '22', '21', '52', '11', '39', '91']
model: gpt3-30b, num requests: 51, total length: 251, prompt/kv_cache length: ['68', '74', '66', '62', '63', '63', '62', '126', '48', '51', '51', '39', '44', '59', '53', '59', '37', '100', '38', '46', '37', '75', '41', '53', '70', '38', '27', '19', '27', '19', '17', '78', '20', '32', '20', '34', '49', '122', '21', '85', '23', '22', '53', '12', '40', '92', '24', '24', '120', '18', '19']
[6.0s] Avg Throughput: propmt: 278, generation: 272
model: gpt3-30b, num requests: 56, total length: 129, prompt/kv_cache length: ['69', '75', '67', '63', '64', '64', '63', '127', '49', '52', '52', '40', '45', '60', '54', '60', '38', '101', '39', '47', '38', '76', '42', '54', '71', '39', '28', '20', '28', '20', '18', '79', '21', '33', '21', '35', '50', '123', '22', '86', '24', '23', '54', '13', '41', '93', '25', '25', '121', '19', '20', '14', '6', '27', '12', '19']
model: gpt3-30b, num requests: 56, total length: 56, prompt/kv_cache length: ['70', '76', '68', '64', '65', '65', '64', '128', '50', '53', '53', '41', '46', '61', '55', '61', '39', '102', '40', '48', '39', '77', '43', '55', '72', '40', '29', '21', '29', '21', '19', '80', '22', '34', '22', '36', '51', '124', '23', '87', '25', '24', '55', '14', '42', '94', '26', '26', '122', '20', '21', '15', '7', '28', '13', '20']
model: gpt3-30b, num requests: 55, total length: 93, prompt/kv_cache length: ['71', '77', '69', '65', '66', '66', '65', '129', '51', '54', '54', '42', '47', '62', '56', '62', '40', '103', '41', '49', '40', '44', '56', '73', '41', '30', '22', '30', '22', '20', '81', '23', '35', '23', '37', '52', '125', '24', '88', '26', '25', '56', '15', '43', '27', '123', '21', '22', '16', '8', '29', '14', '21', '36', '4']
model: gpt3-30b, num requests: 53, total length: 53, prompt/kv_cache length: ['72', '78', '70', '66', '67', '67', '66', '130', '52', '55', '55', '43', '48', '63', '57', '63', '41', '104', '42', '50', '41', '45', '57', '74', '42', '31', '23', '31', '82', '24', '36', '24', '38', '53', '126', '25', '89', '27', '26', '57', '16', '44', '28', '124', '22', '23', '17', '9', '30', '15', '22', '37', '5']
[6.5s] Avg Throughput: propmt: 646, generation: 412
model: gpt3-30b, num requests: 53, total length: 53, prompt/kv_cache length: ['73', '79', '71', '67', '68', '68', '67', '131', '53', '56', '56', '44', '49', '64', '58', '64', '42', '105', '43', '51', '42', '46', '58', '75', '43', '32', '24', '32', '83', '25', '37', '25', '39', '54', '127', '26', '90', '28', '27', '58', '17', '45', '29', '125', '23', '24', '18', '10', '31', '16', '23', '38', '6']
model: gpt3-30b, num requests: 53, total length: 53, prompt/kv_cache length: ['74', '80', '72', '68', '69', '69', '68', '132', '54', '57', '57', '45', '50', '65', '59', '65', '43', '106', '44', '52', '43', '47', '59', '76', '44', '33', '25', '33', '84', '26', '38', '26', '40', '55', '128', '27', '91', '29', '28', '59', '18', '46', '30', '126', '24', '25', '19', '11', '32', '17', '24', '39', '7']
model: gpt3-30b, num requests: 54, total length: 60, prompt/kv_cache length: ['75', '81', '73', '69', '70', '70', '69', '133', '55', '58', '58', '46', '51', '66', '60', '66', '44', '107', '45', '53', '44', '48', '60', '77', '45', '34', '26', '34', '85', '27', '39', '27', '41', '56', '129', '28', '92', '30', '29', '60', '19', '47', '31', '127', '25', '26', '20', '12', '33', '18', '25', '40', '8', '7']
model: gpt3-30b, num requests: 54, total length: 54, prompt/kv_cache length: ['76', '82', '74', '70', '71', '71', '70', '134', '56', '59', '59', '47', '52', '67', '61', '67', '45', '108', '46', '54', '45', '49', '61', '78', '46', '35', '27', '35', '86', '28', '40', '28', '42', '57', '130', '29', '93', '31', '30', '61', '20', '48', '32', '128', '26', '27', '21', '13', '34', '19', '26', '41', '9', '8']
model: gpt3-30b, num requests: 56, total length: 146, prompt/kv_cache length: ['77', '83', '75', '71', '72', '72', '71', '135', '57', '60', '60', '48', '53', '68', '62', '68', '46', '109', '47', '55', '46', '50', '62', '79', '47', '36', '36', '87', '29', '41', '29', '43', '58', '131', '30', '94', '32', '31', '62', '21', '49', '33', '129', '27', '28', '22', '14', '35', '20', '27', '42', '10', '9', '49', '13', '31']
[7.0s] Avg Throughput: propmt: 14, generation: 532
model: gpt3-30b, num requests: 57, total length: 67, prompt/kv_cache length: ['78', '84', '76', '72', '73', '73', '72', '136', '58', '61', '61', '49', '54', '69', '63', '69', '47', '110', '48', '56', '47', '51', '63', '80', '48', '37', '37', '88', '30', '42', '30', '44', '59', '132', '31', '95', '33', '32', '63', '22', '50', '34', '130', '28', '29', '23', '15', '36', '21', '28', '43', '11', '10', '50', '14', '32', '11']
model: gpt3-30b, num requests: 57, total length: 78, prompt/kv_cache length: ['79', '85', '77', '73', '74', '74', '73', '137', '59', '62', '62', '50', '55', '70', '64', '70', '48', '111', '49', '57', '48', '52', '64', '81', '49', '38', '38', '89', '31', '43', '31', '45', '60', '133', '32', '96', '34', '33', '64', '23', '51', '35', '131', '29', '30', '24', '16', '37', '22', '29', '44', '12', '11', '51', '15', '33', '22']
model: gpt3-30b, num requests: 56, total length: 69, prompt/kv_cache length: ['86', '78', '74', '75', '75', '74', '138', '60', '63', '63', '51', '56', '71', '65', '71', '49', '112', '50', '58', '49', '53', '65', '82', '50', '39', '39', '90', '32', '44', '32', '61', '134', '33', '97', '35', '34', '65', '24', '52', '36', '132', '30', '31', '25', '17', '38', '23', '30', '45', '13', '12', '52', '16', '34', '23', '14']
model: gpt3-30b, num requests: 55, total length: 55, prompt/kv_cache length: ['87', '79', '75', '76', '76', '75', '139', '61', '64', '64', '52', '57', '72', '66', '72', '50', '113', '51', '59', '50', '54', '66', '83', '51', '40', '40', '91', '33', '45', '33', '62', '135', '34', '98', '36', '66', '25', '53', '37', '133', '31', '32', '26', '18', '39', '24', '31', '46', '14', '13', '53', '17', '35', '24', '15']
model: gpt3-30b, num requests: 57, total length: 115, prompt/kv_cache length: ['88', '80', '76', '77', '77', '140', '62', '65', '65', '53', '58', '73', '67', '73', '51', '114', '52', '60', '51', '55', '67', '84', '52', '41', '41', '92', '34', '46', '34', '63', '136', '35', '99', '37', '67', '26', '54', '38', '134', '32', '33', '27', '19', '40', '25', '32', '47', '15', '14', '54', '18', '36', '25', '16', '14', '15', '32']
[7.5s] Avg Throughput: propmt: 280, generation: 550
model: gpt3-30b, num requests: 56, total length: 60, prompt/kv_cache length: ['89', '81', '77', '78', '141', '63', '66', '66', '54', '59', '74', '68', '74', '52', '115', '53', '61', '52', '56', '68', '85', '53', '42', '42', '93', '35', '35', '64', '137', '36', '100', '38', '68', '27', '55', '39', '135', '33', '34', '28', '20', '41', '26', '33', '48', '16', '15', '55', '19', '37', '26', '17', '15', '16', '33', '5']
model: gpt3-30b, num requests: 57, total length: 99, prompt/kv_cache length: ['90', '82', '78', '79', '142', '64', '67', '67', '55', '60', '75', '69', '75', '53', '116', '54', '62', '53', '57', '69', '86', '54', '43', '43', '94', '36', '36', '65', '138', '37', '101', '39', '69', '28', '56', '40', '136', '34', '35', '29', '21', '42', '27', '34', '49', '17', '16', '56', '20', '38', '27', '18', '16', '17', '34', '6', '43']
model: gpt3-30b, num requests: 59, total length: 99, prompt/kv_cache length: ['91', '83', '79', '80', '143', '65', '68', '68', '56', '61', '76', '70', '76', '117', '55', '63', '54', '58', '70', '87', '55', '44', '44', '95', '37', '37', '66', '139', '38', '102', '40', '70', '29', '57', '41', '137', '35', '36', '30', '22', '43', '28', '35', '50', '18', '17', '57', '21', '39', '28', '19', '17', '18', '35', '7', '44', '16', '6', '21']
model: gpt3-30b, num requests: 61, total length: 74, prompt/kv_cache length: ['92', '84', '80', '81', '144', '66', '69', '69', '57', '62', '77', '71', '77', '118', '56', '64', '55', '59', '71', '88', '56', '45', '45', '96', '38', '38', '67', '140', '39', '103', '41', '71', '30', '58', '42', '138', '36', '37', '31', '23', '44', '29', '36', '51', '19', '18', '58', '22', '40', '29', '20', '18', '19', '36', '8', '45', '17', '7', '22', '5', '10']
[8.0s] Avg Throughput: propmt: 304, generation: 442
model: gpt3-30b, num requests: 61, total length: 61, prompt/kv_cache length: ['93', '81', '82', '145', '67', '70', '70', '58', '63', '78', '72', '78', '119', '57', '65', '56', '60', '72', '89', '57', '46', '46', '97', '39', '39', '68', '141', '40', '104', '42', '72', '31', '59', '43', '139', '37', '38', '32', '24', '45', '30', '37', '52', '20', '19', '59', '23', '41', '30', '21', '19', '20', '37', '9', '46', '18', '8', '23', '6', '11', '1']
model: gpt3-30b, num requests: 61, total length: 76, prompt/kv_cache length: ['94', '82', '83', '146', '68', '71', '71', '59', '64', '79', '73', '120', '58', '66', '57', '61', '73', '90', '58', '47', '47', '98', '40', '40', '69', '142', '41', '105', '43', '73', '32', '60', '44', '140', '38', '39', '33', '25', '46', '31', '38', '53', '21', '20', '60', '24', '42', '31', '22', '20', '21', '38', '10', '47', '19', '9', '24', '7', '12', '2', '16']
model: gpt3-30b, num requests: 59, total length: 59, prompt/kv_cache length: ['95', '83', '84', '69', '72', '72', '60', '65', '80', '74', '121', '59', '67', '58', '62', '74', '91', '59', '48', '48', '99', '41', '41', '70', '143', '42', '106', '44', '74', '33', '61', '45', '141', '39', '40', '34', '26', '47', '32', '39', '54', '22', '61', '25', '43', '32', '23', '21', '22', '39', '11', '48', '20', '10', '25', '8', '13', '3', '17']
model: gpt3-30b, num requests: 60, total length: 125, prompt/kv_cache length: ['96', '84', '85', '70', '73', '73', '61', '66', '81', '75', '122', '60', '68', '59', '63', '75', '92', '60', '49', '49', '100', '42', '42', '71', '144', '43', '107', '45', '75', '34', '62', '46', '142', '40', '41', '35', '27', '48', '33', '40', '55', '23', '62', '26', '44', '33', '24', '22', '23', '40', '12', '49', '21', '11', '26', '9', '14', '4', '18', '66']
[8.5s] Avg Throughput: propmt: 64, generation: 476
model: gpt3-30b, num requests: 62, total length: 82, prompt/kv_cache length: ['97', '85', '86', '71', '74', '74', '62', '67', '82', '76', '123', '61', '69', '60', '64', '76', '93', '61', '50', '50', '101', '43', '43', '72', '145', '44', '108', '46', '76', '35', '63', '47', '143', '41', '42', '36', '28', '49', '34', '41', '56', '24', '63', '27', '45', '34', '25', '23', '24', '41', '13', '50', '22', '12', '27', '10', '15', '5', '19', '67', '9', '13']
model: gpt3-30b, num requests: 61, total length: 71, prompt/kv_cache length: ['98', '86', '87', '72', '75', '75', '63', '68', '77', '124', '62', '70', '61', '65', '77', '94', '62', '51', '51', '102', '44', '44', '73', '146', '45', '109', '47', '77', '36', '64', '48', '144', '42', '43', '37', '50', '35', '42', '57', '25', '64', '28', '46', '35', '26', '24', '25', '42', '14', '51', '23', '13', '28', '11', '16', '6', '20', '68', '10', '14', '11']
model: gpt3-30b, num requests: 62, total length: 73, prompt/kv_cache length: ['99', '87', '88', '73', '76', '76', '64', '69', '78', '125', '63', '71', '62', '66', '78', '95', '63', '52', '52', '103', '45', '45', '74', '147', '46', '110', '48', '78', '37', '65', '49', '145', '43', '44', '38', '51', '36', '43', '58', '26', '65', '29', '47', '36', '27', '25', '26', '43', '15', '52', '24', '14', '29', '12', '17', '7', '21', '69', '11', '15', '12', '12']
model: gpt3-30b, num requests: 63, total length: 69, prompt/kv_cache length: ['100', '88', '89', '74', '77', '77', '65', '70', '79', '126', '64', '72', '63', '67', '79', '96', '64', '53', '53', '104', '46', '46', '75', '148', '47', '111', '49', '79', '38', '66', '50', '146', '44', '45', '39', '52', '37', '44', '59', '27', '66', '30', '48', '37', '28', '26', '27', '44', '16', '53', '25', '15', '30', '13', '18', '8', '22', '70', '12', '16', '13', '13', '7']
model: gpt3-30b, num requests: 63, total length: 73, prompt/kv_cache length: ['101', '89', '90', '75', '78', '78', '66', '71', '80', '127', '65', '73', '64', '68', '80', '97', '65', '54', '54', '105', '47', '47', '76', '149', '48', '50', '80', '39', '67', '51', '147', '45', '46', '40', '53', '38', '45', '60', '28', '67', '31', '49', '38', '29', '27', '28', '45', '17', '54', '26', '16', '31', '14', '19', '9', '23', '71', '13', '17', '14', '14', '8', '11']
[9.0s] Avg Throughput: propmt: 236, generation: 604
model: gpt3-30b, num requests: 63, total length: 77, prompt/kv_cache length: ['102', '90', '91', '76', '79', '79', '67', '72', '81', '128', '66', '74', '65', '69', '81', '98', '66', '55', '106', '48', '48', '77', '150', '49', '51', '81', '40', '68', '52', '148', '46', '47', '41', '54', '39', '46', '61', '29', '68', '32', '50', '39', '30', '28', '29', '46', '18', '55', '27', '17', '32', '15', '20', '10', '24', '72', '14', '18', '15', '15', '9', '12', '15']
model: gpt3-30b, num requests: 67, total length: 150, prompt/kv_cache length: ['103', '91', '92', '77', '80', '80', '68', '73', '82', '129', '67', '75', '66', '70', '82', '99', '67', '56', '107', '49', '49', '78', '151', '50', '52', '82', '41', '69', '53', '149', '47', '48', '42', '55', '40', '47', '62', '30', '69', '33', '51', '40', '31', '29', '30', '47', '19', '56', '28', '18', '33', '16', '21', '11', '25', '73', '15', '19', '16', '16', '10', '13', '16', '22', '42', '5', '18']
model: gpt3-30b, num requests: 66, total length: 66, prompt/kv_cache length: ['104', '92', '93', '78', '81', '81', '69', '74', '83', '130', '68', '76', '67', '71', '83', '100', '68', '57', '108', '50', '50', '79', '152', '51', '53', '83', '42', '54', '150', '48', '49', '43', '56', '41', '48', '63', '31', '70', '34', '52', '41', '32', '30', '31', '48', '20', '57', '29', '19', '34', '17', '22', '12', '26', '74', '16', '20', '17', '17', '11', '14', '17', '23', '43', '6', '19']
model: gpt3-30b, num requests: 66, total length: 66, prompt/kv_cache length: ['105', '93', '94', '79', '82', '82', '70', '75', '84', '131', '69', '77', '68', '72', '84', '101', '69', '58', '109', '51', '51', '80', '153', '52', '54', '84', '43', '55', '151', '49', '50', '44', '57', '42', '49', '64', '32', '71', '35', '53', '42', '33', '31', '32', '49', '21', '58', '30', '20', '35', '18', '23', '13', '27', '75', '17', '21', '18', '18', '12', '15', '18', '24', '44', '7', '20']
[9.5s] Avg Throughput: propmt: 226, generation: 506
model: gpt3-30b, num requests: 66, total length: 66, prompt/kv_cache length: ['106', '94', '95', '80', '83', '83', '71', '76', '85', '132', '70', '78', '69', '73', '85', '102', '70', '59', '110', '52', '52', '81', '154', '53', '55', '85', '44', '56', '152', '50', '51', '45', '58', '43', '50', '65', '33', '72', '36', '54', '43', '34', '32', '33', '50', '22', '59', '31', '21', '36', '19', '24', '14', '28', '76', '18', '22', '19', '19', '13', '16', '19', '25', '45', '8', '21']
model: gpt3-30b, num requests: 64, total length: 64, prompt/kv_cache length: ['107', '95', '96', '81', '84', '84', '72', '77', '86', '133', '71', '79', '70', '74', '86', '103', '71', '111', '53', '53', '82', '155', '54', '56', '86', '45', '153', '51', '52', '46', '59', '44', '51', '66', '34', '73', '37', '55', '44', '35', '33', '34', '51', '23', '60', '32', '22', '37', '20', '25', '15', '29', '77', '19', '23', '20', '20', '14', '17', '20', '26', '46', '9', '22']
model: gpt3-30b, num requests: 62, total length: 62, prompt/kv_cache length: ['108', '96', '97', '82', '85', '85', '73', '78', '87', '134', '72', '80', '71', '75', '87', '104', '72', '112', '54', '54', '83', '156', '55', '57', '46', '154', '52', '53', '47', '60', '45', '52', '67', '35', '74', '38', '56', '45', '36', '34', '35', '52', '24', '61', '33', '23', '38', '21', '26', '16', '30', '78', '20', '24', '21', '21', '18', '21', '27', '47', '10', '23']
model: gpt3-30b, num requests: 62, total length: 62, prompt/kv_cache length: ['109', '97', '98', '83', '86', '86', '74', '79', '88', '135', '73', '81', '72', '76', '88', '105', '73', '113', '55', '55', '84', '157', '56', '58', '47', '155', '53', '54', '48', '61', '46', '53', '68', '36', '75', '39', '57', '46', '37', '35', '36', '53', '25', '62', '34', '24', '39', '22', '27', '17', '31', '79', '21', '25', '22', '22', '19', '22', '28', '48', '11', '24']
model: gpt3-30b, num requests: 61, total length: 61, prompt/kv_cache length: ['110', '98', '84', '87', '87', '75', '80', '89', '136', '74', '82', '73', '77', '89', '106', '74', '114', '56', '56', '85', '158', '57', '59', '48', '156', '54', '55', '49', '62', '47', '54', '69', '37', '76', '40', '58', '47', '38', '36', '37', '54', '26', '63', '35', '25', '40', '23', '28', '18', '32', '80', '22', '26', '23', '23', '20', '23', '29', '49', '12', '25']
[10.0s] Avg Throughput: propmt: 0, generation: 640
model: gpt3-30b, num requests: 60, total length: 60, prompt/kv_cache length: ['111', '99', '85', '88', '88', '76', '81', '90', '137', '75', '83', '74', '78', '90', '107', '75', '115', '57', '57', '86', '159', '58', '60', '49', '157', '55', '56', '50', '63', '48', '55', '70', '38', '77', '41', '59', '48', '39', '37', '38', '55', '27', '64', '36', '26', '41', '24', '29', '19', '33', '81', '27', '24', '24', '21', '24', '30', '50', '13', '26']
model: gpt3-30b, num requests: 60, total length: 60, prompt/kv_cache length: ['112', '100', '86', '89', '89', '77', '82', '91', '138', '76', '84', '75', '79', '91', '108', '76', '116', '58', '58', '87', '160', '59', '61', '50', '158', '56', '57', '51', '64', '49', '56', '71', '39', '78', '42', '60', '49', '40', '38', '39', '56', '28', '65', '37', '27', '42', '25', '30', '20', '34', '82', '28', '25', '25', '22', '25', '31', '51', '14', '27']
model: gpt3-30b, num requests: 60, total length: 60, prompt/kv_cache length: ['113', '101', '87', '90', '90', '78', '83', '92', '139', '77', '85', '76', '80', '92', '109', '77', '117', '59', '59', '88', '161', '60', '62', '51', '159', '57', '58', '52', '65', '50', '57', '72', '40', '79', '43', '61', '50', '41', '39', '40', '57', '29', '66', '38', '28', '43', '26', '31', '21', '35', '83', '29', '26', '26', '23', '26', '32', '52', '15', '28']
model: gpt3-30b, num requests: 60, total length: 60, prompt/kv_cache length: ['114', '102', '88', '91', '91', '79', '84', '93', '140', '78', '86', '77', '81', '93', '110', '78', '118', '60', '60', '89', '162', '61', '63', '52', '160', '58', '59', '53', '66', '51', '58', '73', '41', '80', '44', '62', '51', '42', '40', '41', '58', '30', '67', '39', '29', '44', '27', '32', '22', '36', '84', '30', '27', '27', '24', '27', '33', '53', '16', '29']
model: gpt3-30b, num requests: 60, total length: 60, prompt/kv_cache length: ['115', '103', '89', '92', '92', '80', '85', '94', '141', '79', '87', '78', '82', '94', '111', '79', '119', '61', '61', '90', '163', '62', '64', '53', '161', '59', '60', '54', '67', '52', '59', '74', '42', '81', '45', '63', '52', '43', '41', '42', '59', '31', '68', '40', '30', '45', '28', '33', '23', '37', '85', '31', '28', '28', '25', '28', '34', '54', '17', '30']
model: gpt3-30b, num requests: 60, total length: 60, prompt/kv_cache length: ['116', '104', '90', '93', '93', '81', '86', '95', '142', '80', '88', '79', '83', '95', '112', '80', '120', '62', '62', '91', '164', '63', '65', '54', '162', '60', '61', '55', '68', '53', '60', '75', '43', '82', '46', '64', '53', '44', '42', '43', '60', '32', '69', '41', '31', '46', '29', '34', '24', '38', '86', '32', '29', '29', '26', '29', '35', '55', '18', '31']
[10.5s] Avg Throughput: propmt: 0, generation: 722
model: gpt3-30b, num requests: 59, total length: 59, prompt/kv_cache length: ['117', '105', '91', '94', '94', '82', '87', '96', '143', '81', '89', '80', '84', '96', '113', '81', '121', '63', '63', '92', '165', '64', '66', '55', '163', '61', '62', '56', '69', '54', '61', '76', '44', '83', '47', '65', '54', '45', '43', '44', '61', '33', '70', '42', '32', '47', '30', '35', '39', '87', '33', '30', '30', '27', '30', '36', '56', '19', '32']
model: gpt3-30b, num requests: 59, total length: 59, prompt/kv_cache length: ['118', '106', '92', '95', '95', '83', '88', '97', '144', '82', '90', '81', '85', '97', '114', '82', '122', '64', '64', '93', '166', '65', '67', '56', '164', '62', '63', '57', '70', '55', '62', '77', '45', '84', '48', '66', '55', '46', '44', '45', '62', '34', '71', '43', '33', '48', '31', '36', '40', '88', '34', '31', '31', '28', '31', '37', '57', '20', '33']
model: gpt3-30b, num requests: 59, total length: 59, prompt/kv_cache length: ['119', '107', '93', '96', '96', '84', '89', '98', '145', '83', '91', '82', '86', '98', '115', '83', '123', '65', '65', '94', '167', '66', '68', '57', '165', '63', '64', '58', '71', '56', '63', '78', '46', '85', '49', '67', '56', '47', '45', '46', '63', '35', '72', '44', '34', '49', '32', '37', '41', '89', '35', '32', '32', '29', '32', '38', '58', '21', '34']
model: gpt3-30b, num requests: 58, total length: 58, prompt/kv_cache length: ['120', '108', '94', '97', '97', '85', '90', '99', '146', '84', '92', '83', '87', '99', '116', '124', '66', '66', '95', '168', '67', '69', '58', '166', '64', '65', '59', '72', '57', '64', '79', '47', '86', '50', '68', '57', '48', '46', '47', '64', '36', '73', '45', '35', '50', '33', '38', '42', '90', '36', '33', '33', '30', '33', '39', '59', '22', '35']
model: gpt3-30b, num requests: 57, total length: 57, prompt/kv_cache length: ['121', '95', '98', '98', '86', '91', '100', '147', '85', '93', '84', '88', '100', '117', '125', '67', '67', '96', '169', '68', '70', '59', '167', '65', '66', '60', '73', '58', '65', '80', '48', '87', '51', '69', '58', '49', '47', '48', '65', '37', '74', '46', '36', '51', '34', '39', '43', '91', '37', '34', '34', '31', '34', '40', '60', '23', '36']
[11.0s] Avg Throughput: propmt: 0, generation: 590
model: gpt3-30b, num requests: 57, total length: 57, prompt/kv_cache length: ['122', '96', '99', '99', '87', '92', '101', '148', '86', '94', '85', '89', '101', '118', '126', '68', '68', '97', '170', '69', '71', '60', '168', '66', '67', '61', '74', '59', '66', '81', '49', '88', '52', '70', '59', '50', '48', '49', '66', '38', '75', '47', '37', '52', '35', '40', '44', '92', '38', '35', '35', '32', '35', '41', '61', '24', '37']
model: gpt3-30b, num requests: 56, total length: 56, prompt/kv_cache length: ['123', '97', '100', '88', '93', '102', '149', '87', '95', '86', '90', '102', '119', '127', '69', '69', '98', '171', '70', '72', '61', '169', '67', '68', '62', '75', '60', '67', '82', '50', '89', '53', '71', '60', '51', '49', '50', '67', '39', '76', '48', '38', '53', '36', '41', '45', '93', '39', '36', '36', '33', '36', '42', '62', '25', '38']
model: gpt3-30b, num requests: 55, total length: 55, prompt/kv_cache length: ['124', '98', '101', '89', '94', '103', '150', '88', '96', '87', '91', '103', '120', '128', '70', '70', '99', '172', '71', '73', '62', '170', '68', '69', '63', '76', '61', '68', '83', '51', '90', '54', '72', '61', '52', '50', '51', '68', '40', '77', '49', '39', '54', '37', '42', '46', '40', '37', '37', '34', '37', '43', '63', '26', '39']
model: gpt3-30b, num requests: 53, total length: 53, prompt/kv_cache length: ['125', '102', '90', '95', '104', '151', '89', '97', '88', '92', '104', '121', '129', '71', '100', '173', '72', '74', '63', '171', '69', '70', '64', '77', '62', '69', '84', '52', '91', '55', '73', '62', '53', '51', '52', '69', '41', '78', '50', '40', '55', '38', '43', '47', '41', '38', '38', '35', '38', '44', '64', '27', '40']
model: gpt3-30b, num requests: 52, total length: 52, prompt/kv_cache length: ['103', '91', '96', '105', '152', '90', '98', '89', '93', '105', '122', '130', '72', '101', '174', '73', '75', '64', '172', '70', '71', '65', '78', '63', '70', '85', '53', '92', '56', '74', '63', '54', '52', '53', '70', '42', '79', '51', '41', '56', '39', '44', '48', '42', '39', '39', '36', '39', '45', '65', '28', '41']
[11.5s] Avg Throughput: propmt: 0, generation: 556
model: gpt3-30b, num requests: 52, total length: 52, prompt/kv_cache length: ['104', '92', '97', '106', '153', '91', '99', '90', '94', '106', '123', '131', '73', '102', '175', '74', '76', '65', '173', '71', '72', '66', '79', '64', '71', '86', '54', '93', '57', '75', '64', '55', '53', '54', '71', '43', '80', '52', '42', '57', '40', '45', '49', '43', '40', '40', '37', '40', '46', '66', '29', '42']
model: gpt3-30b, num requests: 51, total length: 51, prompt/kv_cache length: ['105', '93', '98', '107', '154', '92', '100', '95', '107', '124', '132', '74', '103', '176', '75', '77', '66', '174', '72', '73', '67', '80', '65', '72', '87', '55', '94', '58', '76', '65', '56', '54', '55', '72', '44', '81', '53', '43', '58', '41', '46', '50', '44', '41', '41', '38', '41', '47', '67', '30', '43']
model: gpt3-30b, num requests: 51, total length: 51, prompt/kv_cache length: ['106', '94', '99', '108', '155', '93', '101', '96', '108', '125', '133', '75', '104', '177', '76', '78', '67', '175', '73', '74', '68', '81', '66', '73', '88', '56', '95', '59', '77', '66', '57', '55', '56', '73', '45', '82', '54', '44', '59', '42', '47', '51', '45', '42', '42', '39', '42', '48', '68', '31', '44']
model: gpt3-30b, num requests: 51, total length: 51, prompt/kv_cache length: ['107', '95', '100', '109', '156', '94', '102', '97', '109', '126', '134', '76', '105', '178', '77', '79', '68', '176', '74', '75', '69', '82', '67', '74', '89', '57', '96', '60', '78', '67', '58', '56', '57', '74', '46', '83', '55', '45', '60', '43', '48', '52', '46', '43', '43', '40', '43', '49', '69', '32', '45']
model: gpt3-30b, num requests: 50, total length: 50, prompt/kv_cache length: ['108', '96', '101', '110', '157', '103', '98', '110', '127', '135', '77', '106', '179', '78', '80', '69', '177', '75', '76', '70', '83', '68', '75', '90', '58', '97', '61', '79', '68', '59', '57', '58', '75', '47', '84', '56', '46', '61', '44', '49', '53', '47', '44', '44', '41', '44', '50', '70', '33', '46']
model: gpt3-30b, num requests: 50, total length: 50, prompt/kv_cache length: ['109', '97', '102', '111', '158', '104', '99', '111', '128', '136', '78', '107', '180', '79', '81', '70', '178', '76', '77', '71', '84', '69', '76', '91', '59', '98', '62', '80', '69', '60', '58', '59', '76', '48', '85', '57', '47', '62', '45', '50', '54', '48', '45', '45', '42', '45', '51', '71', '34', '47']
[12.0s] Avg Throughput: propmt: 0, generation: 614
model: gpt3-30b, num requests: 50, total length: 50, prompt/kv_cache length: ['110', '98', '103', '112', '159', '105', '100', '112', '129', '137', '79', '108', '181', '80', '82', '71', '179', '77', '78', '72', '85', '70', '77', '92', '60', '99', '63', '81', '70', '61', '59', '60', '77', '49', '86', '58', '48', '63', '46', '51', '55', '49', '46', '46', '43', '46', '52', '72', '35', '48']
model: gpt3-30b, num requests: 50, total length: 50, prompt/kv_cache length: ['111', '99', '104', '113', '160', '106', '101', '113', '130', '138', '80', '109', '182', '81', '83', '72', '180', '78', '79', '73', '86', '71', '78', '93', '61', '100', '64', '82', '71', '62', '60', '61', '78', '50', '87', '59', '49', '64', '47', '52', '56', '50', '47', '47', '44', '47', '53', '73', '36', '49']
model: gpt3-30b, num requests: 50, total length: 50, prompt/kv_cache length: ['112', '100', '105', '114', '161', '107', '102', '114', '131', '139', '81', '110', '183', '82', '84', '73', '181', '79', '80', '74', '87', '72', '79', '94', '62', '101', '65', '83', '72', '63', '61', '62', '79', '51', '88', '60', '50', '65', '48', '53', '57', '51', '48', '48', '45', '48', '54', '74', '37', '50']
model: gpt3-30b, num requests: 47, total length: 47, prompt/kv_cache length: ['101', '106', '115', '162', '108', '103', '115', '132', '140', '82', '111', '184', '83', '74', '182', '80', '81', '75', '88', '73', '95', '63', '102', '66', '84', '73', '64', '62', '63', '80', '52', '89', '61', '51', '66', '49', '54', '58', '52', '49', '49', '46', '49', '55', '75', '38', '51']
model: gpt3-30b, num requests: 47, total length: 47, prompt/kv_cache length: ['102', '107', '116', '163', '109', '104', '116', '133', '141', '83', '112', '185', '84', '75', '183', '81', '82', '76', '89', '74', '96', '64', '103', '67', '85', '74', '65', '63', '64', '81', '53', '90', '62', '52', '67', '50', '55', '59', '53', '50', '50', '47', '50', '56', '76', '39', '52']
model: gpt3-30b, num requests: 47, total length: 47, prompt/kv_cache length: ['103', '108', '117', '164', '110', '105', '117', '134', '142', '84', '113', '186', '85', '76', '184', '82', '83', '77', '90', '75', '97', '65', '104', '68', '86', '75', '66', '64', '65', '82', '54', '91', '63', '53', '68', '51', '56', '60', '54', '51', '51', '48', '51', '57', '77', '40', '53']
[12.5s] Avg Throughput: propmt: 0, generation: 588
model: gpt3-30b, num requests: 45, total length: 45, prompt/kv_cache length: ['104', '109', '118', '165', '111', '106', '118', '135', '143', '85', '114', '187', '86', '77', '185', '83', '84', '78', '91', '76', '98', '69', '87', '76', '67', '65', '66', '83', '55', '92', '64', '54', '69', '52', '57', '61', '55', '52', '52', '49', '52', '58', '78', '41', '54']
model: gpt3-30b, num requests: 45, total length: 45, prompt/kv_cache length: ['105', '110', '119', '166', '112', '107', '119', '136', '144', '86', '115', '188', '87', '78', '186', '84', '85', '79', '92', '77', '99', '70', '88', '77', '68', '66', '67', '84', '56', '93', '65', '55', '70', '53', '58', '62', '56', '53', '53', '50', '53', '59', '79', '42', '55']
model: gpt3-30b, num requests: 45, total length: 45, prompt/kv_cache length: ['106', '111', '120', '167', '113', '108', '120', '137', '145', '87', '116', '189', '88', '79', '187', '85', '86', '80', '93', '78', '100', '71', '89', '78', '69', '67', '68', '85', '57', '94', '66', '56', '71', '54', '59', '63', '57', '54', '54', '51', '54', '60', '80', '43', '56']
model: gpt3-30b, num requests: 44, total length: 44, prompt/kv_cache length: ['112', '121', '168', '114', '109', '121', '138', '146', '88', '117', '190', '89', '80', '188', '86', '87', '81', '94', '79', '101', '72', '90', '79', '70', '68', '69', '86', '58', '95', '67', '57', '72', '55', '60', '64', '58', '55', '55', '52', '55', '61', '81', '44', '57']
model: gpt3-30b, num requests: 43, total length: 43, prompt/kv_cache length: ['113', '122', '169', '115', '110', '122', '139', '147', '89', '118', '191', '81', '189', '87', '88', '82', '95', '80', '102', '73', '91', '80', '71', '69', '70', '87', '59', '96', '68', '58', '73', '56', '61', '65', '59', '56', '56', '53', '56', '62', '82', '45', '58']
[13.0s] Avg Throughput: propmt: 0, generation: 452
model: gpt3-30b, num requests: 43, total length: 43, prompt/kv_cache length: ['114', '123', '170', '116', '111', '123', '140', '148', '90', '119', '192', '82', '190', '88', '89', '83', '96', '81', '103', '74', '92', '81', '72', '70', '71', '88', '60', '97', '69', '59', '74', '57', '62', '66', '60', '57', '57', '54', '57', '63', '83', '46', '59']
model: gpt3-30b, num requests: 42, total length: 42, prompt/kv_cache length: ['115', '124', '171', '112', '124', '141', '149', '91', '120', '193', '83', '191', '89', '90', '84', '97', '82', '104', '75', '93', '82', '73', '71', '72', '89', '61', '98', '70', '60', '75', '58', '63', '67', '61', '58', '58', '55', '58', '64', '84', '47', '60']
model: gpt3-30b, num requests: 41, total length: 41, prompt/kv_cache length: ['116', '125', '172', '113', '125', '142', '92', '121', '194', '84', '192', '90', '91', '85', '98', '83', '105', '76', '94', '83', '74', '72', '73', '90', '62', '99', '71', '61', '76', '59', '64', '68', '62', '59', '59', '56', '59', '65', '85', '48', '61']
model: gpt3-30b, num requests: 40, total length: 40, prompt/kv_cache length: ['117', '126', '173', '114', '126', '143', '93', '122', '195', '85', '193', '91', '86', '99', '84', '106', '77', '95', '84', '75', '73', '74', '91', '63', '100', '72', '62', '77', '60', '65', '69', '63', '60', '60', '57', '60', '66', '86', '49', '62']
model: gpt3-30b, num requests: 39, total length: 39, prompt/kv_cache length: ['118', '127', '174', '115', '127', '144', '94', '123', '196', '86', '194', '92', '100', '85', '107', '78', '96', '85', '76', '74', '75', '92', '64', '101', '73', '63', '78', '61', '66', '70', '64', '61', '61', '58', '61', '67', '87', '50', '63']
model: gpt3-30b, num requests: 39, total length: 39, prompt/kv_cache length: ['119', '128', '175', '116', '128', '145', '95', '124', '197', '87', '195', '93', '101', '86', '108', '79', '97', '86', '77', '75', '76', '93', '65', '102', '74', '64', '79', '62', '67', '71', '65', '62', '62', '59', '62', '68', '88', '51', '64']
[13.5s] Avg Throughput: propmt: 0, generation: 496
model: gpt3-30b, num requests: 37, total length: 37, prompt/kv_cache length: ['120', '129', '176', '117', '146', '96', '125', '198', '88', '196', '94', '102', '87', '109', '80', '87', '78', '76', '77', '94', '66', '103', '75', '65', '80', '63', '68', '72', '66', '63', '63', '60', '63', '69', '89', '52', '65']
model: gpt3-30b, num requests: 37, total length: 37, prompt/kv_cache length: ['121', '130', '177', '118', '147', '97', '126', '199', '89', '197', '95', '103', '88', '110', '81', '88', '79', '77', '78', '95', '67', '104', '76', '66', '81', '64', '69', '73', '67', '64', '64', '61', '64', '70', '90', '53', '66']
model: gpt3-30b, num requests: 37, total length: 37, prompt/kv_cache length: ['122', '131', '178', '119', '148', '98', '127', '200', '90', '198', '96', '104', '89', '111', '82', '89', '80', '78', '79', '96', '68', '105', '77', '67', '82', '65', '70', '74', '68', '65', '65', '62', '65', '71', '91', '54', '67']
model: gpt3-30b, num requests: 37, total length: 37, prompt/kv_cache length: ['123', '132', '179', '120', '149', '99', '128', '201', '91', '199', '97', '105', '90', '112', '83', '90', '81', '79', '80', '97', '69', '106', '78', '68', '83', '66', '71', '75', '69', '66', '66', '63', '66', '72', '92', '55', '68']
model: gpt3-30b, num requests: 37, total length: 37, prompt/kv_cache length: ['124', '133', '180', '121', '150', '100', '129', '202', '92', '200', '98', '106', '91', '113', '84', '91', '82', '80', '81', '98', '70', '107', '79', '69', '84', '67', '72', '76', '70', '67', '67', '64', '67', '73', '93', '56', '69']
model: gpt3-30b, num requests: 34, total length: 34, prompt/kv_cache length: ['125', '134', '122', '151', '101', '130', '203', '201', '99', '107', '92', '114', '85', '92', '83', '81', '82', '99', '71', '108', '80', '70', '85', '68', '73', '71', '68', '68', '65', '68', '74', '94', '57', '70']
[14.0s] Avg Throughput: propmt: 0, generation: 448
model: gpt3-30b, num requests: 34, total length: 34, prompt/kv_cache length: ['126', '135', '123', '152', '102', '131', '204', '202', '100', '108', '93', '115', '86', '93', '84', '82', '83', '100', '72', '109', '81', '71', '86', '69', '74', '72', '69', '69', '66', '69', '75', '95', '58', '71']
model: gpt3-30b, num requests: 32, total length: 32, prompt/kv_cache length: ['136', '124', '153', '103', '132', '205', '203', '101', '109', '94', '116', '87', '85', '83', '84', '101', '73', '110', '82', '72', '87', '70', '75', '73', '70', '70', '67', '70', '76', '96', '59', '72']
model: gpt3-30b, num requests: 32, total length: 32, prompt/kv_cache length: ['137', '125', '154', '104', '133', '206', '204', '102', '110', '95', '117', '88', '86', '84', '85', '102', '74', '111', '83', '73', '88', '71', '76', '74', '71', '71', '68', '71', '77', '97', '60', '73']
model: gpt3-30b, num requests: 31, total length: 31, prompt/kv_cache length: ['138', '126', '105', '134', '207', '205', '103', '111', '96', '118', '89', '87', '85', '86', '103', '75', '112', '84', '74', '89', '72', '77', '75', '72', '72', '69', '72', '78', '98', '61', '74']
model: gpt3-30b, num requests: 31, total length: 31, prompt/kv_cache length: ['139', '127', '106', '135', '208', '206', '104', '112', '97', '119', '90', '88', '86', '87', '104', '76', '113', '85', '75', '90', '73', '78', '76', '73', '73', '70', '73', '79', '99', '62', '75']
model: gpt3-30b, num requests: 29, total length: 29, prompt/kv_cache length: ['128', '107', '136', '209', '207', '105', '113', '98', '120', '91', '89', '88', '105', '77', '114', '86', '76', '91', '74', '79', '77', '74', '74', '71', '74', '80', '100', '63', '76']
model: gpt3-30b, num requests: 29, total length: 29, prompt/kv_cache length: ['129', '108', '137', '210', '208', '106', '114', '99', '121', '92', '90', '89', '106', '78', '115', '87', '77', '92', '75', '80', '78', '75', '75', '72', '75', '81', '101', '64', '77']
[14.5s] Avg Throughput: propmt: 0, generation: 446
model: gpt3-30b, num requests: 29, total length: 29, prompt/kv_cache length: ['130', '109', '138', '211', '209', '107', '115', '100', '122', '93', '91', '90', '107', '79', '116', '88', '78', '93', '76', '81', '79', '76', '76', '73', '76', '82', '102', '65', '78']
model: gpt3-30b, num requests: 28, total length: 28, prompt/kv_cache length: ['110', '139', '212', '210', '108', '116', '101', '123', '94', '92', '91', '108', '80', '117', '89', '79', '94', '77', '82', '80', '77', '77', '74', '77', '83', '103', '66', '79']
model: gpt3-30b, num requests: 27, total length: 27, prompt/kv_cache length: ['111', '140', '211', '109', '117', '102', '124', '95', '93', '92', '109', '81', '118', '90', '80', '95', '78', '83', '81', '78', '78', '75', '78', '84', '104', '67', '80']
model: gpt3-30b, num requests: 27, total length: 27, prompt/kv_cache length: ['112', '141', '212', '110', '118', '103', '125', '96', '94', '93', '110', '82', '119', '91', '81', '96', '79', '84', '82', '79', '79', '76', '79', '85', '105', '68', '81']
model: gpt3-30b, num requests: 27, total length: 27, prompt/kv_cache length: ['113', '142', '213', '111', '119', '104', '126', '97', '95', '94', '111', '83', '120', '92', '82', '97', '80', '85', '83', '80', '80', '77', '80', '86', '106', '69', '82']
model: gpt3-30b, num requests: 25, total length: 25, prompt/kv_cache length: ['114', '143', '214', '112', '120', '105', '98', '96', '112', '84', '121', '93', '83', '98', '81', '86', '84', '81', '81', '78', '81', '87', '107', '70', '83']
[15.0s] Avg Throughput: propmt: 0, generation: 334
model: gpt3-30b, num requests: 25, total length: 25, prompt/kv_cache length: ['115', '144', '215', '113', '121', '106', '99', '97', '113', '85', '122', '94', '84', '99', '82', '87', '85', '82', '82', '79', '82', '88', '108', '71', '84']
model: gpt3-30b, num requests: 25, total length: 25, prompt/kv_cache length: ['116', '145', '216', '114', '122', '107', '100', '98', '114', '86', '123', '95', '85', '100', '83', '88', '86', '83', '83', '80', '83', '89', '109', '72', '85']
model: gpt3-30b, num requests: 25, total length: 25, prompt/kv_cache length: ['117', '146', '217', '115', '123', '108', '101', '99', '115', '87', '124', '96', '86', '101', '84', '89', '87', '84', '84', '81', '84', '90', '110', '73', '86']
model: gpt3-30b, num requests: 24, total length: 24, prompt/kv_cache length: ['118', '147', '218', '116', '124', '109', '102', '100', '116', '88', '125', '97', '87', '102', '85', '90', '88', '85', '85', '82', '85', '91', '111', '87']
model: gpt3-30b, num requests: 24, total length: 24, prompt/kv_cache length: ['119', '148', '219', '117', '125', '110', '103', '101', '117', '89', '126', '98', '88', '103', '86', '91', '89', '86', '86', '83', '86', '92', '112', '88']
model: gpt3-30b, num requests: 24, total length: 24, prompt/kv_cache length: ['120', '149', '220', '118', '126', '111', '104', '102', '118', '90', '127', '99', '89', '104', '87', '92', '90', '87', '87', '84', '87', '93', '113', '89']
model: gpt3-30b, num requests: 24, total length: 24, prompt/kv_cache length: ['121', '150', '221', '119', '127', '112', '105', '103', '119', '91', '128', '100', '90', '105', '88', '93', '91', '88', '88', '85', '88', '94', '114', '90']
[15.5s] Avg Throughput: propmt: 0, generation: 344
model: gpt3-30b, num requests: 24, total length: 24, prompt/kv_cache length: ['122', '151', '222', '120', '128', '113', '106', '104', '120', '92', '129', '101', '91', '106', '89', '94', '92', '89', '89', '86', '89', '95', '115', '91']
model: gpt3-30b, num requests: 24, total length: 24, prompt/kv_cache length: ['123', '152', '223', '121', '129', '114', '107', '105', '121', '93', '130', '102', '92', '107', '90', '95', '93', '90', '90', '87', '90', '96', '116', '92']
model: gpt3-30b, num requests: 22, total length: 22, prompt/kv_cache length: ['153', '224', '130', '115', '108', '106', '122', '94', '131', '103', '93', '108', '91', '96', '94', '91', '91', '88', '91', '97', '117', '93']
model: gpt3-30b, num requests: 22, total length: 22, prompt/kv_cache length: ['154', '225', '131', '116', '109', '107', '123', '95', '132', '104', '94', '109', '92', '97', '95', '92', '92', '89', '92', '98', '118', '94']
model: gpt3-30b, num requests: 21, total length: 21, prompt/kv_cache length: ['155', '226', '132', '117', '110', '108', '124', '133', '105', '95', '110', '93', '98', '96', '93', '93', '90', '93', '99', '119', '95']
model: gpt3-30b, num requests: 20, total length: 20, prompt/kv_cache length: ['156', '227', '133', '118', '111', '109', '125', '134', '106', '96', '94', '99', '97', '94', '94', '91', '94', '100', '120', '96']
[16.0s] Avg Throughput: propmt: 0, generation: 274
model: gpt3-30b, num requests: 20, total length: 20, prompt/kv_cache length: ['157', '228', '134', '119', '112', '110', '126', '135', '107', '97', '95', '100', '98', '95', '95', '92', '95', '101', '121', '97']
model: gpt3-30b, num requests: 18, total length: 18, prompt/kv_cache length: ['158', '229', '113', '111', '127', '136', '108', '98', '96', '101', '99', '96', '96', '93', '96', '102', '122', '98']
model: gpt3-30b, num requests: 18, total length: 18, prompt/kv_cache length: ['159', '230', '114', '112', '128', '137', '109', '99', '97', '102', '100', '97', '97', '94', '97', '103', '123', '99']
model: gpt3-30b, num requests: 18, total length: 18, prompt/kv_cache length: ['160', '231', '115', '113', '129', '138', '110', '100', '98', '103', '101', '98', '98', '95', '98', '104', '124', '100']
model: gpt3-30b, num requests: 18, total length: 18, prompt/kv_cache length: ['161', '232', '116', '114', '130', '139', '111', '101', '99', '104', '102', '99', '99', '96', '99', '105', '125', '101']
model: gpt3-30b, num requests: 16, total length: 16, prompt/kv_cache length: ['233', '117', '115', '131', '140', '112', '102', '100', '105', '103', '100', '100', '97', '100', '126', '102']
model: gpt3-30b, num requests: 16, total length: 16, prompt/kv_cache length: ['234', '118', '116', '132', '141', '113', '103', '101', '106', '104', '101', '101', '98', '101', '127', '103']
[16.5s] Avg Throughput: propmt: 0, generation: 256
model: gpt3-30b, num requests: 16, total length: 16, prompt/kv_cache length: ['235', '119', '117', '133', '142', '114', '104', '102', '107', '105', '102', '102', '99', '102', '128', '104']
model: gpt3-30b, num requests: 15, total length: 15, prompt/kv_cache length: ['236', '120', '118', '134', '143', '105', '103', '108', '106', '103', '103', '100', '103', '129', '105']
model: gpt3-30b, num requests: 15, total length: 15, prompt/kv_cache length: ['237', '121', '119', '135', '144', '106', '104', '109', '107', '104', '104', '101', '104', '130', '106']
model: gpt3-30b, num requests: 14, total length: 14, prompt/kv_cache length: ['122', '120', '136', '145', '107', '105', '110', '108', '105', '105', '102', '105', '131', '107']
model: gpt3-30b, num requests: 13, total length: 13, prompt/kv_cache length: ['123', '121', '137', '146', '108', '111', '109', '106', '106', '103', '106', '132', '108']
model: gpt3-30b, num requests: 13, total length: 13, prompt/kv_cache length: ['124', '122', '138', '147', '109', '112', '110', '107', '107', '104', '107', '133', '109']
model: gpt3-30b, num requests: 12, total length: 12, prompt/kv_cache length: ['125', '123', '139', '148', '110', '113', '111', '108', '105', '108', '134', '110']
model: gpt3-30b, num requests: 12, total length: 12, prompt/kv_cache length: ['126', '124', '140', '149', '111', '114', '112', '109', '106', '109', '135', '111']
[17.0s] Avg Throughput: propmt: 0, generation: 228
model: gpt3-30b, num requests: 12, total length: 12, prompt/kv_cache length: ['127', '125', '141', '150', '112', '115', '113', '110', '107', '110', '136', '112']
model: gpt3-30b, num requests: 11, total length: 11, prompt/kv_cache length: ['128', '126', '151', '113', '116', '114', '111', '108', '111', '137', '113']
model: gpt3-30b, num requests: 11, total length: 11, prompt/kv_cache length: ['129', '127', '152', '114', '117', '115', '112', '109', '112', '138', '114']
model: gpt3-30b, num requests: 11, total length: 11, prompt/kv_cache length: ['130', '128', '153', '115', '118', '116', '113', '110', '113', '139', '115']
model: gpt3-30b, num requests: 11, total length: 11, prompt/kv_cache length: ['131', '129', '154', '116', '119', '117', '114', '111', '114', '140', '116']
model: gpt3-30b, num requests: 9, total length: 9, prompt/kv_cache length: ['132', '155', '117', '118', '115', '112', '115', '141', '117']
model: gpt3-30b, num requests: 8, total length: 8, prompt/kv_cache length: ['133', '156', '118', '119', '116', '116', '142', '118']
[17.5s] Avg Throughput: propmt: 0, generation: 154
model: gpt3-30b, num requests: 7, total length: 7, prompt/kv_cache length: ['134', '157', '119', '120', '117', '143', '119']
model: gpt3-30b, num requests: 6, total length: 6, prompt/kv_cache length: ['135', '158', '120', '121', '144', '120']
model: gpt3-30b, num requests: 6, total length: 6, prompt/kv_cache length: ['136', '159', '121', '122', '145', '121']
model: gpt3-30b, num requests: 5, total length: 5, prompt/kv_cache length: ['137', '160', '122', '146', '122']
model: gpt3-30b, num requests: 5, total length: 5, prompt/kv_cache length: ['138', '161', '123', '147', '123']
model: gpt3-30b, num requests: 5, total length: 5, prompt/kv_cache length: ['139', '162', '124', '148', '124']
model: gpt3-30b, num requests: 4, total length: 4, prompt/kv_cache length: ['163', '125', '149', '125']
model: gpt3-30b, num requests: 2, total length: 2, prompt/kv_cache length: ['126', '150']
[18.0s] Avg Throughput: propmt: 0, generation: 92
model: gpt3-30b, num requests: 2, total length: 2, prompt/kv_cache length: ['127', '151']
model: gpt3-30b, num requests: 2, total length: 2, prompt/kv_cache length: ['128', '152']
model: gpt3-30b, num requests: 2, total length: 2, prompt/kv_cache length: ['129', '153']
model: gpt3-30b, num requests: 2, total length: 2, prompt/kv_cache length: ['130', '154']
model: gpt3-30b, num requests: 1, total length: 1, prompt/kv_cache length: ['131']
[18.5s] Avg Throughput: propmt: 0, generation: 22
---------------------------
Exiting The Simulator
Memory Is All Freed
Checking Non-Exited Systems ...
---------------------------
All Request Has Been Exited
---------------------------
{'id': 3, 'model': 'gpt3-30b', 'input': 4, 'output': 16, 'arrival': 570907776, 'end_time': 1601378806, 'latency': 1030471030}
{'id': 7, 'model': 'gpt3-30b', 'input': 2, 'output': 11, 'arrival': 811936856, 'end_time': 1601378806, 'latency': 789441950}
{'id': 21, 'model': 'gpt3-30b', 'input': 10, 'output': 20, 'arrival': 1933551216, 'end_time': 3034062860, 'latency': 1100511644}
{'id': 25, 'model': 'gpt3-30b', 'input': 10, 'output': 20, 'arrival': 2228417559, 'end_time': 3284445631, 'latency': 1056028072}
{'id': 9, 'model': 'gpt3-30b', 'input': 5, 'output': 31, 'arrival': 1026970077, 'end_time': 3537953365, 'latency': 2510983288}
{'id': 40, 'model': 'gpt3-30b', 'input': 103, 'output': 105, 'arrival': 3568927610, 'end_time': 4042028451, 'latency': 473100841}
{'id': 18, 'model': 'gpt3-30b', 'input': 30, 'output': 51, 'arrival': 1789468376, 'end_time': 4143190386, 'latency': 2353722010}
{'id': 33, 'model': 'gpt3-30b', 'input': 43, 'output': 56, 'arrival': 2833725517, 'end_time': 4649050419, 'latency': 1815324902}
{'id': 20, 'model': 'gpt3-30b', 'input': 8, 'output': 37, 'arrival': 1918527763, 'end_time': 5278449719, 'latency': 3359921956}
{'id': 51, 'model': 'gpt3-30b', 'input': 4, 'output': 13, 'arrival': 4728227590, 'end_time': 5592610779, 'latency': 864383189}
{'id': 31, 'model': 'gpt3-30b', 'input': 8, 'output': 35, 'arrival': 2529630345, 'end_time': 5804580837, 'latency': 3274950492}
{'id': 28, 'model': 'gpt3-30b', 'input': 47, 'output': 78, 'arrival': 2412644533, 'end_time': 6326060889, 'latency': 3913416356}
{'id': 56, 'model': 'gpt3-30b', 'input': 91, 'output': 95, 'arrival': 5589266757, 'end_time': 6326060889, 'latency': 736794132}
{'id': 58, 'model': 'gpt3-30b', 'input': 24, 'output': 27, 'arrival': 5615708423, 'end_time': 6326060889, 'latency': 710352466}
{'id': 38, 'model': 'gpt3-30b', 'input': 2, 'output': 23, 'arrival': 3497903303, 'end_time': 6448193482, 'latency': 2950290179}
{'id': 39, 'model': 'gpt3-30b', 'input': 1, 'output': 21, 'arrival': 3555912387, 'end_time': 6448193482, 'latency': 2892281095}
{'id': 36, 'model': 'gpt3-30b', 'input': 1, 'output': 28, 'arrival': 3372350495, 'end_time': 6911456903, 'latency': 3539106408}
{'id': 73, 'model': 'gpt3-30b', 'input': 11, 'output': 12, 'arrival': 7025776321, 'end_time': 7175328298, 'latency': 149551977}
{'id': 0, 'model': 'gpt3-30b', 'input': 10, 'output': 80, 'arrival': 0, 'end_time': 7285223437, 'latency': 7285223437}
{'id': 45, 'model': 'gpt3-30b', 'input': 20, 'output': 46, 'arrival': 4019395352, 'end_time': 7285223437, 'latency': 3265828085}
{'id': 52, 'model': 'gpt3-30b', 'input': 16, 'output': 35, 'arrival': 5008737032, 'end_time': 7388496410, 'latency': 2379759378}
{'id': 8, 'model': 'gpt3-30b', 'input': 18, 'output': 76, 'arrival': 903845071, 'end_time': 7480667763, 'latency': 6576822692}
{'id': 5, 'model': 'gpt3-30b', 'input': 15, 'output': 78, 'arrival': 604829893, 'end_time': 7611275732, 'latency': 7006445839}
{'id': 43, 'model': 'gpt3-30b', 'input': 17, 'output': 47, 'arrival': 3880823994, 'end_time': 7611275732, 'latency': 3730451738}
{'id': 22, 'model': 'gpt3-30b', 'input': 4, 'output': 54, 'arrival': 1968102767, 'end_time': 7852958502, 'latency': 5884855735}
{'id': 2, 'model': 'gpt3-30b', 'input': 16, 'output': 85, 'arrival': 479613521, 'end_time': 8077523596, 'latency': 7597910075}
{'id': 19, 'model': 'gpt3-30b', 'input': 25, 'output': 79, 'arrival': 1823890676, 'end_time': 8175902654, 'latency': 6352011978}
{'id': 10, 'model': 'gpt3-30b', 'input': 83, 'output': 147, 'arrival': 1029050008, 'end_time': 8283544606, 'latency': 7254494598}
{'id': 69, 'model': 'gpt3-30b', 'input': 7, 'output': 21, 'arrival': 6686130579, 'end_time': 8283544606, 'latency': 1597414027}
{'id': 16, 'model': 'gpt3-30b', 'input': 23, 'output': 83, 'arrival': 1658521887, 'end_time': 8646084500, 'latency': 6987562613}
{'id': 63, 'model': 'gpt3-30b', 'input': 6, 'output': 29, 'arrival': 5956509192, 'end_time': 8646084500, 'latency': 2689575308}
{'id': 49, 'model': 'gpt3-30b', 'input': 73, 'output': 112, 'arrival': 4229722339, 'end_time': 8958410758, 'latency': 4728688419}
{'id': 35, 'model': 'gpt3-30b', 'input': 8, 'output': 55, 'arrival': 3336021709, 'end_time': 9063594602, 'latency': 5727572893}
{'id': 55, 'model': 'gpt3-30b', 'input': 39, 'output': 70, 'arrival': 5580001211, 'end_time': 9328893412, 'latency': 3748892201}
{'id': 37, 'model': 'gpt3-30b', 'input': 9, 'output': 60, 'arrival': 3382628226, 'end_time': 9623665258, 'latency': 6241037032}
{'id': 57, 'model': 'gpt3-30b', 'input': 24, 'output': 57, 'arrival': 5611080226, 'end_time': 9623665258, 'latency': 4012585032}
{'id': 53, 'model': 'gpt3-30b', 'input': 49, 'output': 87, 'arrival': 5233952232, 'end_time': 9720675097, 'latency': 4486722865}
{'id': 93, 'model': 'gpt3-30b', 'input': 7, 'output': 15, 'arrival': 8788269096, 'end_time': 9720675097, 'latency': 932406001}
{'id': 6, 'model': 'gpt3-30b', 'input': 15, 'output': 99, 'arrival': 610813769, 'end_time': 9912835697, 'latency': 9302021928}
{'id': 89, 'model': 'gpt3-30b', 'input': 9, 'output': 23, 'arrival': 8425191197, 'end_time': 10008449283, 'latency': 1583258086}
{'id': 86, 'model': 'gpt3-30b', 'input': 1, 'output': 25, 'arrival': 8041570457, 'end_time': 10577427129, 'latency': 2535856672}
{'id': 34, 'model': 'gpt3-30b', 'input': 17, 'output': 84, 'arrival': 3170788552, 'end_time': 10860515910, 'latency': 7689727358}
{'id': 4, 'model': 'gpt3-30b', 'input': 13, 'output': 109, 'arrival': 587870263, 'end_time': 10954404636, 'latency': 10366534373}
{'id': 12, 'model': 'gpt3-30b', 'input': 14, 'output': 100, 'arrival': 1558048710, 'end_time': 11141241076, 'latency': 9583192366}
{'id': 88, 'model': 'gpt3-30b', 'input': 66, 'output': 94, 'arrival': 8361284584, 'end_time': 11233882935, 'latency': 2872598351}
{'id': 11, 'model': 'gpt3-30b', 'input': 8, 'output': 99, 'arrival': 1379405756, 'end_time': 11326061872, 'latency': 9946656116}
{'id': 44, 'model': 'gpt3-30b', 'input': 6, 'output': 71, 'arrival': 3910769772, 'end_time': 11326061872, 'latency': 7415292100}
{'id': 1, 'model': 'gpt3-30b', 'input': 22, 'output': 126, 'arrival': 347938952, 'end_time': 11417299895, 'latency': 11069360943}
{'id': 27, 'model': 'gpt3-30b', 'input': 8, 'output': 91, 'arrival': 2322894061, 'end_time': 11598215345, 'latency': 9275321284}
{'id': 24, 'model': 'gpt3-30b', 'input': 7, 'output': 95, 'arrival': 2074623958, 'end_time': 11868186509, 'latency': 9793562551}
{'id': 13, 'model': 'gpt3-30b', 'input': 14, 'output': 113, 'arrival': 1581917473, 'end_time': 12315839007, 'latency': 10733921534}
{'id': 50, 'model': 'gpt3-30b', 'input': 12, 'output': 85, 'arrival': 4579003052, 'end_time': 12315839007, 'latency': 7736835955}
{'id': 66, 'model': 'gpt3-30b', 'input': 19, 'output': 80, 'arrival': 6082919999, 'end_time': 12315839007, 'latency': 6232919008}
{'id': 68, 'model': 'gpt3-30b', 'input': 4, 'output': 66, 'arrival': 6252715945, 'end_time': 12579246825, 'latency': 6326530880}
{'id': 70, 'model': 'gpt3-30b', 'input': 49, 'output': 105, 'arrival': 6834078957, 'end_time': 12579246825, 'latency': 5745167868}
{'id': 14, 'model': 'gpt3-30b', 'input': 3, 'output': 107, 'arrival': 1601985371, 'end_time': 12839854650, 'latency': 11237869279}
{'id': 48, 'model': 'gpt3-30b', 'input': 9, 'output': 90, 'arrival': 4209283479, 'end_time': 12925947419, 'latency': 8716663940}
{'id': 26, 'model': 'gpt3-30b', 'input': 16, 'output': 117, 'arrival': 2250691145, 'end_time': 13097199723, 'latency': 10846508578}
{'id': 41, 'model': 'gpt3-30b', 'input': 63, 'output': 150, 'arrival': 3637282333, 'end_time': 13182355417, 'latency': 9545073084}
{'id': 61, 'model': 'gpt3-30b', 'input': 19, 'output': 92, 'arrival': 5735930705, 'end_time': 13267040702, 'latency': 7531109997}
{'id': 62, 'model': 'gpt3-30b', 'input': 14, 'output': 87, 'arrival': 5912386492, 'end_time': 13350945690, 'latency': 7438559198}
{'id': 30, 'model': 'gpt3-30b', 'input': 26, 'output': 129, 'arrival': 2510934220, 'end_time': 13517822238, 'latency': 11006888018}
{'id': 72, 'model': 'gpt3-30b', 'input': 31, 'output': 98, 'arrival': 6856786643, 'end_time': 13517822238, 'latency': 6661035595}
{'id': 23, 'model': 'gpt3-30b', 'input': 68, 'output': 181, 'arrival': 2013730489, 'end_time': 13930325353, 'latency': 11916594864}
{'id': 54, 'model': 'gpt3-30b', 'input': 9, 'output': 93, 'arrival': 5325057673, 'end_time': 13930325353, 'latency': 8605267680}
{'id': 87, 'model': 'gpt3-30b', 'input': 16, 'output': 77, 'arrival': 8143059393, 'end_time': 13930325353, 'latency': 5787265960}
{'id': 15, 'model': 'gpt3-30b', 'input': 8, 'output': 127, 'arrival': 1622246514, 'end_time': 14091899631, 'latency': 12469653117}
{'id': 74, 'model': 'gpt3-30b', 'input': 22, 'output': 94, 'arrival': 7148485911, 'end_time': 14091899631, 'latency': 6943413720}
{'id': 32, 'model': 'gpt3-30b', 'input': 43, 'output': 155, 'arrival': 2536356738, 'end_time': 14250972591, 'latency': 11714615853}
{'id': 17, 'model': 'gpt3-30b', 'input': 18, 'output': 140, 'arrival': 1732914670, 'end_time': 14409112123, 'latency': 12676197453}
{'id': 76, 'model': 'gpt3-30b', 'input': 14, 'output': 87, 'arrival': 7426573655, 'end_time': 14409112123, 'latency': 6982538468}
{'id': 29, 'model': 'gpt3-30b', 'input': 13, 'output': 131, 'arrival': 2417400918, 'end_time': 14643520996, 'latency': 12226120078}
{'id': 47, 'model': 'gpt3-30b', 'input': 109, 'output': 213, 'arrival': 4130161099, 'end_time': 14720869550, 'latency': 10590708451}
{'id': 67, 'model': 'gpt3-30b', 'input': 36, 'output': 127, 'arrival': 6244968358, 'end_time': 14951515070, 'latency': 8706546712}
{'id': 77, 'model': 'gpt3-30b', 'input': 15, 'output': 95, 'arrival': 7434266581, 'end_time': 14951515070, 'latency': 7517248489}
{'id': 98, 'model': 'gpt3-30b', 'input': 5, 'output': 74, 'arrival': 9136063646, 'end_time': 15255291446, 'latency': 6119227800}
{'id': 42, 'model': 'gpt3-30b', 'input': 5, 'output': 124, 'arrival': 3640781705, 'end_time': 15706286468, 'latency': 12065504763}
{'id': 60, 'model': 'gpt3-30b', 'input': 18, 'output': 122, 'arrival': 5704274661, 'end_time': 15706286468, 'latency': 10002011807}
{'id': 79, 'model': 'gpt3-30b', 'input': 5, 'output': 96, 'arrival': 7490970859, 'end_time': 15854755078, 'latency': 8363784219}
{'id': 83, 'model': 'gpt3-30b', 'input': 21, 'output': 111, 'arrival': 7834202622, 'end_time': 15928518974, 'latency': 8094316352}
{'id': 64, 'model': 'gpt3-30b', 'input': 27, 'output': 135, 'arrival': 5989489476, 'end_time': 16074478586, 'latency': 10084989110}
{'id': 65, 'model': 'gpt3-30b', 'input': 12, 'output': 120, 'arrival': 6067730184, 'end_time': 16074478586, 'latency': 10006748402}
{'id': 46, 'model': 'gpt3-30b', 'input': 36, 'output': 162, 'arrival': 4056750010, 'end_time': 16362680038, 'latency': 12305930028}
{'id': 96, 'model': 'gpt3-30b', 'input': 22, 'output': 106, 'arrival': 9077707450, 'end_time': 16362680038, 'latency': 7284972588}
{'id': 81, 'model': 'gpt3-30b', 'input': 16, 'output': 115, 'arrival': 7787453935, 'end_time': 16575079006, 'latency': 8787625071}
{'id': 59, 'model': 'gpt3-30b', 'input': 120, 'output': 238, 'arrival': 5655061632, 'end_time': 16715745084, 'latency': 11060683452}
{'id': 84, 'model': 'gpt3-30b', 'input': 5, 'output': 106, 'arrival': 7871451457, 'end_time': 16785607665, 'latency': 8914156208}
{'id': 91, 'model': 'gpt3-30b', 'input': 11, 'output': 108, 'arrival': 8562841071, 'end_time': 16924391915, 'latency': 8361550844}
{'id': 78, 'model': 'gpt3-30b', 'input': 32, 'output': 142, 'arrival': 7478655849, 'end_time': 17130237044, 'latency': 9651581195}
{'id': 75, 'model': 'gpt3-30b', 'input': 14, 'output': 130, 'arrival': 7279052202, 'end_time': 17402823164, 'latency': 10123770962}
{'id': 85, 'model': 'gpt3-30b', 'input': 10, 'output': 120, 'arrival': 7910782878, 'end_time': 17402823164, 'latency': 9492040286}
{'id': 94, 'model': 'gpt3-30b', 'input': 11, 'output': 113, 'arrival': 8935658093, 'end_time': 17470034515, 'latency': 8534376422}
{'id': 92, 'model': 'gpt3-30b', 'input': 12, 'output': 117, 'arrival': 8705880346, 'end_time': 17536461776, 'latency': 8830581430}
{'id': 95, 'model': 'gpt3-30b', 'input': 15, 'output': 118, 'arrival': 9003739566, 'end_time': 17602425923, 'latency': 8598686357}
{'id': 90, 'model': 'gpt3-30b', 'input': 13, 'output': 123, 'arrival': 8437928437, 'end_time': 17733420983, 'latency': 9295492546}
{'id': 71, 'model': 'gpt3-30b', 'input': 13, 'output': 140, 'arrival': 6856232901, 'end_time': 17928502199, 'latency': 11072269298}
{'id': 80, 'model': 'gpt3-30b', 'input': 43, 'output': 164, 'arrival': 7689823816, 'end_time': 17992745278, 'latency': 10302921462}
{'id': 99, 'model': 'gpt3-30b', 'input': 18, 'output': 126, 'arrival': 9147480390, 'end_time': 17992745278, 'latency': 8845264888}
{'id': 97, 'model': 'gpt3-30b', 'input': 42, 'output': 155, 'arrival': 9133488869, 'end_time': 18309293778, 'latency': 9175804909}
{'id': 82, 'model': 'gpt3-30b', 'input': 6, 'output': 132, 'arrival': 7827635815, 'end_time': 18372136812, 'latency': 10544500997}
---------------------------
Throughput Results
---------------------------
Total prompts: 2241 tokens/s
Total Generation: 6706 tokens/s
Throughput per 0.5 sec: [(64, 12), (130, 68), (228, 100), (270, 154), (262, 218), (274, 232), (136, 372), (232, 198), (512, 226), (196, 340), (130, 442), (278, 272), (646, 412), (14, 532), (280, 550), (304, 442), (64, 476), (236, 604), (226, 506), (0, 640), (0, 722), (0, 590), (0, 556), (0, 614), (0, 588), (0, 452), (0, 496), (0, 448), (0, 446), (0, 334), (0, 344), (0, 274), (0, 256), (0, 228), (0, 154), (0, 92), (0, 22)]
Total clocks: 18372136812 ticks
Total latency: 18.372136812 s
Average throughput: prompt: 121.97819028520742 generation: 365.0092566053552
---------------------------
Simulation Time (ms)
---------------------------
Total execution engine time: 97445.209
Total graph time: 53094.255
Total astra time: 43575.88
Total scheduler time: 2153.031
Total simulation time: 196268.375
