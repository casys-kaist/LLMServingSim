model: gpt3-6.7b, num requests: 1, total length: 10, prompt/kv_cache length: ['10']
model: gpt3-6.7b, num requests: 1, total length: 1, prompt/kv_cache length: ['11']
model: gpt3-6.7b, num requests: 1, total length: 1, prompt/kv_cache length: ['12']
model: gpt3-6.7b, num requests: 1, total length: 1, prompt/kv_cache length: ['13']
model: gpt3-6.7b, num requests: 1, total length: 1, prompt/kv_cache length: ['14']
model: gpt3-6.7b, num requests: 1, total length: 1, prompt/kv_cache length: ['15']
model: gpt3-6.7b, num requests: 1, total length: 1, prompt/kv_cache length: ['16']
model: gpt3-6.7b, num requests: 1, total length: 1, prompt/kv_cache length: ['17']
model: gpt3-6.7b, num requests: 1, total length: 1, prompt/kv_cache length: ['18']
model: gpt3-6.7b, num requests: 1, total length: 1, prompt/kv_cache length: ['19']
model: gpt3-6.7b, num requests: 1, total length: 1, prompt/kv_cache length: ['20']
model: gpt3-6.7b, num requests: 1, total length: 1, prompt/kv_cache length: ['21']
model: gpt3-6.7b, num requests: 1, total length: 1, prompt/kv_cache length: ['22']
model: gpt3-6.7b, num requests: 1, total length: 1, prompt/kv_cache length: ['23']
model: gpt3-6.7b, num requests: 1, total length: 1, prompt/kv_cache length: ['24']
model: gpt3-6.7b, num requests: 1, total length: 1, prompt/kv_cache length: ['25']
model: gpt3-6.7b, num requests: 1, total length: 1, prompt/kv_cache length: ['26']
model: gpt3-6.7b, num requests: 1, total length: 1, prompt/kv_cache length: ['27']
model: gpt3-6.7b, num requests: 1, total length: 1, prompt/kv_cache length: ['28']
model: gpt3-6.7b, num requests: 1, total length: 1, prompt/kv_cache length: ['29']
model: gpt3-6.7b, num requests: 1, total length: 1, prompt/kv_cache length: ['30']
model: gpt3-6.7b, num requests: 1, total length: 1, prompt/kv_cache length: ['31']
model: gpt3-6.7b, num requests: 1, total length: 1, prompt/kv_cache length: ['32']
model: gpt3-6.7b, num requests: 1, total length: 1, prompt/kv_cache length: ['33']
model: gpt3-6.7b, num requests: 1, total length: 1, prompt/kv_cache length: ['34']
model: gpt3-6.7b, num requests: 1, total length: 1, prompt/kv_cache length: ['35']
model: gpt3-6.7b, num requests: 1, total length: 1, prompt/kv_cache length: ['36']
model: gpt3-6.7b, num requests: 1, total length: 1, prompt/kv_cache length: ['37']
model: gpt3-6.7b, num requests: 1, total length: 1, prompt/kv_cache length: ['38']
model: gpt3-6.7b, num requests: 1, total length: 1, prompt/kv_cache length: ['39']
model: gpt3-6.7b, num requests: 1, total length: 1, prompt/kv_cache length: ['40']
model: gpt3-6.7b, num requests: 1, total length: 1, prompt/kv_cache length: ['41']
model: gpt3-6.7b, num requests: 1, total length: 1, prompt/kv_cache length: ['42']
model: gpt3-6.7b, num requests: 1, total length: 1, prompt/kv_cache length: ['43']
model: gpt3-6.7b, num requests: 1, total length: 1, prompt/kv_cache length: ['44']
model: gpt3-6.7b, num requests: 1, total length: 1, prompt/kv_cache length: ['45']
model: gpt3-6.7b, num requests: 1, total length: 1, prompt/kv_cache length: ['46']
model: gpt3-6.7b, num requests: 1, total length: 1, prompt/kv_cache length: ['47']
model: gpt3-6.7b, num requests: 1, total length: 1, prompt/kv_cache length: ['48']
model: gpt3-6.7b, num requests: 1, total length: 1, prompt/kv_cache length: ['49']
model: gpt3-6.7b, num requests: 1, total length: 1, prompt/kv_cache length: ['50']
model: gpt3-6.7b, num requests: 2, total length: 23, prompt/kv_cache length: ['51', '22']
model: gpt3-6.7b, num requests: 2, total length: 2, prompt/kv_cache length: ['52', '23']
model: gpt3-6.7b, num requests: 2, total length: 2, prompt/kv_cache length: ['53', '24']
model: gpt3-6.7b, num requests: 2, total length: 2, prompt/kv_cache length: ['54', '25']
model: gpt3-6.7b, num requests: 2, total length: 2, prompt/kv_cache length: ['55', '26']
model: gpt3-6.7b, num requests: 2, total length: 2, prompt/kv_cache length: ['56', '27']
model: gpt3-6.7b, num requests: 2, total length: 2, prompt/kv_cache length: ['57', '28']
model: gpt3-6.7b, num requests: 2, total length: 2, prompt/kv_cache length: ['58', '29']
model: gpt3-6.7b, num requests: 2, total length: 2, prompt/kv_cache length: ['59', '30']
model: gpt3-6.7b, num requests: 2, total length: 2, prompt/kv_cache length: ['60', '31']
model: gpt3-6.7b, num requests: 2, total length: 2, prompt/kv_cache length: ['61', '32']
model: gpt3-6.7b, num requests: 2, total length: 2, prompt/kv_cache length: ['62', '33']
model: gpt3-6.7b, num requests: 2, total length: 2, prompt/kv_cache length: ['63', '34']
model: gpt3-6.7b, num requests: 2, total length: 2, prompt/kv_cache length: ['64', '35']
model: gpt3-6.7b, num requests: 3, total length: 18, prompt/kv_cache length: ['65', '36', '16']
[0.5s] Avg Throughput: propmt: 64, generation: 134
model: gpt3-6.7b, num requests: 3, total length: 3, prompt/kv_cache length: ['66', '37', '17']
model: gpt3-6.7b, num requests: 3, total length: 3, prompt/kv_cache length: ['67', '38', '18']
model: gpt3-6.7b, num requests: 3, total length: 3, prompt/kv_cache length: ['68', '39', '19']
model: gpt3-6.7b, num requests: 3, total length: 3, prompt/kv_cache length: ['69', '40', '20']
model: gpt3-6.7b, num requests: 3, total length: 3, prompt/kv_cache length: ['70', '41', '21']
model: gpt3-6.7b, num requests: 3, total length: 3, prompt/kv_cache length: ['71', '42', '22']
model: gpt3-6.7b, num requests: 3, total length: 3, prompt/kv_cache length: ['72', '43', '23']
model: gpt3-6.7b, num requests: 4, total length: 7, prompt/kv_cache length: ['73', '44', '24', '4']
model: gpt3-6.7b, num requests: 4, total length: 4, prompt/kv_cache length: ['74', '45', '25', '5']
model: gpt3-6.7b, num requests: 5, total length: 17, prompt/kv_cache length: ['75', '46', '26', '6', '13']
model: gpt3-6.7b, num requests: 7, total length: 35, prompt/kv_cache length: ['76', '47', '27', '7', '14', '15', '15']
model: gpt3-6.7b, num requests: 7, total length: 7, prompt/kv_cache length: ['77', '48', '28', '8', '15', '16', '16']
model: gpt3-6.7b, num requests: 7, total length: 7, prompt/kv_cache length: ['78', '49', '29', '9', '16', '17', '17']
model: gpt3-6.7b, num requests: 7, total length: 7, prompt/kv_cache length: ['79', '50', '30', '10', '17', '18', '18']
model: gpt3-6.7b, num requests: 6, total length: 6, prompt/kv_cache length: ['51', '31', '11', '18', '19', '19']
model: gpt3-6.7b, num requests: 6, total length: 6, prompt/kv_cache length: ['52', '32', '12', '19', '20', '20']
model: gpt3-6.7b, num requests: 6, total length: 6, prompt/kv_cache length: ['53', '33', '13', '20', '21', '21']
model: gpt3-6.7b, num requests: 6, total length: 6, prompt/kv_cache length: ['54', '34', '14', '21', '22', '22']
model: gpt3-6.7b, num requests: 6, total length: 6, prompt/kv_cache length: ['55', '35', '15', '22', '23', '23']
model: gpt3-6.7b, num requests: 5, total length: 5, prompt/kv_cache length: ['56', '36', '23', '24', '24']
model: gpt3-6.7b, num requests: 5, total length: 5, prompt/kv_cache length: ['57', '37', '24', '25', '25']
model: gpt3-6.7b, num requests: 5, total length: 5, prompt/kv_cache length: ['58', '38', '25', '26', '26']
model: gpt3-6.7b, num requests: 5, total length: 5, prompt/kv_cache length: ['59', '39', '26', '27', '27']
model: gpt3-6.7b, num requests: 5, total length: 5, prompt/kv_cache length: ['60', '40', '27', '28', '28']
model: gpt3-6.7b, num requests: 5, total length: 5, prompt/kv_cache length: ['61', '41', '28', '29', '29']
model: gpt3-6.7b, num requests: 6, total length: 7, prompt/kv_cache length: ['62', '42', '29', '30', '30', '2']
model: gpt3-6.7b, num requests: 6, total length: 6, prompt/kv_cache length: ['63', '43', '30', '31', '31', '3']
model: gpt3-6.7b, num requests: 6, total length: 6, prompt/kv_cache length: ['64', '44', '31', '32', '32', '4']
model: gpt3-6.7b, num requests: 6, total length: 6, prompt/kv_cache length: ['65', '45', '32', '33', '33', '5']
model: gpt3-6.7b, num requests: 6, total length: 6, prompt/kv_cache length: ['66', '46', '33', '34', '34', '6']
model: gpt3-6.7b, num requests: 6, total length: 6, prompt/kv_cache length: ['67', '47', '34', '35', '35', '7']
model: gpt3-6.7b, num requests: 6, total length: 6, prompt/kv_cache length: ['68', '48', '35', '36', '36', '8']
model: gpt3-6.7b, num requests: 7, total length: 24, prompt/kv_cache length: ['69', '49', '36', '37', '37', '9', '18']
model: gpt3-6.7b, num requests: 7, total length: 7, prompt/kv_cache length: ['70', '50', '37', '38', '38', '10', '19']
model: gpt3-6.7b, num requests: 6, total length: 6, prompt/kv_cache length: ['71', '51', '38', '39', '39', '20']
model: gpt3-6.7b, num requests: 6, total length: 6, prompt/kv_cache length: ['72', '52', '39', '40', '40', '21']
model: gpt3-6.7b, num requests: 6, total length: 6, prompt/kv_cache length: ['73', '53', '40', '41', '41', '22']
model: gpt3-6.7b, num requests: 6, total length: 6, prompt/kv_cache length: ['74', '54', '41', '42', '42', '23']
model: gpt3-6.7b, num requests: 6, total length: 6, prompt/kv_cache length: ['75', '55', '42', '43', '43', '24']
[1.0s] Avg Throughput: propmt: 166, generation: 396
model: gpt3-6.7b, num requests: 6, total length: 6, prompt/kv_cache length: ['76', '56', '43', '44', '44', '25']
model: gpt3-6.7b, num requests: 6, total length: 6, prompt/kv_cache length: ['77', '57', '44', '45', '45', '26']
model: gpt3-6.7b, num requests: 7, total length: 11, prompt/kv_cache length: ['78', '58', '45', '46', '46', '27', '5']
model: gpt3-6.7b, num requests: 8, total length: 90, prompt/kv_cache length: ['79', '59', '46', '47', '47', '28', '6', '83']
model: gpt3-6.7b, num requests: 8, total length: 8, prompt/kv_cache length: ['80', '60', '47', '48', '48', '29', '7', '84']
model: gpt3-6.7b, num requests: 8, total length: 8, prompt/kv_cache length: ['81', '61', '48', '49', '49', '30', '8', '85']
model: gpt3-6.7b, num requests: 8, total length: 8, prompt/kv_cache length: ['82', '62', '49', '50', '50', '31', '9', '86']
model: gpt3-6.7b, num requests: 8, total length: 8, prompt/kv_cache length: ['83', '63', '50', '51', '51', '32', '10', '87']
model: gpt3-6.7b, num requests: 8, total length: 8, prompt/kv_cache length: ['84', '64', '51', '52', '52', '33', '11', '88']
model: gpt3-6.7b, num requests: 8, total length: 8, prompt/kv_cache length: ['85', '65', '52', '53', '53', '34', '12', '89']
model: gpt3-6.7b, num requests: 8, total length: 8, prompt/kv_cache length: ['86', '66', '53', '54', '54', '35', '13', '90']
model: gpt3-6.7b, num requests: 8, total length: 8, prompt/kv_cache length: ['87', '67', '54', '55', '55', '36', '14', '91']
model: gpt3-6.7b, num requests: 8, total length: 8, prompt/kv_cache length: ['88', '68', '55', '56', '56', '37', '15', '92']
model: gpt3-6.7b, num requests: 8, total length: 8, prompt/kv_cache length: ['89', '69', '56', '57', '57', '38', '16', '93']
model: gpt3-6.7b, num requests: 8, total length: 8, prompt/kv_cache length: ['90', '70', '57', '58', '58', '39', '17', '94']
model: gpt3-6.7b, num requests: 8, total length: 8, prompt/kv_cache length: ['91', '71', '58', '59', '59', '40', '18', '95']
model: gpt3-6.7b, num requests: 8, total length: 8, prompt/kv_cache length: ['92', '72', '59', '60', '60', '41', '19', '96']
model: gpt3-6.7b, num requests: 8, total length: 8, prompt/kv_cache length: ['93', '73', '60', '61', '61', '42', '20', '97']
model: gpt3-6.7b, num requests: 8, total length: 8, prompt/kv_cache length: ['94', '74', '61', '62', '62', '43', '21', '98']
model: gpt3-6.7b, num requests: 8, total length: 8, prompt/kv_cache length: ['95', '75', '62', '63', '63', '44', '22', '99']
model: gpt3-6.7b, num requests: 8, total length: 8, prompt/kv_cache length: ['96', '76', '63', '64', '64', '45', '23', '100']
model: gpt3-6.7b, num requests: 8, total length: 8, prompt/kv_cache length: ['97', '77', '64', '65', '65', '46', '24', '101']
model: gpt3-6.7b, num requests: 8, total length: 8, prompt/kv_cache length: ['98', '78', '65', '66', '66', '47', '25', '102']
model: gpt3-6.7b, num requests: 9, total length: 16, prompt/kv_cache length: ['99', '79', '66', '67', '67', '48', '26', '103', '8']
model: gpt3-6.7b, num requests: 9, total length: 9, prompt/kv_cache length: ['100', '80', '67', '68', '68', '49', '27', '104', '9']
model: gpt3-6.7b, num requests: 9, total length: 9, prompt/kv_cache length: ['101', '81', '68', '69', '69', '50', '28', '105', '10']
model: gpt3-6.7b, num requests: 9, total length: 9, prompt/kv_cache length: ['102', '82', '69', '70', '70', '51', '29', '106', '11']
model: gpt3-6.7b, num requests: 9, total length: 9, prompt/kv_cache length: ['103', '83', '70', '71', '71', '52', '30', '107', '12']
model: gpt3-6.7b, num requests: 8, total length: 8, prompt/kv_cache length: ['104', '84', '71', '72', '72', '53', '108', '13']
model: gpt3-6.7b, num requests: 7, total length: 7, prompt/kv_cache length: ['105', '72', '73', '73', '54', '109', '14']
model: gpt3-6.7b, num requests: 7, total length: 7, prompt/kv_cache length: ['106', '73', '74', '74', '55', '110', '15']
[1.5s] Avg Throughput: propmt: 192, generation: 484
model: gpt3-6.7b, num requests: 7, total length: 7, prompt/kv_cache length: ['107', '74', '75', '75', '56', '111', '16']
model: gpt3-6.7b, num requests: 7, total length: 7, prompt/kv_cache length: ['108', '75', '76', '76', '57', '112', '17']
model: gpt3-6.7b, num requests: 7, total length: 7, prompt/kv_cache length: ['109', '76', '77', '77', '58', '113', '18']
model: gpt3-6.7b, num requests: 6, total length: 6, prompt/kv_cache length: ['110', '77', '78', '59', '114', '19']
model: gpt3-6.7b, num requests: 7, total length: 20, prompt/kv_cache length: ['111', '78', '79', '60', '115', '20', '14']
model: gpt3-6.7b, num requests: 7, total length: 7, prompt/kv_cache length: ['112', '79', '80', '61', '116', '21', '15']
model: gpt3-6.7b, num requests: 8, total length: 21, prompt/kv_cache length: ['113', '80', '81', '62', '117', '22', '16', '14']
model: gpt3-6.7b, num requests: 9, total length: 11, prompt/kv_cache length: ['114', '81', '82', '63', '118', '23', '17', '15', '3']
model: gpt3-6.7b, num requests: 10, total length: 17, prompt/kv_cache length: ['115', '82', '83', '64', '119', '24', '18', '16', '4', '8']
model: gpt3-6.7b, num requests: 10, total length: 10, prompt/kv_cache length: ['116', '83', '84', '65', '120', '25', '19', '17', '5', '9']
model: gpt3-6.7b, num requests: 11, total length: 33, prompt/kv_cache length: ['117', '84', '85', '66', '121', '26', '20', '18', '6', '10', '23']
model: gpt3-6.7b, num requests: 11, total length: 11, prompt/kv_cache length: ['118', '85', '86', '67', '122', '27', '21', '19', '7', '11', '24']
model: gpt3-6.7b, num requests: 11, total length: 11, prompt/kv_cache length: ['119', '86', '87', '68', '123', '28', '22', '20', '8', '12', '25']
model: gpt3-6.7b, num requests: 11, total length: 11, prompt/kv_cache length: ['120', '87', '88', '69', '124', '29', '23', '21', '9', '13', '26']
model: gpt3-6.7b, num requests: 12, total length: 29, prompt/kv_cache length: ['121', '88', '89', '70', '125', '30', '24', '22', '10', '14', '27', '18']
model: gpt3-6.7b, num requests: 12, total length: 12, prompt/kv_cache length: ['122', '89', '90', '71', '126', '31', '25', '23', '11', '15', '28', '19']
model: gpt3-6.7b, num requests: 12, total length: 12, prompt/kv_cache length: ['123', '90', '91', '72', '127', '32', '26', '24', '12', '16', '29', '20']
model: gpt3-6.7b, num requests: 13, total length: 42, prompt/kv_cache length: ['124', '91', '92', '73', '128', '33', '27', '25', '13', '17', '30', '21', '30']
model: gpt3-6.7b, num requests: 14, total length: 38, prompt/kv_cache length: ['125', '92', '93', '74', '129', '34', '28', '26', '14', '18', '31', '22', '31', '25']
model: gpt3-6.7b, num requests: 13, total length: 13, prompt/kv_cache length: ['93', '94', '75', '130', '35', '29', '27', '15', '19', '32', '23', '32', '26']
model: gpt3-6.7b, num requests: 12, total length: 12, prompt/kv_cache length: ['94', '95', '131', '36', '30', '28', '16', '20', '33', '24', '33', '27']
model: gpt3-6.7b, num requests: 12, total length: 12, prompt/kv_cache length: ['95', '96', '132', '37', '31', '29', '17', '21', '34', '25', '34', '28']
model: gpt3-6.7b, num requests: 13, total length: 20, prompt/kv_cache length: ['96', '97', '133', '38', '32', '30', '18', '22', '35', '26', '35', '29', '8']
model: gpt3-6.7b, num requests: 14, total length: 23, prompt/kv_cache length: ['97', '98', '134', '39', '33', '31', '19', '23', '36', '27', '36', '30', '9', '10']
model: gpt3-6.7b, num requests: 13, total length: 13, prompt/kv_cache length: ['98', '135', '40', '34', '32', '20', '24', '37', '28', '37', '31', '10', '11']
model: gpt3-6.7b, num requests: 14, total length: 17, prompt/kv_cache length: ['99', '136', '41', '35', '33', '21', '25', '38', '29', '38', '32', '11', '12', '4']
[2.0s] Avg Throughput: propmt: 306, generation: 518
model: gpt3-6.7b, num requests: 14, total length: 14, prompt/kv_cache length: ['100', '137', '42', '36', '34', '22', '26', '39', '30', '39', '33', '12', '13', '5']
model: gpt3-6.7b, num requests: 15, total length: 82, prompt/kv_cache length: ['101', '138', '43', '37', '35', '23', '27', '40', '31', '40', '34', '13', '14', '6', '68']
model: gpt3-6.7b, num requests: 16, total length: 22, prompt/kv_cache length: ['102', '139', '44', '38', '36', '24', '28', '41', '32', '41', '35', '14', '15', '7', '69', '7']
model: gpt3-6.7b, num requests: 16, total length: 16, prompt/kv_cache length: ['103', '140', '45', '39', '37', '25', '29', '42', '33', '42', '36', '15', '16', '8', '70', '8']
model: gpt3-6.7b, num requests: 16, total length: 16, prompt/kv_cache length: ['104', '141', '46', '40', '38', '26', '30', '43', '34', '43', '37', '16', '17', '9', '71', '9']
model: gpt3-6.7b, num requests: 16, total length: 16, prompt/kv_cache length: ['105', '142', '47', '41', '39', '27', '31', '44', '35', '44', '38', '17', '18', '10', '72', '10']
model: gpt3-6.7b, num requests: 16, total length: 16, prompt/kv_cache length: ['106', '143', '48', '42', '40', '28', '32', '45', '36', '45', '39', '18', '19', '11', '73', '11']
model: gpt3-6.7b, num requests: 15, total length: 15, prompt/kv_cache length: ['107', '144', '49', '43', '41', '29', '33', '46', '37', '46', '40', '19', '12', '74', '12']
model: gpt3-6.7b, num requests: 15, total length: 15, prompt/kv_cache length: ['108', '145', '50', '44', '42', '30', '34', '47', '38', '47', '41', '20', '13', '75', '13']
model: gpt3-6.7b, num requests: 15, total length: 24, prompt/kv_cache length: ['146', '51', '45', '43', '31', '35', '48', '39', '48', '42', '21', '14', '76', '14', '10']
model: gpt3-6.7b, num requests: 15, total length: 30, prompt/kv_cache length: ['52', '46', '44', '32', '36', '49', '40', '49', '43', '22', '15', '77', '15', '11', '16']
model: gpt3-6.7b, num requests: 15, total length: 15, prompt/kv_cache length: ['53', '47', '45', '33', '37', '50', '41', '50', '44', '23', '16', '78', '16', '12', '17']
model: gpt3-6.7b, num requests: 14, total length: 14, prompt/kv_cache length: ['54', '48', '46', '34', '38', '51', '42', '45', '24', '17', '79', '17', '13', '18']
model: gpt3-6.7b, num requests: 14, total length: 14, prompt/kv_cache length: ['55', '49', '47', '35', '39', '52', '43', '46', '25', '18', '80', '18', '14', '19']
model: gpt3-6.7b, num requests: 15, total length: 22, prompt/kv_cache length: ['56', '50', '48', '36', '40', '53', '44', '47', '26', '19', '81', '19', '15', '20', '8']
model: gpt3-6.7b, num requests: 15, total length: 15, prompt/kv_cache length: ['57', '51', '49', '37', '41', '54', '45', '48', '27', '20', '82', '20', '16', '21', '9']
model: gpt3-6.7b, num requests: 15, total length: 15, prompt/kv_cache length: ['58', '52', '50', '38', '42', '55', '46', '49', '28', '21', '83', '21', '17', '22', '10']
model: gpt3-6.7b, num requests: 15, total length: 15, prompt/kv_cache length: ['59', '53', '51', '39', '43', '56', '47', '50', '29', '22', '84', '22', '18', '23', '11']
model: gpt3-6.7b, num requests: 17, total length: 75, prompt/kv_cache length: ['60', '54', '52', '40', '44', '57', '48', '51', '30', '23', '85', '23', '19', '24', '12', '47', '13']
model: gpt3-6.7b, num requests: 16, total length: 16, prompt/kv_cache length: ['61', '55', '53', '41', '45', '58', '49', '52', '31', '24', '86', '24', '25', '13', '48', '14']
[2.5s] Avg Throughput: propmt: 346, generation: 590
model: gpt3-6.7b, num requests: 16, total length: 16, prompt/kv_cache length: ['62', '56', '54', '42', '46', '59', '50', '53', '32', '25', '87', '25', '26', '14', '49', '15']
model: gpt3-6.7b, num requests: 17, total length: 42, prompt/kv_cache length: ['63', '57', '55', '43', '47', '60', '51', '54', '33', '26', '88', '26', '27', '15', '50', '16', '26']
model: gpt3-6.7b, num requests: 19, total length: 68, prompt/kv_cache length: ['64', '58', '56', '44', '48', '61', '52', '55', '34', '27', '89', '27', '28', '16', '51', '17', '27', '8', '43']
model: gpt3-6.7b, num requests: 19, total length: 19, prompt/kv_cache length: ['65', '59', '57', '45', '49', '62', '53', '56', '35', '28', '90', '28', '29', '17', '52', '18', '28', '9', '44']
model: gpt3-6.7b, num requests: 19, total length: 19, prompt/kv_cache length: ['66', '60', '58', '46', '50', '63', '54', '57', '36', '29', '91', '29', '30', '18', '53', '19', '29', '10', '45']
model: gpt3-6.7b, num requests: 18, total length: 18, prompt/kv_cache length: ['67', '61', '59', '47', '51', '64', '55', '58', '30', '92', '30', '31', '19', '54', '20', '30', '11', '46']
model: gpt3-6.7b, num requests: 18, total length: 18, prompt/kv_cache length: ['68', '62', '60', '48', '52', '65', '56', '59', '31', '93', '31', '32', '20', '55', '21', '31', '12', '47']
model: gpt3-6.7b, num requests: 18, total length: 18, prompt/kv_cache length: ['69', '63', '61', '49', '53', '66', '57', '60', '32', '94', '32', '33', '21', '56', '22', '32', '13', '48']
model: gpt3-6.7b, num requests: 18, total length: 18, prompt/kv_cache length: ['70', '64', '62', '50', '54', '67', '58', '61', '33', '95', '33', '34', '22', '57', '23', '33', '14', '49']
model: gpt3-6.7b, num requests: 18, total length: 18, prompt/kv_cache length: ['71', '65', '63', '51', '55', '68', '59', '62', '34', '96', '34', '35', '23', '58', '24', '34', '15', '50']
model: gpt3-6.7b, num requests: 18, total length: 18, prompt/kv_cache length: ['72', '66', '64', '52', '56', '69', '60', '63', '35', '97', '35', '36', '24', '59', '25', '35', '16', '51']
model: gpt3-6.7b, num requests: 18, total length: 18, prompt/kv_cache length: ['73', '67', '65', '53', '57', '70', '61', '64', '36', '98', '36', '37', '25', '60', '26', '36', '17', '52']
model: gpt3-6.7b, num requests: 18, total length: 18, prompt/kv_cache length: ['74', '68', '66', '54', '58', '71', '62', '65', '37', '99', '37', '38', '26', '61', '27', '37', '18', '53']
model: gpt3-6.7b, num requests: 19, total length: 61, prompt/kv_cache length: ['75', '69', '67', '55', '59', '72', '63', '66', '38', '100', '38', '39', '27', '62', '28', '38', '19', '54', '43']
model: gpt3-6.7b, num requests: 19, total length: 19, prompt/kv_cache length: ['76', '70', '68', '56', '60', '73', '64', '67', '39', '101', '39', '40', '28', '63', '29', '39', '20', '55', '44']
model: gpt3-6.7b, num requests: 19, total length: 19, prompt/kv_cache length: ['77', '71', '69', '57', '61', '74', '65', '68', '40', '102', '40', '41', '29', '64', '30', '40', '21', '56', '45']
model: gpt3-6.7b, num requests: 19, total length: 19, prompt/kv_cache length: ['78', '72', '70', '58', '62', '75', '66', '69', '41', '103', '41', '42', '30', '65', '31', '41', '22', '57', '46']
model: gpt3-6.7b, num requests: 19, total length: 19, prompt/kv_cache length: ['79', '73', '71', '59', '63', '76', '67', '70', '42', '104', '42', '43', '31', '66', '32', '42', '23', '58', '47']
model: gpt3-6.7b, num requests: 19, total length: 19, prompt/kv_cache length: ['80', '74', '72', '60', '64', '77', '68', '71', '43', '105', '43', '44', '32', '67', '33', '43', '24', '59', '48']
[3.0s] Avg Throughput: propmt: 240, generation: 682
model: gpt3-6.7b, num requests: 19, total length: 19, prompt/kv_cache length: ['81', '75', '73', '61', '65', '78', '69', '72', '44', '106', '44', '45', '33', '68', '34', '44', '25', '60', '49']
model: gpt3-6.7b, num requests: 19, total length: 19, prompt/kv_cache length: ['82', '76', '74', '62', '66', '79', '70', '73', '45', '107', '45', '46', '34', '69', '35', '45', '26', '61', '50']
model: gpt3-6.7b, num requests: 19, total length: 19, prompt/kv_cache length: ['83', '77', '75', '63', '67', '80', '71', '74', '46', '108', '46', '47', '35', '70', '36', '46', '27', '62', '51']
model: gpt3-6.7b, num requests: 19, total length: 19, prompt/kv_cache length: ['84', '78', '76', '64', '68', '81', '72', '75', '47', '109', '47', '48', '36', '71', '37', '47', '28', '63', '52']
model: gpt3-6.7b, num requests: 19, total length: 19, prompt/kv_cache length: ['85', '79', '77', '65', '69', '82', '73', '76', '48', '110', '48', '49', '37', '72', '38', '48', '29', '64', '53']
model: gpt3-6.7b, num requests: 18, total length: 18, prompt/kv_cache length: ['86', '80', '78', '66', '70', '74', '77', '49', '111', '49', '50', '38', '73', '39', '49', '30', '65', '54']
model: gpt3-6.7b, num requests: 18, total length: 18, prompt/kv_cache length: ['87', '81', '79', '67', '71', '75', '78', '50', '112', '50', '51', '39', '74', '40', '50', '31', '66', '55']
model: gpt3-6.7b, num requests: 17, total length: 33, prompt/kv_cache length: ['88', '82', '80', '68', '72', '76', '51', '113', '51', '52', '40', '75', '41', '51', '32', '67', '17']
model: gpt3-6.7b, num requests: 17, total length: 17, prompt/kv_cache length: ['89', '83', '81', '69', '73', '77', '52', '114', '52', '53', '41', '76', '42', '52', '33', '68', '18']
model: gpt3-6.7b, num requests: 17, total length: 17, prompt/kv_cache length: ['90', '84', '82', '70', '74', '78', '53', '115', '53', '54', '42', '77', '43', '53', '34', '69', '19']
model: gpt3-6.7b, num requests: 14, total length: 14, prompt/kv_cache length: ['91', '85', '83', '71', '75', '79', '116', '54', '55', '43', '44', '54', '70', '20']
model: gpt3-6.7b, num requests: 14, total length: 14, prompt/kv_cache length: ['92', '86', '84', '72', '76', '80', '117', '55', '56', '44', '45', '55', '71', '21']
model: gpt3-6.7b, num requests: 14, total length: 14, prompt/kv_cache length: ['93', '87', '85', '73', '77', '81', '118', '56', '57', '45', '46', '56', '72', '22']
model: gpt3-6.7b, num requests: 14, total length: 14, prompt/kv_cache length: ['94', '88', '86', '74', '78', '82', '119', '57', '58', '46', '47', '57', '73', '23']
model: gpt3-6.7b, num requests: 14, total length: 14, prompt/kv_cache length: ['95', '89', '87', '75', '79', '83', '120', '58', '59', '47', '48', '58', '74', '24']
model: gpt3-6.7b, num requests: 15, total length: 22, prompt/kv_cache length: ['96', '90', '88', '76', '80', '84', '121', '59', '60', '48', '49', '59', '75', '25', '8']
model: gpt3-6.7b, num requests: 16, total length: 16, prompt/kv_cache length: ['97', '91', '89', '77', '81', '85', '122', '60', '61', '49', '50', '60', '76', '26', '9', '1']
model: gpt3-6.7b, num requests: 17, total length: 25, prompt/kv_cache length: ['98', '92', '90', '78', '82', '86', '123', '61', '62', '50', '51', '61', '77', '27', '10', '2', '9']
model: gpt3-6.7b, num requests: 16, total length: 16, prompt/kv_cache length: ['93', '91', '79', '83', '87', '124', '62', '63', '51', '52', '62', '78', '28', '11', '3', '10']
model: gpt3-6.7b, num requests: 16, total length: 16, prompt/kv_cache length: ['94', '92', '80', '84', '88', '125', '63', '64', '52', '53', '63', '79', '29', '12', '4', '11']
model: gpt3-6.7b, num requests: 16, total length: 16, prompt/kv_cache length: ['95', '93', '81', '85', '89', '126', '64', '65', '53', '54', '64', '80', '30', '13', '5', '12']
model: gpt3-6.7b, num requests: 16, total length: 16, prompt/kv_cache length: ['96', '94', '82', '86', '90', '127', '65', '66', '54', '55', '65', '81', '31', '14', '6', '13']
[3.5s] Avg Throughput: propmt: 70, generation: 726
model: gpt3-6.7b, num requests: 17, total length: 18, prompt/kv_cache length: ['97', '95', '83', '87', '91', '128', '66', '67', '55', '56', '66', '82', '32', '15', '7', '14', '2']
model: gpt3-6.7b, num requests: 17, total length: 17, prompt/kv_cache length: ['98', '96', '84', '88', '92', '129', '67', '68', '56', '57', '67', '83', '33', '16', '8', '15', '3']
model: gpt3-6.7b, num requests: 17, total length: 17, prompt/kv_cache length: ['99', '97', '85', '89', '93', '130', '68', '69', '57', '58', '68', '84', '34', '17', '9', '16', '4']
model: gpt3-6.7b, num requests: 18, total length: 120, prompt/kv_cache length: ['98', '86', '90', '94', '131', '69', '70', '58', '59', '69', '85', '35', '18', '10', '17', '5', '1', '103']
model: gpt3-6.7b, num requests: 20, total length: 86, prompt/kv_cache length: ['99', '87', '91', '95', '132', '70', '71', '59', '60', '70', '86', '36', '19', '11', '18', '6', '2', '104', '63', '5']
model: gpt3-6.7b, num requests: 19, total length: 19, prompt/kv_cache length: ['100', '88', '92', '96', '133', '71', '72', '60', '61', '71', '87', '37', '20', '12', '19', '7', '3', '64', '6']
model: gpt3-6.7b, num requests: 19, total length: 19, prompt/kv_cache length: ['101', '89', '93', '97', '134', '72', '73', '61', '62', '72', '88', '38', '21', '13', '20', '8', '4', '65', '7']
model: gpt3-6.7b, num requests: 19, total length: 19, prompt/kv_cache length: ['102', '90', '94', '98', '135', '73', '74', '62', '63', '73', '89', '39', '22', '14', '21', '9', '5', '66', '8']
model: gpt3-6.7b, num requests: 19, total length: 19, prompt/kv_cache length: ['103', '91', '95', '99', '136', '74', '75', '63', '64', '74', '90', '40', '23', '15', '22', '10', '6', '67', '9']
model: gpt3-6.7b, num requests: 19, total length: 19, prompt/kv_cache length: ['104', '92', '96', '100', '137', '75', '76', '64', '65', '75', '91', '41', '24', '16', '23', '11', '7', '68', '10']
model: gpt3-6.7b, num requests: 19, total length: 19, prompt/kv_cache length: ['105', '93', '97', '101', '138', '76', '77', '65', '66', '76', '92', '42', '25', '17', '24', '12', '8', '69', '11']
model: gpt3-6.7b, num requests: 19, total length: 19, prompt/kv_cache length: ['106', '94', '98', '102', '139', '77', '78', '66', '67', '77', '93', '43', '26', '18', '25', '13', '9', '70', '12']
model: gpt3-6.7b, num requests: 20, total length: 36, prompt/kv_cache length: ['107', '95', '99', '103', '140', '78', '79', '67', '68', '78', '94', '44', '27', '19', '26', '14', '10', '71', '13', '17']
model: gpt3-6.7b, num requests: 21, total length: 26, prompt/kv_cache length: ['108', '96', '100', '104', '141', '79', '80', '68', '69', '79', '95', '45', '28', '20', '27', '15', '11', '72', '14', '18', '6']
model: gpt3-6.7b, num requests: 21, total length: 21, prompt/kv_cache length: ['109', '97', '101', '105', '142', '80', '81', '69', '70', '80', '96', '46', '29', '21', '28', '16', '12', '73', '15', '19', '7']
model: gpt3-6.7b, num requests: 21, total length: 21, prompt/kv_cache length: ['110', '98', '102', '106', '143', '81', '82', '70', '71', '81', '97', '47', '30', '22', '29', '17', '13', '74', '16', '20', '8']
[4.0s] Avg Throughput: propmt: 394, generation: 586
model: gpt3-6.7b, num requests: 21, total length: 21, prompt/kv_cache length: ['111', '99', '103', '107', '144', '82', '83', '71', '72', '82', '98', '48', '31', '23', '30', '18', '14', '75', '17', '21', '9']
model: gpt3-6.7b, num requests: 22, total length: 41, prompt/kv_cache length: ['112', '100', '104', '108', '145', '83', '84', '72', '73', '83', '99', '49', '32', '24', '31', '19', '15', '76', '18', '22', '10', '20']
model: gpt3-6.7b, num requests: 22, total length: 57, prompt/kv_cache length: ['101', '105', '109', '146', '84', '85', '73', '74', '84', '100', '50', '33', '25', '32', '20', '16', '77', '19', '23', '11', '21', '36']
model: gpt3-6.7b, num requests: 22, total length: 22, prompt/kv_cache length: ['102', '106', '110', '147', '85', '86', '74', '75', '85', '101', '51', '34', '26', '33', '21', '17', '78', '20', '24', '12', '22', '37']
model: gpt3-6.7b, num requests: 23, total length: 131, prompt/kv_cache length: ['103', '107', '111', '148', '86', '87', '75', '76', '86', '102', '52', '35', '27', '34', '22', '18', '79', '21', '25', '13', '23', '38', '109']
model: gpt3-6.7b, num requests: 23, total length: 103, prompt/kv_cache length: ['104', '108', '112', '149', '87', '88', '76', '77', '87', '103', '53', '36', '35', '19', '80', '22', '26', '14', '24', '39', '110', '9', '73']
model: gpt3-6.7b, num requests: 23, total length: 23, prompt/kv_cache length: ['105', '109', '113', '150', '88', '89', '77', '78', '88', '104', '54', '37', '36', '20', '81', '23', '27', '15', '25', '40', '111', '10', '74']
model: gpt3-6.7b, num requests: 22, total length: 22, prompt/kv_cache length: ['106', '110', '114', '151', '89', '90', '78', '79', '89', '105', '55', '38', '37', '82', '24', '28', '16', '26', '41', '112', '11', '75']
model: gpt3-6.7b, num requests: 21, total length: 21, prompt/kv_cache length: ['111', '115', '152', '90', '91', '79', '80', '90', '106', '56', '39', '38', '83', '25', '29', '17', '27', '42', '113', '12', '76']
model: gpt3-6.7b, num requests: 21, total length: 21, prompt/kv_cache length: ['112', '116', '153', '91', '92', '80', '81', '91', '107', '57', '40', '39', '84', '26', '30', '18', '28', '43', '114', '13', '77']
model: gpt3-6.7b, num requests: 21, total length: 21, prompt/kv_cache length: ['113', '117', '154', '92', '93', '81', '82', '92', '108', '58', '41', '40', '85', '27', '31', '19', '29', '44', '115', '14', '78']
model: gpt3-6.7b, num requests: 21, total length: 21, prompt/kv_cache length: ['114', '118', '155', '93', '94', '82', '83', '93', '109', '59', '42', '41', '86', '28', '32', '20', '30', '45', '116', '15', '79']
model: gpt3-6.7b, num requests: 21, total length: 21, prompt/kv_cache length: ['115', '119', '156', '94', '95', '83', '84', '94', '110', '60', '43', '42', '87', '29', '33', '21', '31', '46', '117', '16', '80']
model: gpt3-6.7b, num requests: 20, total length: 20, prompt/kv_cache length: ['116', '120', '157', '96', '84', '85', '95', '111', '61', '44', '43', '88', '30', '34', '22', '32', '47', '118', '17', '81']
[4.5s] Avg Throughput: propmt: 494, generation: 598
model: gpt3-6.7b, num requests: 20, total length: 20, prompt/kv_cache length: ['117', '121', '158', '97', '85', '86', '96', '112', '62', '45', '44', '89', '31', '35', '23', '33', '48', '119', '18', '82']
model: gpt3-6.7b, num requests: 20, total length: 20, prompt/kv_cache length: ['118', '122', '159', '98', '86', '87', '97', '113', '63', '46', '45', '90', '32', '36', '24', '34', '49', '120', '19', '83']
model: gpt3-6.7b, num requests: 20, total length: 20, prompt/kv_cache length: ['119', '123', '160', '99', '87', '88', '98', '114', '64', '47', '46', '91', '33', '37', '25', '35', '50', '121', '20', '84']
model: gpt3-6.7b, num requests: 21, total length: 32, prompt/kv_cache length: ['120', '124', '161', '100', '88', '89', '99', '115', '65', '48', '47', '92', '34', '38', '26', '36', '51', '122', '21', '85', '12']
model: gpt3-6.7b, num requests: 21, total length: 21, prompt/kv_cache length: ['121', '125', '162', '101', '89', '90', '100', '116', '66', '49', '48', '93', '35', '39', '27', '37', '52', '123', '22', '86', '13']
model: gpt3-6.7b, num requests: 21, total length: 21, prompt/kv_cache length: ['122', '126', '163', '102', '90', '91', '101', '117', '67', '50', '49', '94', '36', '40', '28', '38', '53', '124', '23', '87', '14']
model: gpt3-6.7b, num requests: 20, total length: 20, prompt/kv_cache length: ['123', '127', '164', '103', '92', '102', '118', '68', '51', '50', '95', '37', '41', '29', '39', '54', '125', '24', '88', '15']
model: gpt3-6.7b, num requests: 20, total length: 20, prompt/kv_cache length: ['124', '128', '165', '104', '93', '103', '119', '69', '52', '51', '96', '38', '42', '30', '40', '55', '126', '25', '89', '16']
model: gpt3-6.7b, num requests: 21, total length: 24, prompt/kv_cache length: ['125', '129', '166', '105', '94', '104', '120', '70', '53', '52', '97', '39', '43', '31', '41', '56', '127', '26', '90', '17', '4']
model: gpt3-6.7b, num requests: 21, total length: 21, prompt/kv_cache length: ['126', '130', '167', '106', '95', '105', '121', '71', '54', '53', '98', '40', '44', '32', '42', '57', '128', '27', '91', '18', '5']
model: gpt3-6.7b, num requests: 19, total length: 19, prompt/kv_cache length: ['131', '168', '107', '96', '106', '122', '72', '54', '99', '41', '45', '33', '43', '58', '129', '28', '92', '19', '6']
model: gpt3-6.7b, num requests: 19, total length: 19, prompt/kv_cache length: ['132', '169', '108', '97', '107', '123', '73', '55', '100', '42', '46', '34', '44', '59', '130', '29', '93', '20', '7']
model: gpt3-6.7b, num requests: 18, total length: 18, prompt/kv_cache length: ['133', '170', '109', '98', '108', '124', '74', '56', '101', '43', '35', '45', '60', '131', '30', '94', '21', '8']
model: gpt3-6.7b, num requests: 17, total length: 17, prompt/kv_cache length: ['134', '171', '110', '99', '109', '125', '75', '57', '102', '44', '36', '61', '132', '31', '95', '22', '9']
model: gpt3-6.7b, num requests: 17, total length: 17, prompt/kv_cache length: ['135', '172', '111', '100', '110', '126', '76', '58', '103', '45', '37', '62', '133', '32', '96', '23', '10']
model: gpt3-6.7b, num requests: 17, total length: 17, prompt/kv_cache length: ['136', '173', '112', '101', '111', '127', '77', '59', '104', '46', '38', '63', '134', '33', '97', '24', '11']
model: gpt3-6.7b, num requests: 16, total length: 16, prompt/kv_cache length: ['137', '174', '113', '102', '112', '128', '78', '105', '47', '39', '64', '135', '34', '98', '25', '12']
model: gpt3-6.7b, num requests: 15, total length: 15, prompt/kv_cache length: ['138', '175', '114', '103', '113', '129', '79', '106', '48', '40', '65', '136', '35', '99', '26']
model: gpt3-6.7b, num requests: 15, total length: 15, prompt/kv_cache length: ['139', '176', '115', '104', '114', '130', '80', '107', '49', '41', '66', '137', '36', '100', '27']
model: gpt3-6.7b, num requests: 14, total length: 14, prompt/kv_cache length: ['177', '116', '105', '115', '131', '81', '108', '50', '42', '67', '138', '37', '101', '28']
[5.0s] Avg Throughput: propmt: 32, generation: 752
model: gpt3-6.7b, num requests: 14, total length: 29, prompt/kv_cache length: ['178', '106', '116', '132', '82', '109', '51', '43', '68', '139', '38', '102', '29', '16']
model: gpt3-6.7b, num requests: 14, total length: 14, prompt/kv_cache length: ['179', '107', '117', '133', '83', '110', '52', '44', '69', '140', '39', '103', '30', '17']
model: gpt3-6.7b, num requests: 13, total length: 13, prompt/kv_cache length: ['180', '108', '118', '134', '111', '53', '45', '70', '141', '40', '104', '31', '18']
model: gpt3-6.7b, num requests: 12, total length: 12, prompt/kv_cache length: ['109', '119', '135', '112', '54', '46', '71', '142', '41', '105', '32', '19']
model: gpt3-6.7b, num requests: 12, total length: 12, prompt/kv_cache length: ['110', '120', '136', '113', '55', '47', '72', '143', '42', '106', '33', '20']
model: gpt3-6.7b, num requests: 12, total length: 12, prompt/kv_cache length: ['111', '121', '137', '114', '56', '48', '73', '144', '43', '107', '34', '21']
model: gpt3-6.7b, num requests: 12, total length: 12, prompt/kv_cache length: ['112', '122', '138', '115', '57', '49', '74', '145', '44', '108', '35', '22']
model: gpt3-6.7b, num requests: 12, total length: 12, prompt/kv_cache length: ['113', '123', '139', '116', '58', '50', '75', '146', '45', '109', '36', '23']
model: gpt3-6.7b, num requests: 12, total length: 12, prompt/kv_cache length: ['114', '124', '140', '117', '59', '51', '76', '147', '46', '110', '37', '24']
model: gpt3-6.7b, num requests: 12, total length: 12, prompt/kv_cache length: ['115', '125', '141', '118', '60', '52', '77', '148', '47', '111', '38', '25']
model: gpt3-6.7b, num requests: 11, total length: 11, prompt/kv_cache length: ['116', '126', '142', '119', '61', '53', '78', '149', '48', '39', '26']
model: gpt3-6.7b, num requests: 11, total length: 11, prompt/kv_cache length: ['117', '127', '143', '120', '62', '54', '79', '150', '49', '40', '27']
model: gpt3-6.7b, num requests: 12, total length: 60, prompt/kv_cache length: ['118', '128', '144', '121', '63', '55', '80', '151', '50', '41', '28', '49']
model: gpt3-6.7b, num requests: 11, total length: 11, prompt/kv_cache length: ['119', '145', '122', '64', '56', '81', '152', '51', '42', '29', '50']
model: gpt3-6.7b, num requests: 11, total length: 11, prompt/kv_cache length: ['120', '146', '123', '65', '57', '82', '153', '52', '43', '30', '51']
model: gpt3-6.7b, num requests: 11, total length: 11, prompt/kv_cache length: ['121', '147', '124', '66', '58', '83', '154', '53', '44', '31', '52']
model: gpt3-6.7b, num requests: 12, total length: 20, prompt/kv_cache length: ['122', '148', '125', '67', '59', '84', '155', '54', '45', '32', '53', '9']
model: gpt3-6.7b, num requests: 12, total length: 12, prompt/kv_cache length: ['123', '149', '126', '68', '60', '85', '156', '55', '46', '33', '54', '10']
model: gpt3-6.7b, num requests: 12, total length: 12, prompt/kv_cache length: ['124', '150', '127', '69', '61', '86', '157', '56', '47', '34', '55', '11']
model: gpt3-6.7b, num requests: 11, total length: 11, prompt/kv_cache length: ['125', '151', '128', '70', '62', '87', '158', '57', '48', '56', '12']
model: gpt3-6.7b, num requests: 11, total length: 11, prompt/kv_cache length: ['126', '152', '129', '71', '63', '88', '159', '58', '49', '57', '13']
model: gpt3-6.7b, num requests: 11, total length: 11, prompt/kv_cache length: ['127', '153', '130', '72', '64', '89', '160', '59', '50', '58', '14']
model: gpt3-6.7b, num requests: 11, total length: 11, prompt/kv_cache length: ['128', '154', '131', '73', '65', '90', '161', '60', '51', '59', '15']
model: gpt3-6.7b, num requests: 10, total length: 10, prompt/kv_cache length: ['129', '132', '74', '66', '91', '162', '61', '52', '60', '16']
model: gpt3-6.7b, num requests: 10, total length: 10, prompt/kv_cache length: ['130', '133', '75', '67', '92', '163', '62', '53', '61', '17']
model: gpt3-6.7b, num requests: 9, total length: 9, prompt/kv_cache length: ['134', '76', '68', '93', '164', '63', '54', '62', '18']
[5.5s] Avg Throughput: propmt: 148, generation: 606
model: gpt3-6.7b, num requests: 9, total length: 9, prompt/kv_cache length: ['135', '77', '69', '94', '165', '64', '55', '63', '19']
model: gpt3-6.7b, num requests: 9, total length: 9, prompt/kv_cache length: ['136', '78', '70', '95', '166', '65', '56', '64', '20']
model: gpt3-6.7b, num requests: 8, total length: 8, prompt/kv_cache length: ['137', '79', '96', '167', '66', '57', '65', '21']
model: gpt3-6.7b, num requests: 8, total length: 8, prompt/kv_cache length: ['138', '80', '97', '168', '67', '58', '66', '22']
model: gpt3-6.7b, num requests: 8, total length: 8, prompt/kv_cache length: ['139', '81', '98', '169', '68', '59', '67', '23']
model: gpt3-6.7b, num requests: 10, total length: 138, prompt/kv_cache length: ['140', '82', '99', '170', '69', '60', '68', '24', '39', '91']
model: gpt3-6.7b, num requests: 13, total length: 178, prompt/kv_cache length: ['141', '83', '100', '171', '70', '61', '69', '25', '40', '92', '24', '24', '120']
model: gpt3-6.7b, num requests: 15, total length: 50, prompt/kv_cache length: ['142', '84', '101', '172', '71', '62', '70', '26', '41', '93', '25', '25', '121', '18', '19']
model: gpt3-6.7b, num requests: 15, total length: 15, prompt/kv_cache length: ['143', '85', '102', '173', '72', '63', '71', '27', '42', '94', '26', '26', '122', '19', '20']
model: gpt3-6.7b, num requests: 13, total length: 13, prompt/kv_cache length: ['144', '86', '103', '174', '73', '64', '72', '28', '43', '27', '123', '20', '21']
model: gpt3-6.7b, num requests: 13, total length: 13, prompt/kv_cache length: ['145', '87', '104', '175', '74', '65', '73', '29', '44', '28', '124', '21', '22']
model: gpt3-6.7b, num requests: 13, total length: 13, prompt/kv_cache length: ['146', '88', '105', '176', '75', '66', '74', '30', '45', '29', '125', '22', '23']
model: gpt3-6.7b, num requests: 13, total length: 13, prompt/kv_cache length: ['147', '89', '106', '177', '76', '67', '75', '31', '46', '30', '126', '23', '24']
model: gpt3-6.7b, num requests: 14, total length: 27, prompt/kv_cache length: ['148', '90', '107', '178', '77', '68', '76', '32', '47', '31', '127', '24', '25', '14']
model: gpt3-6.7b, num requests: 14, total length: 14, prompt/kv_cache length: ['149', '91', '108', '179', '78', '69', '77', '33', '48', '32', '128', '25', '26', '15']
model: gpt3-6.7b, num requests: 14, total length: 19, prompt/kv_cache length: ['92', '109', '180', '79', '70', '78', '34', '49', '33', '129', '26', '27', '16', '6']
model: gpt3-6.7b, num requests: 14, total length: 14, prompt/kv_cache length: ['93', '110', '181', '80', '71', '79', '35', '50', '34', '130', '27', '28', '17', '7']
[6.0s] Avg Throughput: propmt: 710, generation: 378
model: gpt3-6.7b, num requests: 15, total length: 41, prompt/kv_cache length: ['94', '111', '182', '81', '72', '80', '36', '51', '35', '131', '28', '29', '18', '8', '27']
model: gpt3-6.7b, num requests: 15, total length: 15, prompt/kv_cache length: ['95', '112', '183', '82', '73', '81', '37', '52', '36', '132', '29', '30', '19', '9', '28']
model: gpt3-6.7b, num requests: 15, total length: 15, prompt/kv_cache length: ['96', '113', '184', '83', '74', '82', '38', '53', '37', '133', '30', '31', '20', '10', '29']
model: gpt3-6.7b, num requests: 16, total length: 27, prompt/kv_cache length: ['97', '114', '185', '84', '75', '83', '39', '54', '38', '134', '31', '32', '21', '11', '30', '12']
model: gpt3-6.7b, num requests: 17, total length: 35, prompt/kv_cache length: ['98', '115', '186', '85', '76', '84', '40', '55', '39', '135', '32', '33', '22', '12', '31', '13', '19']
model: gpt3-6.7b, num requests: 17, total length: 17, prompt/kv_cache length: ['99', '116', '187', '86', '77', '85', '41', '56', '40', '136', '33', '34', '23', '13', '32', '14', '20']
model: gpt3-6.7b, num requests: 17, total length: 17, prompt/kv_cache length: ['100', '117', '188', '87', '78', '86', '42', '57', '41', '137', '34', '35', '24', '14', '33', '15', '21']
model: gpt3-6.7b, num requests: 16, total length: 16, prompt/kv_cache length: ['101', '118', '189', '88', '79', '43', '58', '42', '138', '35', '36', '25', '15', '34', '16', '22']
model: gpt3-6.7b, num requests: 16, total length: 16, prompt/kv_cache length: ['102', '119', '190', '89', '80', '44', '59', '43', '139', '36', '37', '26', '16', '35', '17', '23']
model: gpt3-6.7b, num requests: 15, total length: 15, prompt/kv_cache length: ['103', '120', '191', '81', '45', '60', '44', '140', '37', '38', '27', '17', '36', '18', '24']
model: gpt3-6.7b, num requests: 16, total length: 51, prompt/kv_cache length: ['104', '121', '192', '82', '46', '61', '45', '141', '38', '39', '28', '18', '37', '19', '25', '36']
model: gpt3-6.7b, num requests: 17, total length: 20, prompt/kv_cache length: ['105', '122', '193', '83', '47', '62', '46', '142', '39', '40', '29', '19', '38', '20', '26', '37', '4']
model: gpt3-6.7b, num requests: 17, total length: 17, prompt/kv_cache length: ['106', '123', '194', '84', '48', '63', '47', '143', '40', '41', '30', '20', '39', '21', '27', '38', '5']
model: gpt3-6.7b, num requests: 16, total length: 16, prompt/kv_cache length: ['107', '124', '195', '49', '64', '48', '144', '41', '42', '31', '21', '40', '22', '28', '39', '6']
model: gpt3-6.7b, num requests: 16, total length: 16, prompt/kv_cache length: ['108', '125', '196', '50', '65', '49', '145', '42', '43', '32', '22', '41', '23', '29', '40', '7']
model: gpt3-6.7b, num requests: 16, total length: 16, prompt/kv_cache length: ['109', '126', '197', '51', '66', '50', '146', '43', '44', '33', '23', '42', '24', '30', '41', '8']
model: gpt3-6.7b, num requests: 16, total length: 16, prompt/kv_cache length: ['110', '127', '198', '52', '67', '51', '147', '44', '45', '34', '24', '43', '25', '31', '42', '9']
model: gpt3-6.7b, num requests: 16, total length: 16, prompt/kv_cache length: ['111', '128', '199', '53', '68', '52', '148', '45', '46', '35', '25', '44', '26', '32', '43', '10']
model: gpt3-6.7b, num requests: 16, total length: 16, prompt/kv_cache length: ['112', '129', '200', '54', '69', '53', '149', '46', '47', '36', '26', '45', '27', '33', '44', '11']
model: gpt3-6.7b, num requests: 15, total length: 15, prompt/kv_cache length: ['113', '130', '201', '55', '54', '150', '47', '48', '37', '27', '46', '28', '34', '45', '12']
model: gpt3-6.7b, num requests: 15, total length: 15, prompt/kv_cache length: ['114', '131', '202', '56', '55', '151', '48', '49', '38', '28', '47', '29', '35', '46', '13']
[6.5s] Avg Throughput: propmt: 196, generation: 658
model: gpt3-6.7b, num requests: 14, total length: 14, prompt/kv_cache length: ['115', '132', '203', '57', '56', '152', '49', '50', '39', '48', '30', '36', '47', '14']
model: gpt3-6.7b, num requests: 13, total length: 13, prompt/kv_cache length: ['116', '133', '204', '58', '153', '50', '51', '40', '49', '31', '37', '48', '15']
model: gpt3-6.7b, num requests: 13, total length: 13, prompt/kv_cache length: ['117', '134', '205', '59', '154', '51', '52', '41', '50', '32', '38', '49', '16']
model: gpt3-6.7b, num requests: 13, total length: 13, prompt/kv_cache length: ['118', '135', '206', '60', '155', '52', '53', '42', '51', '33', '39', '50', '17']
model: gpt3-6.7b, num requests: 13, total length: 13, prompt/kv_cache length: ['119', '136', '207', '61', '156', '53', '54', '43', '52', '34', '40', '51', '18']
model: gpt3-6.7b, num requests: 13, total length: 13, prompt/kv_cache length: ['120', '137', '208', '62', '157', '54', '55', '44', '53', '35', '41', '52', '19']
model: gpt3-6.7b, num requests: 13, total length: 13, prompt/kv_cache length: ['121', '138', '209', '63', '158', '55', '56', '45', '54', '36', '42', '53', '20']
model: gpt3-6.7b, num requests: 13, total length: 13, prompt/kv_cache length: ['122', '139', '210', '64', '159', '56', '57', '46', '55', '37', '43', '54', '21']
model: gpt3-6.7b, num requests: 13, total length: 13, prompt/kv_cache length: ['123', '140', '211', '65', '160', '57', '58', '47', '56', '38', '44', '55', '22']
model: gpt3-6.7b, num requests: 12, total length: 12, prompt/kv_cache length: ['141', '212', '66', '161', '58', '59', '48', '57', '39', '45', '56', '23']
model: gpt3-6.7b, num requests: 12, total length: 18, prompt/kv_cache length: ['142', '67', '162', '59', '60', '49', '58', '40', '46', '57', '24', '7']
model: gpt3-6.7b, num requests: 12, total length: 12, prompt/kv_cache length: ['143', '68', '163', '60', '61', '50', '59', '41', '47', '58', '25', '8']
model: gpt3-6.7b, num requests: 12, total length: 12, prompt/kv_cache length: ['144', '69', '164', '61', '62', '51', '60', '42', '48', '59', '26', '9']
model: gpt3-6.7b, num requests: 12, total length: 12, prompt/kv_cache length: ['145', '70', '165', '62', '63', '52', '61', '43', '49', '60', '27', '10']
model: gpt3-6.7b, num requests: 12, total length: 12, prompt/kv_cache length: ['146', '71', '166', '63', '64', '53', '62', '44', '50', '61', '28', '11']
model: gpt3-6.7b, num requests: 12, total length: 12, prompt/kv_cache length: ['147', '72', '167', '64', '65', '54', '63', '45', '51', '62', '29', '12']
model: gpt3-6.7b, num requests: 12, total length: 12, prompt/kv_cache length: ['148', '73', '168', '65', '66', '55', '64', '46', '52', '63', '30', '13']
model: gpt3-6.7b, num requests: 12, total length: 12, prompt/kv_cache length: ['149', '74', '169', '66', '67', '56', '65', '47', '53', '64', '31', '14']
model: gpt3-6.7b, num requests: 13, total length: 61, prompt/kv_cache length: ['150', '75', '170', '67', '68', '57', '66', '48', '54', '65', '32', '15', '49']
model: gpt3-6.7b, num requests: 15, total length: 57, prompt/kv_cache length: ['151', '76', '171', '68', '69', '58', '67', '49', '55', '66', '33', '16', '50', '13', '31']
model: gpt3-6.7b, num requests: 15, total length: 15, prompt/kv_cache length: ['152', '77', '172', '69', '70', '59', '68', '50', '56', '67', '34', '17', '51', '14', '32']
model: gpt3-6.7b, num requests: 15, total length: 15, prompt/kv_cache length: ['153', '78', '173', '70', '71', '60', '69', '51', '57', '68', '35', '18', '52', '15', '33']
model: gpt3-6.7b, num requests: 15, total length: 15, prompt/kv_cache length: ['154', '79', '174', '71', '72', '61', '70', '52', '58', '69', '36', '19', '53', '16', '34']
model: gpt3-6.7b, num requests: 15, total length: 15, prompt/kv_cache length: ['155', '80', '175', '72', '73', '62', '71', '53', '59', '70', '37', '20', '54', '17', '35']
[7.0s] Avg Throughput: propmt: 200, generation: 620
model: gpt3-6.7b, num requests: 14, total length: 14, prompt/kv_cache length: ['156', '81', '176', '73', '74', '63', '72', '54', '60', '71', '38', '55', '18', '36']
model: gpt3-6.7b, num requests: 15, total length: 25, prompt/kv_cache length: ['157', '82', '177', '74', '75', '64', '73', '55', '61', '72', '39', '56', '19', '37', '11']
model: gpt3-6.7b, num requests: 14, total length: 14, prompt/kv_cache length: ['158', '83', '178', '75', '76', '65', '74', '56', '62', '73', '40', '57', '20', '38']
model: gpt3-6.7b, num requests: 14, total length: 14, prompt/kv_cache length: ['159', '84', '179', '76', '77', '66', '75', '57', '63', '74', '41', '58', '21', '39']
model: gpt3-6.7b, num requests: 14, total length: 14, prompt/kv_cache length: ['160', '85', '180', '77', '78', '67', '76', '58', '64', '75', '42', '59', '22', '40']
model: gpt3-6.7b, num requests: 14, total length: 14, prompt/kv_cache length: ['161', '86', '181', '78', '79', '68', '77', '59', '65', '76', '43', '60', '23', '41']
model: gpt3-6.7b, num requests: 13, total length: 13, prompt/kv_cache length: ['87', '182', '79', '80', '69', '78', '60', '66', '77', '44', '61', '24', '42']
model: gpt3-6.7b, num requests: 14, total length: 35, prompt/kv_cache length: ['88', '183', '80', '81', '70', '79', '61', '67', '78', '45', '62', '25', '43', '22']
model: gpt3-6.7b, num requests: 14, total length: 14, prompt/kv_cache length: ['89', '184', '81', '82', '71', '80', '62', '68', '79', '46', '63', '26', '44', '23']
model: gpt3-6.7b, num requests: 14, total length: 14, prompt/kv_cache length: ['90', '185', '82', '83', '72', '81', '63', '69', '80', '47', '64', '27', '45', '24']
model: gpt3-6.7b, num requests: 14, total length: 14, prompt/kv_cache length: ['91', '186', '83', '84', '73', '82', '64', '70', '81', '48', '65', '28', '46', '25']
model: gpt3-6.7b, num requests: 14, total length: 14, prompt/kv_cache length: ['92', '187', '84', '85', '74', '83', '65', '71', '82', '49', '66', '29', '47', '26']
model: gpt3-6.7b, num requests: 13, total length: 13, prompt/kv_cache length: ['188', '85', '86', '75', '84', '66', '72', '83', '50', '67', '30', '48', '27']
model: gpt3-6.7b, num requests: 14, total length: 27, prompt/kv_cache length: ['189', '86', '87', '76', '85', '67', '73', '84', '51', '68', '31', '49', '28', '14']
model: gpt3-6.7b, num requests: 14, total length: 14, prompt/kv_cache length: ['190', '87', '88', '77', '86', '68', '74', '85', '52', '69', '32', '50', '29', '15']
model: gpt3-6.7b, num requests: 14, total length: 14, prompt/kv_cache length: ['191', '88', '89', '78', '87', '69', '75', '86', '53', '70', '33', '51', '30', '16']
model: gpt3-6.7b, num requests: 14, total length: 14, prompt/kv_cache length: ['192', '89', '90', '79', '88', '70', '76', '87', '54', '71', '34', '52', '31', '17']
model: gpt3-6.7b, num requests: 14, total length: 14, prompt/kv_cache length: ['193', '90', '91', '80', '89', '71', '77', '88', '55', '72', '35', '53', '32', '18']
model: gpt3-6.7b, num requests: 13, total length: 13, prompt/kv_cache length: ['194', '91', '81', '90', '72', '78', '89', '56', '73', '36', '54', '33', '19']
model: gpt3-6.7b, num requests: 13, total length: 13, prompt/kv_cache length: ['195', '92', '82', '91', '73', '79', '90', '57', '74', '37', '55', '34', '20']
model: gpt3-6.7b, num requests: 13, total length: 26, prompt/kv_cache length: ['196', '93', '83', '92', '74', '91', '58', '75', '38', '56', '35', '21', '14']
model: gpt3-6.7b, num requests: 14, total length: 28, prompt/kv_cache length: ['197', '94', '84', '93', '75', '92', '59', '76', '39', '57', '36', '22', '15', '15']
model: gpt3-6.7b, num requests: 14, total length: 14, prompt/kv_cache length: ['198', '95', '85', '94', '76', '93', '60', '77', '40', '58', '37', '23', '16', '16']
model: gpt3-6.7b, num requests: 16, total length: 51, prompt/kv_cache length: ['199', '96', '86', '95', '77', '94', '61', '78', '41', '59', '38', '24', '17', '17', '32', '5']
[7.5s] Avg Throughput: propmt: 152, generation: 656
model: gpt3-6.7b, num requests: 15, total length: 15, prompt/kv_cache length: ['200', '97', '96', '78', '95', '62', '79', '42', '60', '39', '25', '18', '18', '33', '6']
model: gpt3-6.7b, num requests: 15, total length: 15, prompt/kv_cache length: ['201', '98', '97', '79', '96', '63', '80', '43', '61', '40', '26', '19', '19', '34', '7']
model: gpt3-6.7b, num requests: 15, total length: 15, prompt/kv_cache length: ['202', '99', '98', '80', '97', '64', '81', '44', '62', '41', '27', '20', '20', '35', '8']
model: gpt3-6.7b, num requests: 15, total length: 15, prompt/kv_cache length: ['203', '100', '99', '81', '98', '65', '82', '45', '63', '42', '28', '21', '21', '36', '9']
model: gpt3-6.7b, num requests: 14, total length: 14, prompt/kv_cache length: ['204', '101', '100', '82', '99', '83', '46', '64', '43', '29', '22', '22', '37', '10']
model: gpt3-6.7b, num requests: 14, total length: 14, prompt/kv_cache length: ['205', '102', '101', '83', '100', '84', '47', '65', '44', '30', '23', '23', '38', '11']
model: gpt3-6.7b, num requests: 14, total length: 14, prompt/kv_cache length: ['206', '103', '102', '84', '101', '85', '48', '66', '45', '31', '24', '24', '39', '12']
model: gpt3-6.7b, num requests: 14, total length: 14, prompt/kv_cache length: ['207', '104', '103', '85', '102', '86', '49', '67', '46', '32', '25', '25', '40', '13']
model: gpt3-6.7b, num requests: 15, total length: 57, prompt/kv_cache length: ['208', '105', '104', '86', '103', '87', '50', '68', '47', '33', '26', '26', '41', '14', '43']
model: gpt3-6.7b, num requests: 15, total length: 15, prompt/kv_cache length: ['209', '106', '105', '87', '104', '88', '51', '69', '48', '34', '27', '27', '42', '15', '44']
model: gpt3-6.7b, num requests: 15, total length: 15, prompt/kv_cache length: ['210', '107', '106', '88', '105', '89', '52', '70', '49', '35', '28', '28', '43', '16', '45']
model: gpt3-6.7b, num requests: 15, total length: 15, prompt/kv_cache length: ['211', '108', '107', '89', '106', '90', '53', '71', '50', '36', '29', '29', '44', '17', '46']
model: gpt3-6.7b, num requests: 16, total length: 31, prompt/kv_cache length: ['212', '109', '108', '90', '107', '91', '54', '72', '51', '37', '30', '30', '45', '18', '47', '16']
model: gpt3-6.7b, num requests: 17, total length: 22, prompt/kv_cache length: ['213', '110', '109', '91', '108', '92', '55', '73', '52', '38', '31', '31', '46', '19', '48', '17', '6']
model: gpt3-6.7b, num requests: 18, total length: 38, prompt/kv_cache length: ['214', '111', '110', '92', '109', '93', '56', '74', '53', '39', '32', '32', '47', '20', '49', '18', '7', '21']
model: gpt3-6.7b, num requests: 19, total length: 23, prompt/kv_cache length: ['215', '112', '111', '93', '110', '94', '57', '75', '54', '40', '33', '33', '48', '21', '50', '19', '8', '22', '5']
model: gpt3-6.7b, num requests: 20, total length: 29, prompt/kv_cache length: ['216', '113', '112', '94', '111', '95', '58', '76', '55', '41', '34', '34', '49', '22', '51', '20', '9', '23', '6', '10']
model: gpt3-6.7b, num requests: 20, total length: 20, prompt/kv_cache length: ['217', '114', '113', '95', '112', '96', '59', '77', '56', '42', '35', '35', '50', '23', '52', '21', '10', '24', '7', '11']
model: gpt3-6.7b, num requests: 20, total length: 20, prompt/kv_cache length: ['218', '115', '114', '96', '113', '97', '60', '78', '57', '43', '36', '36', '51', '24', '53', '22', '11', '25', '8', '12']
model: gpt3-6.7b, num requests: 20, total length: 20, prompt/kv_cache length: ['219', '116', '115', '97', '114', '98', '61', '79', '58', '44', '37', '37', '52', '25', '54', '23', '12', '26', '9', '13']
[8.0s] Avg Throughput: propmt: 276, generation: 628
model: gpt3-6.7b, num requests: 20, total length: 20, prompt/kv_cache length: ['220', '117', '116', '98', '115', '99', '62', '80', '59', '45', '38', '38', '53', '26', '55', '24', '13', '27', '10', '14']
model: gpt3-6.7b, num requests: 21, total length: 21, prompt/kv_cache length: ['221', '118', '117', '99', '116', '100', '63', '81', '60', '46', '39', '39', '54', '27', '56', '25', '14', '28', '11', '15', '1']
model: gpt3-6.7b, num requests: 21, total length: 21, prompt/kv_cache length: ['222', '119', '118', '100', '117', '101', '64', '82', '61', '47', '40', '40', '55', '28', '57', '26', '15', '29', '12', '16', '2']
model: gpt3-6.7b, num requests: 21, total length: 21, prompt/kv_cache length: ['223', '120', '119', '101', '118', '102', '65', '83', '62', '48', '41', '41', '56', '29', '58', '27', '16', '30', '13', '17', '3']
model: gpt3-6.7b, num requests: 21, total length: 21, prompt/kv_cache length: ['224', '121', '120', '102', '119', '103', '66', '84', '63', '49', '42', '42', '57', '30', '59', '28', '17', '31', '14', '18', '4']
model: gpt3-6.7b, num requests: 21, total length: 36, prompt/kv_cache length: ['225', '121', '103', '120', '104', '67', '85', '64', '50', '43', '43', '58', '31', '60', '29', '18', '32', '15', '19', '5', '16']
model: gpt3-6.7b, num requests: 20, total length: 20, prompt/kv_cache length: ['226', '122', '104', '121', '68', '86', '65', '51', '44', '44', '59', '32', '61', '30', '19', '33', '16', '20', '6', '17']
model: gpt3-6.7b, num requests: 20, total length: 20, prompt/kv_cache length: ['227', '123', '105', '122', '69', '87', '66', '52', '45', '45', '60', '33', '62', '31', '20', '34', '17', '21', '7', '18']
model: gpt3-6.7b, num requests: 20, total length: 20, prompt/kv_cache length: ['228', '124', '106', '123', '70', '88', '67', '53', '46', '46', '61', '34', '63', '32', '21', '35', '18', '22', '8', '19']
model: gpt3-6.7b, num requests: 20, total length: 20, prompt/kv_cache length: ['229', '125', '107', '124', '71', '89', '68', '54', '47', '47', '62', '35', '64', '33', '22', '36', '19', '23', '9', '20']
model: gpt3-6.7b, num requests: 20, total length: 20, prompt/kv_cache length: ['230', '126', '108', '125', '72', '90', '69', '55', '48', '48', '63', '36', '65', '34', '23', '37', '20', '24', '10', '21']
model: gpt3-6.7b, num requests: 20, total length: 20, prompt/kv_cache length: ['231', '127', '109', '126', '73', '91', '70', '56', '49', '49', '64', '37', '66', '35', '24', '38', '21', '25', '11', '22']
model: gpt3-6.7b, num requests: 19, total length: 19, prompt/kv_cache length: ['232', '128', '110', '74', '92', '71', '57', '50', '50', '65', '38', '67', '36', '25', '39', '22', '26', '12', '23']
model: gpt3-6.7b, num requests: 19, total length: 19, prompt/kv_cache length: ['233', '129', '111', '75', '93', '72', '58', '51', '51', '66', '39', '68', '37', '26', '40', '23', '27', '13', '24']
model: gpt3-6.7b, num requests: 20, total length: 85, prompt/kv_cache length: ['234', '130', '112', '76', '94', '73', '59', '52', '52', '67', '40', '69', '38', '27', '41', '24', '28', '14', '25', '66']
model: gpt3-6.7b, num requests: 22, total length: 42, prompt/kv_cache length: ['235', '131', '113', '77', '95', '74', '60', '53', '53', '68', '41', '70', '39', '28', '42', '25', '29', '15', '26', '67', '9', '13']
model: gpt3-6.7b, num requests: 22, total length: 22, prompt/kv_cache length: ['236', '132', '114', '78', '96', '75', '61', '54', '54', '69', '42', '71', '40', '29', '43', '26', '30', '16', '27', '68', '10', '14']
[8.5s] Avg Throughput: propmt: 210, generation: 680
model: gpt3-6.7b, num requests: 22, total length: 22, prompt/kv_cache length: ['237', '133', '115', '79', '97', '76', '62', '55', '55', '70', '43', '72', '41', '30', '44', '27', '31', '17', '28', '69', '11', '15']
model: gpt3-6.7b, num requests: 20, total length: 20, prompt/kv_cache length: ['134', '116', '80', '77', '63', '56', '56', '71', '44', '73', '42', '31', '45', '28', '32', '18', '29', '70', '12', '16']
model: gpt3-6.7b, num requests: 19, total length: 19, prompt/kv_cache length: ['117', '81', '78', '64', '57', '57', '72', '45', '74', '43', '32', '46', '29', '33', '19', '30', '71', '13', '17']
model: gpt3-6.7b, num requests: 20, total length: 30, prompt/kv_cache length: ['118', '82', '79', '65', '58', '58', '73', '46', '75', '44', '33', '47', '30', '34', '20', '31', '72', '14', '18', '11']
model: gpt3-6.7b, num requests: 20, total length: 20, prompt/kv_cache length: ['119', '83', '80', '66', '59', '59', '74', '47', '76', '45', '34', '48', '31', '35', '21', '32', '73', '15', '19', '12']
model: gpt3-6.7b, num requests: 19, total length: 19, prompt/kv_cache length: ['84', '81', '67', '60', '60', '75', '48', '77', '46', '35', '49', '32', '36', '22', '33', '74', '16', '20', '13']
model: gpt3-6.7b, num requests: 19, total length: 19, prompt/kv_cache length: ['85', '82', '68', '61', '61', '76', '49', '78', '47', '36', '50', '33', '37', '23', '34', '75', '17', '21', '14']
model: gpt3-6.7b, num requests: 19, total length: 19, prompt/kv_cache length: ['86', '83', '69', '62', '62', '77', '50', '79', '48', '37', '51', '34', '38', '24', '35', '76', '18', '22', '15']
model: gpt3-6.7b, num requests: 18, total length: 18, prompt/kv_cache length: ['87', '84', '70', '63', '63', '78', '51', '80', '49', '38', '52', '35', '39', '36', '77', '19', '23', '16']
model: gpt3-6.7b, num requests: 19, total length: 30, prompt/kv_cache length: ['88', '85', '71', '64', '64', '79', '52', '81', '50', '39', '53', '36', '40', '37', '78', '20', '24', '17', '12']
model: gpt3-6.7b, num requests: 19, total length: 19, prompt/kv_cache length: ['89', '86', '72', '65', '65', '80', '53', '82', '51', '40', '54', '37', '41', '38', '79', '21', '25', '18', '13']
model: gpt3-6.7b, num requests: 19, total length: 19, prompt/kv_cache length: ['90', '87', '73', '66', '66', '81', '54', '83', '52', '41', '55', '38', '42', '39', '80', '22', '26', '19', '14']
model: gpt3-6.7b, num requests: 19, total length: 25, prompt/kv_cache length: ['91', '88', '74', '67', '67', '82', '55', '84', '53', '42', '56', '39', '43', '40', '81', '27', '20', '15', '7']
model: gpt3-6.7b, num requests: 19, total length: 19, prompt/kv_cache length: ['92', '89', '75', '68', '68', '83', '56', '85', '54', '43', '57', '40', '44', '41', '82', '28', '21', '16', '8']
model: gpt3-6.7b, num requests: 19, total length: 19, prompt/kv_cache length: ['93', '90', '76', '69', '69', '84', '57', '86', '55', '44', '58', '41', '45', '42', '83', '29', '22', '17', '9']
model: gpt3-6.7b, num requests: 19, total length: 19, prompt/kv_cache length: ['94', '91', '77', '70', '70', '85', '58', '87', '56', '45', '59', '42', '46', '43', '84', '30', '23', '18', '10']
model: gpt3-6.7b, num requests: 19, total length: 19, prompt/kv_cache length: ['95', '92', '78', '71', '71', '86', '59', '88', '57', '46', '60', '43', '47', '44', '85', '31', '24', '19', '11']
model: gpt3-6.7b, num requests: 19, total length: 19, prompt/kv_cache length: ['96', '93', '79', '72', '72', '87', '60', '89', '58', '47', '61', '44', '48', '45', '86', '32', '25', '20', '12']
model: gpt3-6.7b, num requests: 19, total length: 29, prompt/kv_cache length: ['97', '80', '73', '73', '88', '61', '90', '59', '48', '62', '45', '49', '46', '87', '33', '26', '21', '13', '11']
model: gpt3-6.7b, num requests: 19, total length: 19, prompt/kv_cache length: ['98', '81', '74', '74', '89', '62', '91', '60', '49', '63', '46', '50', '47', '88', '34', '27', '22', '14', '12']
[9.0s] Avg Throughput: propmt: 82, generation: 768
model: gpt3-6.7b, num requests: 19, total length: 33, prompt/kv_cache length: ['99', '82', '75', '75', '90', '63', '92', '61', '50', '64', '47', '51', '48', '89', '35', '28', '23', '13', '15']
model: gpt3-6.7b, num requests: 19, total length: 19, prompt/kv_cache length: ['100', '83', '76', '76', '91', '64', '93', '62', '51', '65', '48', '52', '49', '90', '36', '29', '24', '14', '16']
model: gpt3-6.7b, num requests: 19, total length: 19, prompt/kv_cache length: ['101', '84', '77', '77', '92', '65', '94', '63', '52', '66', '49', '53', '50', '91', '37', '30', '25', '15', '17']
model: gpt3-6.7b, num requests: 20, total length: 41, prompt/kv_cache length: ['102', '85', '78', '78', '93', '66', '95', '64', '53', '67', '50', '54', '51', '92', '38', '31', '26', '16', '18', '22']
model: gpt3-6.7b, num requests: 20, total length: 20, prompt/kv_cache length: ['103', '86', '79', '79', '94', '67', '96', '65', '54', '68', '51', '55', '52', '93', '39', '32', '27', '17', '19', '23']
model: gpt3-6.7b, num requests: 21, total length: 66, prompt/kv_cache length: ['104', '87', '80', '80', '95', '68', '97', '66', '55', '69', '52', '56', '53', '40', '33', '28', '18', '20', '24', '42', '5']
model: gpt3-6.7b, num requests: 22, total length: 39, prompt/kv_cache length: ['105', '88', '81', '81', '96', '69', '98', '67', '56', '70', '53', '57', '54', '41', '34', '29', '19', '21', '25', '43', '6', '18']
model: gpt3-6.7b, num requests: 22, total length: 22, prompt/kv_cache length: ['106', '89', '82', '82', '97', '70', '99', '68', '57', '71', '54', '58', '55', '42', '35', '30', '20', '22', '26', '44', '7', '19']
model: gpt3-6.7b, num requests: 22, total length: 22, prompt/kv_cache length: ['107', '90', '83', '83', '98', '71', '100', '69', '58', '72', '55', '59', '56', '43', '36', '31', '21', '23', '27', '45', '8', '20']
model: gpt3-6.7b, num requests: 22, total length: 22, prompt/kv_cache length: ['108', '91', '84', '84', '99', '72', '101', '70', '59', '73', '56', '60', '57', '44', '37', '32', '22', '24', '28', '46', '9', '21']
model: gpt3-6.7b, num requests: 22, total length: 22, prompt/kv_cache length: ['109', '92', '85', '85', '100', '73', '102', '71', '60', '74', '57', '61', '58', '45', '38', '33', '23', '25', '29', '47', '10', '22']
model: gpt3-6.7b, num requests: 22, total length: 22, prompt/kv_cache length: ['110', '93', '86', '86', '101', '74', '103', '72', '61', '75', '58', '62', '59', '46', '39', '34', '24', '26', '30', '48', '11', '23']
model: gpt3-6.7b, num requests: 21, total length: 21, prompt/kv_cache length: ['111', '94', '87', '102', '75', '104', '73', '62', '76', '59', '63', '60', '47', '40', '35', '25', '27', '31', '49', '12', '24']
model: gpt3-6.7b, num requests: 21, total length: 21, prompt/kv_cache length: ['112', '95', '88', '103', '76', '105', '74', '63', '77', '60', '64', '61', '48', '41', '36', '26', '28', '32', '50', '13', '25']
model: gpt3-6.7b, num requests: 21, total length: 21, prompt/kv_cache length: ['113', '96', '89', '104', '77', '106', '75', '64', '78', '61', '65', '62', '49', '42', '37', '27', '29', '33', '51', '14', '26']
model: gpt3-6.7b, num requests: 21, total length: 21, prompt/kv_cache length: ['114', '97', '90', '105', '78', '107', '76', '65', '79', '62', '66', '63', '50', '43', '38', '28', '30', '34', '52', '15', '27']
model: gpt3-6.7b, num requests: 21, total length: 21, prompt/kv_cache length: ['115', '98', '91', '106', '79', '108', '77', '66', '80', '63', '67', '64', '51', '44', '39', '29', '31', '35', '53', '16', '28']
model: gpt3-6.7b, num requests: 21, total length: 21, prompt/kv_cache length: ['116', '99', '92', '107', '80', '109', '78', '67', '81', '64', '68', '65', '52', '45', '40', '30', '32', '36', '54', '17', '29']
[9.5s] Avg Throughput: propmt: 204, generation: 738
model: gpt3-6.7b, num requests: 21, total length: 21, prompt/kv_cache length: ['117', '100', '93', '108', '81', '110', '79', '68', '82', '65', '69', '66', '53', '46', '41', '31', '33', '37', '55', '18', '30']
model: gpt3-6.7b, num requests: 21, total length: 21, prompt/kv_cache length: ['118', '101', '94', '109', '82', '111', '80', '69', '83', '66', '70', '67', '54', '47', '42', '32', '34', '38', '56', '19', '31']
model: gpt3-6.7b, num requests: 20, total length: 20, prompt/kv_cache length: ['119', '102', '110', '83', '112', '81', '70', '84', '67', '71', '68', '55', '48', '43', '33', '35', '39', '57', '20', '32']
model: gpt3-6.7b, num requests: 20, total length: 20, prompt/kv_cache length: ['120', '103', '111', '84', '113', '82', '71', '85', '68', '72', '69', '56', '49', '44', '34', '36', '40', '58', '21', '33']
model: gpt3-6.7b, num requests: 20, total length: 20, prompt/kv_cache length: ['121', '104', '112', '85', '114', '83', '72', '86', '69', '73', '70', '57', '50', '45', '35', '37', '41', '59', '22', '34']
model: gpt3-6.7b, num requests: 20, total length: 20, prompt/kv_cache length: ['122', '105', '113', '86', '115', '84', '73', '87', '70', '74', '71', '58', '51', '46', '36', '38', '42', '60', '23', '35']
model: gpt3-6.7b, num requests: 20, total length: 20, prompt/kv_cache length: ['123', '106', '114', '87', '116', '85', '74', '88', '71', '75', '72', '59', '52', '47', '37', '39', '43', '61', '24', '36']
model: gpt3-6.7b, num requests: 20, total length: 20, prompt/kv_cache length: ['124', '107', '115', '88', '117', '86', '75', '89', '72', '76', '73', '60', '53', '48', '38', '40', '44', '62', '25', '37']
model: gpt3-6.7b, num requests: 20, total length: 20, prompt/kv_cache length: ['125', '108', '116', '89', '118', '87', '76', '90', '73', '77', '74', '61', '54', '49', '39', '41', '45', '63', '26', '38']
model: gpt3-6.7b, num requests: 20, total length: 20, prompt/kv_cache length: ['126', '109', '117', '90', '119', '88', '77', '91', '74', '78', '75', '62', '55', '50', '40', '42', '46', '64', '27', '39']
model: gpt3-6.7b, num requests: 20, total length: 20, prompt/kv_cache length: ['127', '110', '118', '91', '120', '89', '78', '92', '75', '79', '76', '63', '56', '51', '41', '43', '47', '65', '28', '40']
model: gpt3-6.7b, num requests: 19, total length: 19, prompt/kv_cache length: ['128', '111', '119', '92', '121', '90', '79', '93', '76', '80', '64', '57', '52', '42', '44', '48', '66', '29', '41']
model: gpt3-6.7b, num requests: 19, total length: 19, prompt/kv_cache length: ['129', '112', '120', '93', '122', '91', '80', '94', '77', '81', '65', '58', '53', '43', '45', '49', '67', '30', '42']
model: gpt3-6.7b, num requests: 19, total length: 19, prompt/kv_cache length: ['130', '113', '121', '94', '123', '92', '81', '95', '78', '82', '66', '59', '54', '44', '46', '50', '68', '31', '43']
model: gpt3-6.7b, num requests: 19, total length: 19, prompt/kv_cache length: ['131', '114', '122', '95', '124', '93', '82', '96', '79', '83', '67', '60', '55', '45', '47', '51', '69', '32', '44']
model: gpt3-6.7b, num requests: 18, total length: 18, prompt/kv_cache length: ['132', '115', '123', '125', '94', '83', '97', '80', '84', '68', '61', '56', '46', '48', '52', '70', '33', '45']
model: gpt3-6.7b, num requests: 18, total length: 18, prompt/kv_cache length: ['133', '116', '124', '126', '95', '84', '98', '81', '85', '69', '62', '57', '47', '49', '53', '71', '34', '46']
model: gpt3-6.7b, num requests: 18, total length: 18, prompt/kv_cache length: ['134', '117', '125', '127', '96', '85', '99', '82', '86', '70', '63', '58', '48', '50', '54', '72', '35', '47']
model: gpt3-6.7b, num requests: 18, total length: 18, prompt/kv_cache length: ['135', '118', '126', '128', '97', '86', '100', '83', '87', '71', '64', '59', '49', '51', '55', '73', '36', '48']
model: gpt3-6.7b, num requests: 18, total length: 18, prompt/kv_cache length: ['136', '119', '127', '129', '98', '87', '101', '84', '88', '72', '65', '60', '50', '52', '56', '74', '37', '49']
[10.0s] Avg Throughput: propmt: 0, generation: 782
model: gpt3-6.7b, num requests: 18, total length: 18, prompt/kv_cache length: ['137', '120', '128', '130', '99', '88', '102', '85', '89', '73', '66', '61', '51', '53', '57', '75', '38', '50']
model: gpt3-6.7b, num requests: 18, total length: 18, prompt/kv_cache length: ['138', '121', '129', '131', '100', '89', '103', '86', '90', '74', '67', '62', '52', '54', '58', '76', '39', '51']
model: gpt3-6.7b, num requests: 18, total length: 18, prompt/kv_cache length: ['139', '122', '130', '132', '101', '90', '104', '87', '91', '75', '68', '63', '53', '55', '59', '77', '40', '52']
model: gpt3-6.7b, num requests: 17, total length: 17, prompt/kv_cache length: ['123', '131', '133', '102', '91', '105', '88', '92', '76', '69', '64', '54', '56', '60', '78', '41', '53']
model: gpt3-6.7b, num requests: 17, total length: 17, prompt/kv_cache length: ['124', '132', '134', '103', '92', '106', '89', '93', '77', '70', '65', '55', '57', '61', '79', '42', '54']
model: gpt3-6.7b, num requests: 17, total length: 17, prompt/kv_cache length: ['125', '133', '135', '104', '93', '107', '90', '94', '78', '71', '66', '56', '58', '62', '80', '43', '55']
model: gpt3-6.7b, num requests: 17, total length: 17, prompt/kv_cache length: ['126', '134', '136', '105', '94', '108', '91', '95', '79', '72', '67', '57', '59', '63', '81', '44', '56']
model: gpt3-6.7b, num requests: 17, total length: 17, prompt/kv_cache length: ['127', '135', '137', '106', '95', '109', '92', '96', '80', '73', '68', '58', '60', '64', '82', '45', '57']
model: gpt3-6.7b, num requests: 17, total length: 17, prompt/kv_cache length: ['128', '136', '138', '107', '96', '110', '93', '97', '81', '74', '69', '59', '61', '65', '83', '46', '58']
model: gpt3-6.7b, num requests: 16, total length: 16, prompt/kv_cache length: ['129', '137', '139', '108', '97', '94', '98', '82', '75', '70', '60', '62', '66', '84', '47', '59']
model: gpt3-6.7b, num requests: 15, total length: 15, prompt/kv_cache length: ['138', '140', '109', '98', '95', '99', '83', '76', '71', '61', '63', '67', '85', '48', '60']
model: gpt3-6.7b, num requests: 15, total length: 15, prompt/kv_cache length: ['139', '141', '110', '99', '96', '100', '84', '77', '72', '62', '64', '68', '86', '49', '61']
model: gpt3-6.7b, num requests: 15, total length: 15, prompt/kv_cache length: ['140', '142', '111', '100', '97', '101', '85', '78', '73', '63', '65', '69', '87', '50', '62']
model: gpt3-6.7b, num requests: 15, total length: 15, prompt/kv_cache length: ['141', '143', '112', '101', '98', '102', '86', '79', '74', '64', '66', '70', '88', '51', '63']
model: gpt3-6.7b, num requests: 14, total length: 14, prompt/kv_cache length: ['144', '113', '102', '99', '103', '87', '80', '75', '65', '67', '71', '89', '52', '64']
model: gpt3-6.7b, num requests: 14, total length: 14, prompt/kv_cache length: ['145', '114', '103', '100', '104', '88', '81', '76', '66', '68', '72', '90', '53', '65']
model: gpt3-6.7b, num requests: 13, total length: 13, prompt/kv_cache length: ['146', '104', '101', '105', '89', '82', '77', '67', '69', '73', '91', '54', '66']
model: gpt3-6.7b, num requests: 13, total length: 13, prompt/kv_cache length: ['147', '105', '102', '106', '90', '83', '78', '68', '70', '74', '92', '55', '67']
model: gpt3-6.7b, num requests: 13, total length: 13, prompt/kv_cache length: ['148', '106', '103', '107', '91', '84', '79', '69', '71', '75', '93', '56', '68']
model: gpt3-6.7b, num requests: 13, total length: 13, prompt/kv_cache length: ['149', '107', '104', '108', '92', '85', '80', '70', '72', '76', '94', '57', '69']
model: gpt3-6.7b, num requests: 13, total length: 13, prompt/kv_cache length: ['150', '108', '105', '109', '93', '86', '81', '71', '73', '77', '95', '58', '70']
model: gpt3-6.7b, num requests: 12, total length: 12, prompt/kv_cache length: ['151', '109', '110', '94', '87', '82', '72', '74', '78', '96', '59', '71']
model: gpt3-6.7b, num requests: 12, total length: 12, prompt/kv_cache length: ['152', '110', '111', '95', '88', '83', '73', '75', '79', '97', '60', '72']
[10.5s] Avg Throughput: propmt: 0, generation: 710
model: gpt3-6.7b, num requests: 12, total length: 12, prompt/kv_cache length: ['153', '111', '112', '96', '89', '84', '74', '76', '80', '98', '61', '73']
model: gpt3-6.7b, num requests: 12, total length: 12, prompt/kv_cache length: ['154', '112', '113', '97', '90', '85', '75', '77', '81', '99', '62', '74']
model: gpt3-6.7b, num requests: 12, total length: 12, prompt/kv_cache length: ['155', '113', '114', '98', '91', '86', '76', '78', '82', '100', '63', '75']
model: gpt3-6.7b, num requests: 12, total length: 12, prompt/kv_cache length: ['156', '114', '115', '99', '92', '87', '77', '79', '83', '101', '64', '76']
model: gpt3-6.7b, num requests: 12, total length: 12, prompt/kv_cache length: ['157', '115', '116', '100', '93', '88', '78', '80', '84', '102', '65', '77']
model: gpt3-6.7b, num requests: 12, total length: 12, prompt/kv_cache length: ['158', '116', '117', '101', '94', '89', '79', '81', '85', '103', '66', '78']
model: gpt3-6.7b, num requests: 12, total length: 12, prompt/kv_cache length: ['159', '117', '118', '102', '95', '90', '80', '82', '86', '104', '67', '79']
model: gpt3-6.7b, num requests: 12, total length: 12, prompt/kv_cache length: ['160', '118', '119', '103', '96', '91', '81', '83', '87', '105', '68', '80']
model: gpt3-6.7b, num requests: 11, total length: 11, prompt/kv_cache length: ['161', '119', '104', '97', '92', '82', '84', '88', '106', '69', '81']
model: gpt3-6.7b, num requests: 11, total length: 11, prompt/kv_cache length: ['162', '120', '105', '98', '93', '83', '85', '89', '107', '70', '82']
model: gpt3-6.7b, num requests: 11, total length: 11, prompt/kv_cache length: ['163', '121', '106', '99', '94', '84', '86', '90', '108', '71', '83']
model: gpt3-6.7b, num requests: 10, total length: 10, prompt/kv_cache length: ['122', '107', '100', '95', '85', '87', '91', '109', '72', '84']
model: gpt3-6.7b, num requests: 10, total length: 10, prompt/kv_cache length: ['123', '108', '101', '96', '86', '88', '92', '110', '73', '85']
model: gpt3-6.7b, num requests: 9, total length: 9, prompt/kv_cache length: ['124', '109', '102', '97', '87', '89', '93', '111', '86']
model: gpt3-6.7b, num requests: 9, total length: 9, prompt/kv_cache length: ['125', '110', '103', '98', '88', '90', '94', '112', '87']
model: gpt3-6.7b, num requests: 9, total length: 9, prompt/kv_cache length: ['126', '111', '104', '99', '89', '91', '95', '113', '88']
model: gpt3-6.7b, num requests: 9, total length: 9, prompt/kv_cache length: ['127', '112', '105', '100', '90', '92', '96', '114', '89']
model: gpt3-6.7b, num requests: 9, total length: 9, prompt/kv_cache length: ['128', '113', '106', '101', '91', '93', '97', '115', '90']
model: gpt3-6.7b, num requests: 9, total length: 9, prompt/kv_cache length: ['129', '114', '107', '102', '92', '94', '98', '116', '91']
model: gpt3-6.7b, num requests: 8, total length: 8, prompt/kv_cache length: ['130', '115', '103', '93', '95', '99', '117', '92']
model: gpt3-6.7b, num requests: 8, total length: 8, prompt/kv_cache length: ['131', '116', '104', '94', '96', '100', '118', '93']
model: gpt3-6.7b, num requests: 7, total length: 7, prompt/kv_cache length: ['117', '105', '95', '97', '101', '119', '94']
model: gpt3-6.7b, num requests: 7, total length: 7, prompt/kv_cache length: ['118', '106', '96', '98', '102', '120', '95']
model: gpt3-6.7b, num requests: 7, total length: 7, prompt/kv_cache length: ['119', '107', '97', '99', '103', '121', '96']
model: gpt3-6.7b, num requests: 7, total length: 7, prompt/kv_cache length: ['120', '108', '98', '100', '104', '122', '97']
model: gpt3-6.7b, num requests: 7, total length: 7, prompt/kv_cache length: ['121', '109', '99', '101', '105', '123', '98']
model: gpt3-6.7b, num requests: 6, total length: 6, prompt/kv_cache length: ['122', '110', '100', '102', '124', '99']
model: gpt3-6.7b, num requests: 5, total length: 5, prompt/kv_cache length: ['111', '101', '103', '125', '100']
model: gpt3-6.7b, num requests: 5, total length: 5, prompt/kv_cache length: ['112', '102', '104', '126', '101']
model: gpt3-6.7b, num requests: 5, total length: 5, prompt/kv_cache length: ['113', '103', '105', '127', '102']
model: gpt3-6.7b, num requests: 5, total length: 5, prompt/kv_cache length: ['114', '104', '106', '128', '103']
[11.0s] Avg Throughput: propmt: 0, generation: 574
model: gpt3-6.7b, num requests: 5, total length: 5, prompt/kv_cache length: ['115', '105', '107', '129', '104']
model: gpt3-6.7b, num requests: 5, total length: 5, prompt/kv_cache length: ['116', '106', '108', '130', '105']
model: gpt3-6.7b, num requests: 4, total length: 4, prompt/kv_cache length: ['107', '109', '131', '106']
model: gpt3-6.7b, num requests: 4, total length: 4, prompt/kv_cache length: ['108', '110', '132', '107']
model: gpt3-6.7b, num requests: 4, total length: 4, prompt/kv_cache length: ['109', '111', '133', '108']
model: gpt3-6.7b, num requests: 4, total length: 4, prompt/kv_cache length: ['110', '112', '134', '109']
model: gpt3-6.7b, num requests: 4, total length: 4, prompt/kv_cache length: ['111', '113', '135', '110']
model: gpt3-6.7b, num requests: 4, total length: 4, prompt/kv_cache length: ['112', '114', '136', '111']
model: gpt3-6.7b, num requests: 3, total length: 3, prompt/kv_cache length: ['115', '137', '112']
model: gpt3-6.7b, num requests: 3, total length: 3, prompt/kv_cache length: ['116', '138', '113']
model: gpt3-6.7b, num requests: 3, total length: 3, prompt/kv_cache length: ['117', '139', '114']
model: gpt3-6.7b, num requests: 2, total length: 2, prompt/kv_cache length: ['140', '115']
model: gpt3-6.7b, num requests: 2, total length: 2, prompt/kv_cache length: ['141', '116']
model: gpt3-6.7b, num requests: 2, total length: 2, prompt/kv_cache length: ['142', '117']
model: gpt3-6.7b, num requests: 2, total length: 2, prompt/kv_cache length: ['143', '118']
model: gpt3-6.7b, num requests: 2, total length: 2, prompt/kv_cache length: ['144', '119']
model: gpt3-6.7b, num requests: 2, total length: 2, prompt/kv_cache length: ['145', '120']
model: gpt3-6.7b, num requests: 2, total length: 2, prompt/kv_cache length: ['146', '121']
model: gpt3-6.7b, num requests: 2, total length: 2, prompt/kv_cache length: ['147', '122']
model: gpt3-6.7b, num requests: 2, total length: 2, prompt/kv_cache length: ['148', '123']
model: gpt3-6.7b, num requests: 2, total length: 2, prompt/kv_cache length: ['149', '124']
model: gpt3-6.7b, num requests: 2, total length: 2, prompt/kv_cache length: ['150', '125']
model: gpt3-6.7b, num requests: 1, total length: 1, prompt/kv_cache length: ['151']
model: gpt3-6.7b, num requests: 1, total length: 1, prompt/kv_cache length: ['152']
model: gpt3-6.7b, num requests: 1, total length: 1, prompt/kv_cache length: ['153']
model: gpt3-6.7b, num requests: 1, total length: 1, prompt/kv_cache length: ['154']
[11.5s] Avg Throughput: propmt: 0, generation: 148
---------------------------
Exiting The Simulator
Memory Is All Freed
Checking Non-Exited Systems ...
---------------------------
All Request Has Been Exited
---------------------------
{'id': 0, 'model': 'gpt3-6.7b', 'input': 10, 'output': 80, 'arrival': 0, 'end_time': 680307933, 'latency': 680307933}
{'id': 3, 'model': 'gpt3-6.7b', 'input': 4, 'output': 16, 'arrival': 570907776, 'end_time': 743684398, 'latency': 172776622}
{'id': 7, 'model': 'gpt3-6.7b', 'input': 2, 'output': 11, 'arrival': 811936856, 'end_time': 938605887, 'latency': 126669031}
{'id': 9, 'model': 'gpt3-6.7b', 'input': 5, 'output': 31, 'arrival': 1026970077, 'end_time': 1464494606, 'latency': 437524529}
{'id': 2, 'model': 'gpt3-6.7b', 'input': 16, 'output': 85, 'arrival': 479613521, 'end_time': 1479233497, 'latency': 999619976}
{'id': 5, 'model': 'gpt3-6.7b', 'input': 15, 'output': 78, 'arrival': 604829893, 'end_time': 1548476664, 'latency': 943646771}
{'id': 1, 'model': 'gpt3-6.7b', 'input': 22, 'output': 126, 'arrival': 347938952, 'end_time': 1867461428, 'latency': 1519522476}
{'id': 8, 'model': 'gpt3-6.7b', 'input': 18, 'output': 76, 'arrival': 903845071, 'end_time': 1886398831, 'latency': 982553760}
{'id': 6, 'model': 'gpt3-6.7b', 'input': 15, 'output': 99, 'arrival': 610813769, 'end_time': 1967690796, 'latency': 1356877027}
{'id': 21, 'model': 'gpt3-6.7b', 'input': 10, 'output': 20, 'arrival': 1933551216, 'end_time': 2189164219, 'latency': 255613003}
{'id': 4, 'model': 'gpt3-6.7b', 'input': 13, 'output': 109, 'arrival': 587870263, 'end_time': 2230567627, 'latency': 1642697364}
{'id': 10, 'model': 'gpt3-6.7b', 'input': 83, 'output': 147, 'arrival': 1029050008, 'end_time': 2254870622, 'latency': 1225820614}
{'id': 18, 'model': 'gpt3-6.7b', 'input': 30, 'output': 51, 'arrival': 1789468376, 'end_time': 2302122112, 'latency': 512653736}
{'id': 25, 'model': 'gpt3-6.7b', 'input': 10, 'output': 20, 'arrival': 2228417559, 'end_time': 2478653871, 'latency': 250236312}
{'id': 20, 'model': 'gpt3-6.7b', 'input': 8, 'output': 37, 'arrival': 1918527763, 'end_time': 2650773291, 'latency': 732245528}
{'id': 16, 'model': 'gpt3-6.7b', 'input': 23, 'output': 83, 'arrival': 1658521887, 'end_time': 3126561267, 'latency': 1468039380}
{'id': 19, 'model': 'gpt3-6.7b', 'input': 25, 'output': 79, 'arrival': 1823890676, 'end_time': 3173727307, 'latency': 1349836631}
{'id': 33, 'model': 'gpt3-6.7b', 'input': 43, 'output': 56, 'arrival': 2833725517, 'end_time': 3173727307, 'latency': 340001790}
{'id': 22, 'model': 'gpt3-6.7b', 'input': 4, 'output': 54, 'arrival': 1968102767, 'end_time': 3248399187, 'latency': 1280296420}
{'id': 28, 'model': 'gpt3-6.7b', 'input': 47, 'output': 78, 'arrival': 2412644533, 'end_time': 3248399187, 'latency': 835754654}
{'id': 31, 'model': 'gpt3-6.7b', 'input': 8, 'output': 35, 'arrival': 2529630345, 'end_time': 3248399187, 'latency': 718768842}
{'id': 11, 'model': 'gpt3-6.7b', 'input': 8, 'output': 99, 'arrival': 1379405756, 'end_time': 3420422998, 'latency': 2041017242}
{'id': 12, 'model': 'gpt3-6.7b', 'input': 14, 'output': 100, 'arrival': 1558048710, 'end_time': 3575971368, 'latency': 2017922658}
{'id': 40, 'model': 'gpt3-6.7b', 'input': 103, 'output': 105, 'arrival': 3568927610, 'end_time': 3716709654, 'latency': 147782044}
{'id': 13, 'model': 'gpt3-6.7b', 'input': 14, 'output': 113, 'arrival': 1581917473, 'end_time': 4061655172, 'latency': 2479737699}
{'id': 36, 'model': 'gpt3-6.7b', 'input': 1, 'output': 28, 'arrival': 3372350495, 'end_time': 4232163167, 'latency': 859812672}
{'id': 38, 'model': 'gpt3-6.7b', 'input': 2, 'output': 23, 'arrival': 3497903303, 'end_time': 4232163167, 'latency': 734259864}
{'id': 39, 'model': 'gpt3-6.7b', 'input': 1, 'output': 21, 'arrival': 3555912387, 'end_time': 4332720130, 'latency': 776807743}
{'id': 14, 'model': 'gpt3-6.7b', 'input': 3, 'output': 107, 'arrival': 1601985371, 'end_time': 4360020295, 'latency': 2758034924}
{'id': 24, 'model': 'gpt3-6.7b', 'input': 7, 'output': 95, 'arrival': 2074623958, 'end_time': 4492167314, 'latency': 2417543356}
{'id': 27, 'model': 'gpt3-6.7b', 'input': 8, 'output': 91, 'arrival': 2322894061, 'end_time': 4678602203, 'latency': 2355708142}
{'id': 15, 'model': 'gpt3-6.7b', 'input': 8, 'output': 127, 'arrival': 1622246514, 'end_time': 4784132143, 'latency': 3161885629}
{'id': 35, 'model': 'gpt3-6.7b', 'input': 8, 'output': 55, 'arrival': 3336021709, 'end_time': 4784132143, 'latency': 1448110434}
{'id': 43, 'model': 'gpt3-6.7b', 'input': 17, 'output': 47, 'arrival': 3880823994, 'end_time': 4833581171, 'latency': 952757177}
{'id': 45, 'model': 'gpt3-6.7b', 'input': 20, 'output': 46, 'arrival': 4019395352, 'end_time': 4857458911, 'latency': 838063559}
{'id': 37, 'model': 'gpt3-6.7b', 'input': 9, 'output': 60, 'arrival': 3382628226, 'end_time': 4926573534, 'latency': 1543945308}
{'id': 51, 'model': 'gpt3-6.7b', 'input': 4, 'output': 13, 'arrival': 4728227590, 'end_time': 4948760573, 'latency': 220532983}
{'id': 17, 'model': 'gpt3-6.7b', 'input': 18, 'output': 140, 'arrival': 1732914670, 'end_time': 4991497357, 'latency': 3258582687}
{'id': 26, 'model': 'gpt3-6.7b', 'input': 16, 'output': 117, 'arrival': 2250691145, 'end_time': 5011919390, 'latency': 2761228245}
{'id': 34, 'model': 'gpt3-6.7b', 'input': 17, 'output': 84, 'arrival': 3170788552, 'end_time': 5058822354, 'latency': 1888033802}
{'id': 23, 'model': 'gpt3-6.7b', 'input': 68, 'output': 181, 'arrival': 2013730489, 'end_time': 5078275981, 'latency': 3064545492}
{'id': 49, 'model': 'gpt3-6.7b', 'input': 73, 'output': 112, 'arrival': 4229722339, 'end_time': 5207728329, 'latency': 978005990}
{'id': 30, 'model': 'gpt3-6.7b', 'input': 26, 'output': 129, 'arrival': 2510934220, 'end_time': 5283489667, 'latency': 2772555447}
{'id': 52, 'model': 'gpt3-6.7b', 'input': 16, 'output': 35, 'arrival': 5008737032, 'end_time': 5394768302, 'latency': 386031270}
{'id': 32, 'model': 'gpt3-6.7b', 'input': 43, 'output': 155, 'arrival': 2536356738, 'end_time': 5465243430, 'latency': 2928886692}
{'id': 29, 'model': 'gpt3-6.7b', 'input': 13, 'output': 131, 'arrival': 2417400918, 'end_time': 5498582806, 'latency': 3081181888}
{'id': 44, 'model': 'gpt3-6.7b', 'input': 6, 'output': 71, 'arrival': 3910769772, 'end_time': 5545783737, 'latency': 1635013965}
{'id': 56, 'model': 'gpt3-6.7b', 'input': 91, 'output': 95, 'arrival': 5589266757, 'end_time': 5840598763, 'latency': 251332006}
{'id': 58, 'model': 'gpt3-6.7b', 'input': 24, 'output': 27, 'arrival': 5615708423, 'end_time': 5840598763, 'latency': 224890340}
{'id': 41, 'model': 'gpt3-6.7b', 'input': 63, 'output': 150, 'arrival': 3637282333, 'end_time': 5963518366, 'latency': 2326236033}
{'id': 53, 'model': 'gpt3-6.7b', 'input': 49, 'output': 87, 'arrival': 5233952232, 'end_time': 6181530910, 'latency': 947578678}
{'id': 48, 'model': 'gpt3-6.7b', 'input': 9, 'output': 90, 'arrival': 4209283479, 'end_time': 6225198236, 'latency': 2015914757}
{'id': 50, 'model': 'gpt3-6.7b', 'input': 12, 'output': 85, 'arrival': 4579003052, 'end_time': 6329701797, 'latency': 1750698745}
{'id': 55, 'model': 'gpt3-6.7b', 'input': 39, 'output': 70, 'arrival': 5580001211, 'end_time': 6460674399, 'latency': 880673188}
{'id': 63, 'model': 'gpt3-6.7b', 'input': 6, 'output': 29, 'arrival': 5956509192, 'end_time': 6502665327, 'latency': 546156135}
{'id': 57, 'model': 'gpt3-6.7b', 'input': 24, 'output': 57, 'arrival': 5611080226, 'end_time': 6522825728, 'latency': 911745502}
{'id': 42, 'model': 'gpt3-6.7b', 'input': 5, 'output': 124, 'arrival': 3640781705, 'end_time': 6677498456, 'latency': 3036716751}
{'id': 47, 'model': 'gpt3-6.7b', 'input': 109, 'output': 213, 'arrival': 4130161099, 'end_time': 6695939900, 'latency': 2565778801}
{'id': 69, 'model': 'gpt3-6.7b', 'input': 7, 'output': 21, 'arrival': 6686130579, 'end_time': 7008529682, 'latency': 322399103}
{'id': 73, 'model': 'gpt3-6.7b', 'input': 11, 'output': 12, 'arrival': 7025776321, 'end_time': 7053790189, 'latency': 28013868}
{'id': 46, 'model': 'gpt3-6.7b', 'input': 36, 'output': 162, 'arrival': 4056750010, 'end_time': 7134607601, 'latency': 3077857591}
{'id': 54, 'model': 'gpt3-6.7b', 'input': 9, 'output': 93, 'arrival': 5325057673, 'end_time': 7263356955, 'latency': 1938299282}
{'id': 61, 'model': 'gpt3-6.7b', 'input': 19, 'output': 92, 'arrival': 5735930705, 'end_time': 7388692944, 'latency': 1652762239}
{'id': 66, 'model': 'gpt3-6.7b', 'input': 19, 'output': 80, 'arrival': 6082919999, 'end_time': 7427236294, 'latency': 1344316295}
{'id': 62, 'model': 'gpt3-6.7b', 'input': 14, 'output': 87, 'arrival': 5912386492, 'end_time': 7534535511, 'latency': 1622149019}
{'id': 68, 'model': 'gpt3-6.7b', 'input': 4, 'output': 66, 'arrival': 6252715945, 'end_time': 7618244407, 'latency': 1365528462}
{'id': 60, 'model': 'gpt3-6.7b', 'input': 18, 'output': 122, 'arrival': 5704274661, 'end_time': 8150313391, 'latency': 2446038730}
{'id': 70, 'model': 'gpt3-6.7b', 'input': 49, 'output': 105, 'arrival': 6834078957, 'end_time': 8182763152, 'latency': 1348684195}
{'id': 67, 'model': 'gpt3-6.7b', 'input': 36, 'output': 127, 'arrival': 6244968358, 'end_time': 8334967142, 'latency': 2089998784}
{'id': 59, 'model': 'gpt3-6.7b', 'input': 120, 'output': 238, 'arrival': 5655061632, 'end_time': 8529339084, 'latency': 2874277452}
{'id': 72, 'model': 'gpt3-6.7b', 'input': 31, 'output': 98, 'arrival': 6856786643, 'end_time': 8529339084, 'latency': 1672552441}
{'id': 64, 'model': 'gpt3-6.7b', 'input': 27, 'output': 135, 'arrival': 5989489476, 'end_time': 8554529637, 'latency': 2565040161}
{'id': 65, 'model': 'gpt3-6.7b', 'input': 12, 'output': 120, 'arrival': 6067730184, 'end_time': 8633099514, 'latency': 2565369330}
{'id': 86, 'model': 'gpt3-6.7b', 'input': 1, 'output': 25, 'arrival': 8041570457, 'end_time': 8705748672, 'latency': 664178215}
{'id': 89, 'model': 'gpt3-6.7b', 'input': 9, 'output': 23, 'arrival': 8425191197, 'end_time': 8806494314, 'latency': 381303117}
{'id': 74, 'model': 'gpt3-6.7b', 'input': 22, 'output': 94, 'arrival': 7148485911, 'end_time': 8954996286, 'latency': 1806510375}
{'id': 93, 'model': 'gpt3-6.7b', 'input': 7, 'output': 15, 'arrival': 8788269096, 'end_time': 9007766435, 'latency': 219497339}
{'id': 88, 'model': 'gpt3-6.7b', 'input': 66, 'output': 94, 'arrival': 8361284584, 'end_time': 9146056304, 'latency': 784771720}
{'id': 76, 'model': 'gpt3-6.7b', 'input': 14, 'output': 87, 'arrival': 7426573655, 'end_time': 9361010002, 'latency': 1934436347}
{'id': 77, 'model': 'gpt3-6.7b', 'input': 15, 'output': 95, 'arrival': 7434266581, 'end_time': 9570988682, 'latency': 2136722101}
{'id': 87, 'model': 'gpt3-6.7b', 'input': 16, 'output': 77, 'arrival': 8143059393, 'end_time': 9800455019, 'latency': 1657395626}
{'id': 79, 'model': 'gpt3-6.7b', 'input': 5, 'output': 96, 'arrival': 7490970859, 'end_time': 9899337843, 'latency': 2408366984}
{'id': 71, 'model': 'gpt3-6.7b', 'input': 13, 'output': 140, 'arrival': 6856232901, 'end_time': 10090609939, 'latency': 3234377038}
{'id': 83, 'model': 'gpt3-6.7b', 'input': 21, 'output': 111, 'arrival': 7834202622, 'end_time': 10228997649, 'latency': 2394795027}
{'id': 75, 'model': 'gpt3-6.7b', 'input': 14, 'output': 130, 'arrival': 7279052202, 'end_time': 10251185776, 'latency': 2972133574}
{'id': 78, 'model': 'gpt3-6.7b', 'input': 32, 'output': 142, 'arrival': 7478655849, 'end_time': 10336253648, 'latency': 2857597799}
{'id': 81, 'model': 'gpt3-6.7b', 'input': 16, 'output': 115, 'arrival': 7787453935, 'end_time': 10376933810, 'latency': 2589479875}
{'id': 84, 'model': 'gpt3-6.7b', 'input': 5, 'output': 106, 'arrival': 7871451457, 'end_time': 10474158809, 'latency': 2602707352}
{'id': 85, 'model': 'gpt3-6.7b', 'input': 10, 'output': 120, 'arrival': 7910782878, 'end_time': 10660194305, 'latency': 2749411427}
{'id': 80, 'model': 'gpt3-6.7b', 'input': 43, 'output': 164, 'arrival': 7689823816, 'end_time': 10713392907, 'latency': 3023569091}
{'id': 98, 'model': 'gpt3-6.7b', 'input': 5, 'output': 74, 'arrival': 9136063646, 'end_time': 10746927803, 'latency': 1610864157}
{'id': 91, 'model': 'gpt3-6.7b', 'input': 11, 'output': 108, 'arrival': 8562841071, 'end_time': 10842352577, 'latency': 2279511506}
{'id': 82, 'model': 'gpt3-6.7b', 'input': 6, 'output': 132, 'arrival': 7827635815, 'end_time': 10872365463, 'latency': 3044729648}
{'id': 96, 'model': 'gpt3-6.7b', 'input': 22, 'output': 106, 'arrival': 9077707450, 'end_time': 10942721846, 'latency': 1865014396}
{'id': 90, 'model': 'gpt3-6.7b', 'input': 13, 'output': 123, 'arrival': 8437928437, 'end_time': 10955881427, 'latency': 2517952990}
{'id': 92, 'model': 'gpt3-6.7b', 'input': 12, 'output': 117, 'arrival': 8705880346, 'end_time': 11029262781, 'latency': 2323382435}
{'id': 94, 'model': 'gpt3-6.7b', 'input': 11, 'output': 113, 'arrival': 8935658093, 'end_time': 11097155997, 'latency': 2161497904}
{'id': 95, 'model': 'gpt3-6.7b', 'input': 15, 'output': 118, 'arrival': 9003739566, 'end_time': 11128335147, 'latency': 2124595581}
{'id': 99, 'model': 'gpt3-6.7b', 'input': 18, 'output': 126, 'arrival': 9147480390, 'end_time': 11232447180, 'latency': 2084966790}
{'id': 97, 'model': 'gpt3-6.7b', 'input': 42, 'output': 155, 'arrival': 9133488869, 'end_time': 11266551872, 'latency': 2133063003}
---------------------------
Throughput Results
---------------------------
Total prompts: 2241 tokens/s
Total Generation: 6706 tokens/s
Throughput per 0.5 sec: [(64, 134), (166, 396), (192, 484), (306, 518), (346, 590), (240, 682), (70, 726), (394, 586), (494, 598), (32, 752), (148, 606), (710, 378), (196, 658), (200, 620), (152, 656), (276, 628), (210, 680), (82, 768), (204, 738), (0, 782), (0, 710), (0, 574), (0, 148)]
Total clocks: 11266551872 ticks
Total latency: 11.266551872 s
Average throughput: prompt: 198.90735208608106 generation: 595.2131651446942
---------------------------
Simulation Time (ms)
---------------------------
Total execution engine time: 220402.898
Total graph time: 69708.958
Total astra time: 28929.22
Total scheduler time: 5400.92
Total simulation time: 324441.996
